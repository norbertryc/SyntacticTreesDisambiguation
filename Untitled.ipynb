{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "#import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2vecs_full = pickle.load(open(\"embeddings/w2v_allwiki_nkjpfull_300.pkl\",\"rb\"),encoding=\"latin1\")\n",
    "\n",
    "datasets = [\"Data/tokens.txt\"]\n",
    "\n",
    "words = set()\n",
    "for dataset in datasets:\n",
    "    with open(dataset) as f:\n",
    "        for x in f.read().split():\n",
    "            words.add(x)\n",
    "            \n",
    "words2ids_filtered = {}\n",
    "vectors_filtered = []\n",
    "\n",
    "i = 0\n",
    "for word in w2vecs_full.index2word:\n",
    "    if word in words:\n",
    "        words2ids_filtered[word] = i\n",
    "        vectors_filtered.append(w2vecs_full[word])\n",
    "        i = i + 1\n",
    "        \n",
    "        \n",
    "t = open(\"Data/tokens.txt\",\"r\")\n",
    "tokens = [x.split() for x in t.readlines()]\n",
    "t.close()\n",
    "r = open(\"Data/rules.txt\",\"r\")\n",
    "rules = [x.split() for x in r.readlines()]\n",
    "r.close()\n",
    "\n",
    "\n",
    "tokens2 = [[]]*len(tokens)\n",
    "unique_rules = set()\n",
    "for i in range(len(tokens)):\n",
    "    for j in range(len(tokens[i])):\n",
    "        if tokens[i][j][:2] == \"__\":\n",
    "            tokens2[i].append(tokens[i][j]+rules[i][j])\n",
    "            unique_rules.add(tokens[i][j]+rules[i][j])\n",
    "        else:\n",
    "            tokens2[i].append(tokens[i][j])\n",
    "            \n",
    "            \n",
    "for i, x in zip(range(len(vectors_filtered), len(vectors_filtered) + len(unique_rules)), unique_rules):\n",
    "    \n",
    "    words2ids_filtered[x] = i\n",
    "    vectors_filtered.append(np.random.uniform(-0.1,0.1,300))\n",
    "    \n",
    "vectors_filtered.append(np.random.uniform(-0.1,0.1,300))\n",
    "vectors_filtered = np.array(vectors_filtered)\n",
    "\n",
    "\n",
    "w2vecs = {}\n",
    "w2vecs[\"words2ids\"] = words2ids_filtered\n",
    "w2vecs[\"vectors\"] = vectors_filtered\n",
    "\n",
    "pickle.dump(w2vecs,open(\"embeddings/filtered_w2v_allwiki_nkjpfull_300.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30557"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(w2vecs[\"words2ids\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30556"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(list(w2vecs[\"words2ids\"].values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30558, 300)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w2vecs[\"vectors\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def words_in_from_down_to_top_order(sentence_tree):\n",
    "    #print sentence_tree\n",
    "    levels = np.setdiff1d(range(len(sentence_tree)),np.unique(sentence_tree)) # - zwraca slowo/a, ktore nie jest niczyim dzieckiem - czyli powinno/y byc korzeniem/korzeniami frazy/fraz\n",
    "    if len(levels) == 0: # wczesniej bylo != 1, co oznaczalo, ze jezeli okazuje sie jest wiecej niz jeden korzec (lub nie ma korzenia) to zwracamy None, aby pozniej rozpoznac takie zdanie i je wywalic. Ale jak robimy batche to musi byc kilka korzeni\n",
    "        return None, None\n",
    "    levels = levels.tolist() \n",
    "\n",
    "    for i in range(len(sentence_tree)):\n",
    "        x = np.setdiff1d(sentence_tree[levels[i]],-1)\n",
    "        levels.extend(x[x<len(sentence_tree)])\n",
    "            \n",
    "    ordered_words = np.array(levels)[levels != np.array(-1)][::-1] #odwracamy kolejnosc na poczatku beda slowa znajdujace sie najglebiej\n",
    "    \n",
    "    order = np.zeros(len(sentence_tree),dtype='int')\n",
    "    for i in range(len(sentence_tree)):\n",
    "        order[ordered_words[i]] = i\n",
    "\n",
    "    return ordered_words, order\n",
    "\n",
    "\n",
    "def load_stanford_data4(labels, parents, tokens, rules, words2ids, use_batch, batch_size, nb_classes):\n",
    "\n",
    "\n",
    "\n",
    "    sentences = []\n",
    "\n",
    "    l = open(labels, \"r\")\n",
    "    # 5 klas: labels = [[2 if y=='#' else int(y)+2 for y in x.split()] for x in l.readlines()] \n",
    "\n",
    "    # Na ten moment przyjmujemy wartosc \"2\" w miejsce \"#\"\n",
    "\n",
    "    labels = [[int(y) for y in x.split()] for x in l.readlines()] \n",
    "    l.close()\n",
    "\n",
    "    p = open(parents,\"r\")\n",
    "    parents = [[int(y) for y in x.split()] for x in p.readlines()]\n",
    "    p.close()\n",
    "\n",
    "    t = open(tokens,\"r\")\n",
    "    tokens = [x.split() for x in t.readlines()]\n",
    "    t.close()\n",
    "    \n",
    "    r = open(rules,\"r\")\n",
    "    rules = [x.split() for x in r.readlines()]\n",
    "    r.close()\n",
    "    \n",
    "    k = 0\n",
    "    sentence_length = 0\n",
    "    current_batch, batch_tokens, batch_children_ids, batch_children_positions, batch_labels = [], [], [], [], []\n",
    "    batch_words = []\n",
    "    \n",
    "    for labels_i, parents_i, tokens_i, rules_i in zip(labels,parents,tokens,rules):\n",
    "        \n",
    "        k = k + 1\n",
    "         \n",
    "        s = []\n",
    "        for i in range(len(tokens_i)):\n",
    "            \n",
    "            if tokens_i[i] == \"__nonterminal__\":\n",
    "                token = \"__nonterminal__\"+rules_i[i]\n",
    "            else:\n",
    "                token = tokens_i[i]\n",
    "            \n",
    "            \n",
    "            s.append([i,int(parents_i[i]),labels_i[i],token])\n",
    "\n",
    "        if len(s) == 1 and use_batch == False: #przypadek gdy fraza sklada sie z jednego tokena\n",
    "\n",
    "            #if nb_classes == 2:\n",
    "            #    if s[0][-1] < 0:\n",
    "            #        continue\n",
    "\n",
    "            sentences.append([\\\n",
    "                                  np.array([words2ids.get(tokens[0], -1)]),\\\n",
    "                                  #wyrzucamy macierz id dzieci numpy.array([-1], ndmin=2),\\\n",
    "                                  np.array([-1], ndmin=2), \\\n",
    "                                  np.array(labels_i[0]) \\\n",
    "                                  #,numpy.array([0])\n",
    "                              ])    \n",
    "                                \n",
    "        else: \n",
    "\n",
    "            for i in range(len(s)): # nie wiem czy sie nie wywali dla frazy dlugosci 1\n",
    "                children = []\n",
    "                for j in range(len(s)):\n",
    "                    if s[j][1] == i+1:\n",
    "                        children.append(s[j][0])\n",
    "                s[i].append(children)\n",
    "\n",
    "            words = [x[0] for x in s]\n",
    "            children = seq.pad_sequences([x[4] for x in s], padding='post', value = -1)\n",
    "            tokens = [x[3] for x in s]\n",
    "            labels_in_batch = [x[2] for x in s]\n",
    "            \n",
    "            ordered_words, order = words_in_from_down_to_top_order(children)\n",
    "\n",
    "            if ordered_words is None: \n",
    "                continue\n",
    "\n",
    "            current_sentence = [\n",
    "                                  np.array([words2ids.get(x,-1) for x in tokens])[ordered_words],\n",
    "                                  #wyrzucamy macierz id dzieci numpy.array([[words2ids.get(tokens[w],-1) if w>=0 else -1 for w in x] \n",
    "                                  #             for x in children[ordered_words]]), \n",
    "                                  np.array([[order[w] if w>= 0 else -1 for w in x] for x in children[ordered_words]]), \n",
    "                                  np.array(labels_in_batch)[ordered_words] \n",
    "                                  ,np.array(words)\n",
    "                                  ]\n",
    "            #if nb_classes == 2:\n",
    "            #    if current_sentence[3][-1] <0:\n",
    "            #        continue\n",
    "\n",
    "            if use_batch == True:\n",
    "                \n",
    "                # w tej chwili len(current_sentence[0]) nie jest nigdzie wykorzystywane\n",
    "                current_batch.append((current_sentence, len(current_sentence[0])))\n",
    "                \n",
    "                if len(current_batch) % batch_size == 0:\n",
    "\n",
    "                    shift = 0\n",
    "                    \n",
    "                    for sent in range(batch_size):\n",
    "                        \n",
    "                        ##if sent > 0:\n",
    "                        ##    shift = shift + current_batch[sent-1][1]\n",
    "                        \n",
    "                        for tok in range(len(current_batch[sent][0][0])):\n",
    "                            \n",
    "                            if sent == 0:\n",
    "                                batch_children_positions.append(current_batch[sent][0][1][tok])\n",
    "                            else:\n",
    "                                batch_children_positions.append([chd+shift if chd>=0 else -1 for chd in current_batch[sent][0][1][tok]])\n",
    "                            #batch_children_positions.append(current_batch[sent][0][2][tok])\n",
    "\n",
    "                            batch_tokens.append(current_batch[sent][0][0][tok])   \n",
    "                            #wyrzucamy macierz id dzieci batch_children_ids.append(current_batch[sent][0][1][tok])\n",
    "                            batch_labels.append(current_batch[sent][0][2][tok])\n",
    "                            batch_words.append(current_batch[sent][0][3][tok])\n",
    "                                                               \n",
    "                    #wyrzucamy macierz id dzieci batch_children_ids = seq.pad_sequences(batch_children_ids, padding='post', value = -1)\n",
    "                    batch_children_positions = seq.pad_sequences(batch_children_positions, padding='post', value = -1)\n",
    "                    \n",
    "                    sentences.append([\n",
    "                                        np.array(batch_tokens), \n",
    "                                        #wyrzucamy macierz id dzieci numpy.array(batch_children_ids), \n",
    "                                        np.array(batch_children_positions), \n",
    "                                        np.array(batch_labels)\n",
    "                                        ,np.array(batch_words)\n",
    "                                    ])\n",
    "                    \n",
    "                    current_batch, batch_tokens, batch_children_positions, batch_labels = [], [], [], []\n",
    "                    batch_words = []\n",
    "                                       \n",
    "            else:\n",
    "                \n",
    "                sentences.append(current_sentence)\n",
    "\n",
    "            \n",
    "    # gdy liczba zdan nie jest wilokrotnosci licznosci batch, to na koncu trzeba dodac pozostale zdania:\n",
    "    if use_batch == True and len(current_batch) > 0:\n",
    "        \n",
    "        shift = 0\n",
    "\n",
    "        for sent in range(len(current_batch)):\n",
    " \n",
    "            #if sent > 0:\n",
    "            #    shift = shift + current_batch[sent-1][1]\n",
    "\n",
    "            for tok in range(len(current_batch[sent][0][0])):\n",
    "\n",
    "                if sent == 0:\n",
    "                    batch_children_positions.append(current_batch[sent][0][1][tok])\n",
    "                else:\n",
    "                    batch_children_positions.append([chd+shift if chd>=0 else -1 for chd in current_batch[sent][0][1][tok]])\n",
    "                #batch_children_positions.append(current_batch[sent][0][2][tok])\n",
    "\n",
    "                batch_tokens.append(current_batch[sent][0][0][tok])\n",
    "                #wyrzucamy macierz id dzieci batch_children_ids.append(current_batch[sent][0][1][tok])\n",
    "                batch_labels.append(current_batch[sent][0][2][tok])\n",
    "                batch_words.append(current_batch[sent][0][3][tok])\n",
    "\n",
    "\n",
    "        #wyrzucamy macierz id dzieci batch_children_ids = seq.pad_sequences(batch_children_ids, padding='post', value = -1)\n",
    "        batch_children_positions = seq.pad_sequences(batch_children_positions, padding='post', value = -1)\n",
    "\n",
    "        sentences.append([\n",
    "                            np.array(batch_tokens), \n",
    "                            #wyrzucamy macierz id dzieci numpy.array(batch_children_ids), \n",
    "                            np.array(batch_children_positions), \n",
    "                            np.array(batch_labels)\n",
    "                            ,np.array(batch_words)\n",
    "                        ])\n",
    "           \n",
    "    return sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLSTM(object):  \n",
    "\n",
    "    def __init__(self, h_dim, nc, w2v_model_path, file_with_rules, \n",
    "                 rules_emb_dim, max_phrase_length, emb_dropout_rate, h_dropout_rate, l, srng,\n",
    "                load_params=None): \n",
    "\n",
    "        '''\n",
    "\n",
    "        - dropout stanu ukrytego (LSTM_1)\n",
    "        - dropout embeddinga (LSTM_1)\n",
    "        - regularyzacja l2 (LSTM_1)\n",
    "        - indywidualna obsluga lisci - struktura taka sama, macierze te same, ale uczymy: h_aggregated_0, hidden_state_0, cell_state_0, zamiast brac w te miejsca 0\n",
    "\n",
    "\n",
    "        nh :: dimension of hidden state\n",
    "        nc :: number of classes\n",
    "        '''\n",
    "\n",
    "        self.max_phrase_length = max_phrase_length\n",
    "\n",
    "        w2vecs = pickle.load(open(w2v_model_path,\"rb\"))\n",
    "        self.emb = theano.shared(w2vecs[\"vectors\"].astype(theano.config.floatX))\n",
    "        self.words2ids = w2vecs[\"words2ids\"]\n",
    "\n",
    "        emb_dim = w2vecs[\"vectors\"].shape[1]\n",
    "        del w2vecs\n",
    "\n",
    "        \n",
    "        r = open(file_with_rules,\"r\")\n",
    "        rules = [x.split() for x in r.readlines()]\n",
    "        r.close()\n",
    "        unique_rules = set()\n",
    "        for i in range(len(rules)):\n",
    "            for j in range(len(rules[i])):\n",
    "                unique_rules.add(rules[i][j])\n",
    "                \n",
    "        number_of_uniue_rules = len(unique_rules)\n",
    " \n",
    "        r = 0.05\n",
    "\n",
    "        self.rules2ids = dict(zip(unique_rules,range(number_of_uniue_rules)))\n",
    "        self.emb_rules = theano.shared(r * np.random.uniform(-1,1,(number_of_uniue_rules, rules_emb_dim)).astype(theano.config.floatX))\n",
    "        \n",
    "   \n",
    "\n",
    "        self.W_i = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_i = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_i = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_f = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_f = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_f = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_o = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_o = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_o = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_u = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_u = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_u = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_y   = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, nc)).astype(theano.config.floatX))\n",
    "        self.b_y   = theano.shared(r * np.random.uniform(-1.0, 1.0, nc).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "        self.h_aggregated_0 = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "        self.cell_state_0 = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "        self.hidden_state_0 = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "\n",
    "        self.srng = srng\n",
    "        self.h_dropout_rate = h_dropout_rate\n",
    "        self.emb_dropout_rate = emb_dropout_rate\n",
    "        self.l = l\n",
    "\n",
    "\n",
    "        if load_params:\n",
    "            for key in load_params.keys():\n",
    "                if key not in ['emb', 'emb_rules', 'W_i', 'U_i', 'b_i', 'W_f', 'U_f', 'b_f', 'W_o', 'U_o', 'b_o', 'W_u', 'U_u', 'b_u', 'W_y', 'b_y', 'h_aggregated_0', 'cell_state_0', 'hidden_state_0']:\n",
    "                    setattr(self, key, load_params[key])\n",
    "                else:\n",
    "                    setattr(self, key, theano.shared(load_params[key]))\n",
    "        \n",
    "        \n",
    "\n",
    "        def one_step(word_id, rule_id, word_children_positions, y_true, k, hidden_states, cell_states, learning_rate):\n",
    "\n",
    "            x = T.concatenate( [self.emb[word_id], self.emb_rules[rule_id] ])\n",
    "\n",
    "            #dropout:\n",
    "            mask1 = self.srng.binomial(n=1, p=1-self.emb_dropout_rate, size=(emb_dim+rules_emb_dim,), dtype='floatX')\n",
    "            x = x * mask1\n",
    "\n",
    "\n",
    "            tmp = word_children_positions>=0.0\n",
    "            number_of_children = tmp.sum(dtype = theano.config.floatX) \n",
    "            idx_tmp = tmp.nonzero()                                                                   # indeksy realne dzieci - czyli te, gdzie nie ma -1        \n",
    "\n",
    "            h_aggregated = ifelse(T.gt(number_of_children, 0.0), hidden_states[word_children_positions[idx_tmp]].sum(axis=0), self.h_aggregated_0)\n",
    "\n",
    "\n",
    "            i = T.nnet.sigmoid(\tT.dot(x, self.W_i) + T.dot(h_aggregated, self.U_i) + self.b_i)             \n",
    "\n",
    "            o = T.nnet.sigmoid(\tT.dot(x, self.W_o) + T.dot(h_aggregated, self.U_o) + self.b_o)             \n",
    "\n",
    "            u = T.tanh(\tT.dot(x, self.W_u) + T.dot(h_aggregated, self.U_u) + self.b_u)             \n",
    "\n",
    "            f_c = ifelse(T.gt(number_of_children, 0.0), \n",
    "                (T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(hidden_states[word_children_positions[idx_tmp]], self.U_f)  + self.b_f )*cell_states[word_children_positions[idx_tmp]]).sum(axis=0),\n",
    "                T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(self.hidden_state_0, self.U_f)  + self.b_f ) * self.cell_state_0\n",
    "            )\n",
    "\n",
    "            c = i*u + f_c\n",
    "\n",
    "            h = o * T.tanh(c)\n",
    "            #dropout:\n",
    "            mask = self.srng.binomial(n=1, p=1-self.h_dropout_rate, size=(h_dim,), dtype='floatX')\n",
    "            h = h * mask\n",
    "\n",
    "\n",
    "            current_cell_state = cell_states[k]\n",
    "            cell_states_new = T.set_subtensor(current_cell_state, c)\n",
    "\n",
    "            current_hidden_state = hidden_states[k]\n",
    "            hidden_states_new = T.set_subtensor(current_hidden_state, h)\n",
    "\n",
    "\n",
    "            y_prob = T.nnet.softmax(T.dot(h,self.W_y) + self.b_y)[0]\n",
    "\n",
    "            cross_entropy = -T.log(y_prob[y_true])\t\t\t\t\t\t       # + norm_coefficient * l2_norm\n",
    "\n",
    "            return cross_entropy, hidden_states_new, cell_states_new  \n",
    "\n",
    "\n",
    "        y = T.vector('y',dtype=dataType)\n",
    "        learning_rate = T.scalar('lr',dtype=theano.config.floatX)\n",
    "        words = T.vector(dtype=dataType)\n",
    "        rules = T.vector(dtype=dataType)\n",
    "        children_positions = T.matrix(dtype=dataType)\n",
    "        words_indexes = T.vector(dtype=dataType)\n",
    "\n",
    "        [cross_entropy_vector, _, _] , _ = theano.scan(fn=one_step, \\\n",
    "                                 sequences = [words, rules, children_positions,y,words_indexes],\n",
    "                                 outputs_info = [None, \n",
    "                                     theano.shared(np.zeros((self.max_phrase_length+1,h_dim), dtype = theano.config.floatX)),\n",
    "                                     theano.shared(np.zeros((self.max_phrase_length+1,h_dim), dtype = theano.config.floatX))],\n",
    "                                 non_sequences = learning_rate,\n",
    "                                 n_steps = words.shape[0])\n",
    "\n",
    "        cost = T.mean(cross_entropy_vector) + self.l * (self.emb_rules**2).sum() #*0.5 * self.l * ((self.W_i**2).sum()+(self.W_f**2).sum()+(self.W_o**2).sum()+(self.W_u**2).sum()+(self.W_y**2).sum()+(self.U_i**2).sum()+(self.U_f**2).sum()+(self.U_o**2).sum()+(self.U_u**2).sum())\n",
    "\n",
    "        updates = OrderedDict([\n",
    "            (self.W_i, self.W_i-learning_rate*T.grad(cost, self.W_i)),\n",
    "            (self.W_f, self.W_f-learning_rate*T.grad(cost, self.W_f)),\n",
    "            (self.W_o, self.W_o-learning_rate*T.grad(cost, self.W_o)),\n",
    "            (self.W_u, self.W_u-learning_rate*T.grad(cost, self.W_u)),\n",
    "            (self.W_y, self.W_y-learning_rate*T.grad(cost, self.W_y)),\n",
    "\n",
    "            (self.U_i, self.U_i-learning_rate*T.grad(cost, self.U_i)),\n",
    "            (self.U_f, self.U_f-learning_rate*T.grad(cost, self.U_f)),\n",
    "            (self.U_o, self.U_o-learning_rate*T.grad(cost, self.U_o)),\n",
    "            (self.U_u, self.U_u-learning_rate*T.grad(cost, self.U_u)),\n",
    "\n",
    "            #(self.emb, self.emb-learning_rate*T.grad(cost, self.emb)), #SPROBOWAC TU 0.1 ZAMIAST LR, A DLA POLSKICH BEZ AKTUALIZACJI EMB\n",
    "            (self.emb_rules, self.emb_rules-learning_rate*T.grad(cost, self.emb_rules)),\n",
    "            (self.b_i, self.b_i-learning_rate*T.grad(cost,self.b_i)),\n",
    "                        (self.b_f, self.b_f-learning_rate*T.grad(cost,self.b_f)),\n",
    "                        (self.b_o, self.b_o-learning_rate*T.grad(cost,self.b_o)),\n",
    "                        (self.b_u, self.b_u-learning_rate*T.grad(cost,self.b_u)),\n",
    "                        (self.b_y, self.b_y-learning_rate*T.grad(cost,self.b_y)),\n",
    "\n",
    "            (self.h_aggregated_0, self.h_aggregated_0-learning_rate*T.grad(cost,self.h_aggregated_0)),\n",
    "            (self.cell_state_0, self.cell_state_0-learning_rate*T.grad(cost,self.cell_state_0)),\n",
    "            (self.hidden_state_0, self.hidden_state_0-learning_rate*T.grad(cost,self.hidden_state_0))\n",
    "\n",
    "            ])\n",
    "\n",
    "        self.train = theano.function( inputs  = [words, rules, children_positions, y, words_indexes, learning_rate],\n",
    "                                      outputs = [],\n",
    "                                      updates = updates,\n",
    "                                      allow_input_downcast=True,\n",
    "                                      mode='FAST_RUN'\n",
    "                                      )\n",
    "\n",
    "\n",
    "        def one_step_classify(word_id, rule_id, word_children_positions, k, hidden_states, cell_states):\n",
    "\n",
    "            x = T.concatenate( [self.emb[word_id], self.emb_rules[rule_id] ])\n",
    "\n",
    "            x = (1-self.emb_dropout_rate) * x\n",
    "\n",
    "            tmp = word_children_positions>=0.0\n",
    "            number_of_children = tmp.sum(dtype = theano.config.floatX) \n",
    "            idx_tmp = tmp.nonzero()                                                                   # indeksy realne dzieci - czyli te, gdzie nie ma -1        \n",
    "\n",
    "            h_aggregated = ifelse(T.gt(number_of_children, 0.0), hidden_states[word_children_positions[idx_tmp]].sum(axis=0), self.h_aggregated_0)\n",
    "\n",
    "            i = T.nnet.sigmoid(\tT.dot(x, self.W_i) + T.dot(h_aggregated, self.U_i) + self.b_i)             \n",
    "\n",
    "            o = T.nnet.sigmoid(\tT.dot(x, self.W_o) + T.dot(h_aggregated, self.U_o) + self.b_o)             \n",
    "\n",
    "            u = T.tanh(\tT.dot(x, self.W_u) + T.dot(h_aggregated, self.U_u) + self.b_u)             \n",
    "\n",
    "            f_c = ifelse(T.gt(number_of_children, 0.0), \n",
    "                (T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(hidden_states[word_children_positions[idx_tmp]], self.U_f)  + self.b_f )*cell_states[word_children_positions[idx_tmp]]).sum(axis=0),\n",
    "                T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(self.hidden_state_0, self.U_f)  + self.b_f ) * self.cell_state_0\n",
    "            )\n",
    "\n",
    "            c = i*u + f_c\n",
    "\n",
    "            h = o * T.tanh(c)\n",
    "            # podczas uczenia zerowalismy 1-dropout_rate procent wspolrzednych, wiec trzeba to \n",
    "            h = h * (1-self.h_dropout_rate)\n",
    "\n",
    "            current_cell_state = cell_states[k]\n",
    "            cell_states_new = T.set_subtensor(current_cell_state, c)\n",
    "\n",
    "            current_hidden_state = hidden_states[k]\n",
    "            hidden_states_new = T.set_subtensor(current_hidden_state, h)\n",
    "\n",
    "\n",
    "            y_prob = T.nnet.softmax(T.dot(h,self.W_y) + self.b_y)[0]             \n",
    "\n",
    "            return  y_prob, hidden_states_new, cell_states_new\n",
    "\n",
    "\n",
    "        [y_probs_classify, _ , _ ], _ = theano.scan(\n",
    "                 fn=one_step_classify, \n",
    "                                 sequences = [words, rules, children_positions, words_indexes],\n",
    "                 outputs_info = [None,\n",
    "                         theano.shared(np.zeros((self.max_phrase_length+1,h_dim), dtype = theano.config.floatX)),\n",
    "                         theano.shared(np.zeros((self.max_phrase_length+1,h_dim), dtype = theano.config.floatX))])\n",
    "\n",
    "        predictions, _ = theano.scan(lambda i: T.argmax(y_probs_classify[i]), \n",
    "                                     sequences = [words_indexes])\n",
    "        \n",
    "        probs, _ = theano.scan(lambda i: y_probs_classify[i], \n",
    "                                     sequences = [words_indexes])\n",
    "\n",
    "        self.classify = theano.function(inputs=[words, rules, children_positions,words_indexes], \n",
    "                                     outputs=predictions,\n",
    "                                     allow_input_downcast=True,\n",
    "                                     mode='FAST_RUN' \n",
    "                                     )\n",
    "\n",
    "        self.predict_proba = theano.function(inputs=[words, rules, children_positions,words_indexes], \n",
    "                             outputs=probs,\n",
    "                             allow_input_downcast=True,\n",
    "                             mode='FAST_RUN' \n",
    "                             )\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "s = {'lr':0.05,\n",
    "         'nepochs':80,\n",
    "         'seed':345,\n",
    "         'nc':2,        # number of y classes\n",
    "         'h_dim': 100,\n",
    "         'h_dropout_rate': 0.5,\n",
    "         'emb_dropout_rate': 0.5,\n",
    "         'time_without_improvement': 10,\n",
    "         'batch_size': 1,\n",
    "         'w2v_DIM': \"300\",\n",
    "         \"rules_emb_dim\": 30\n",
    "         }  \n",
    "\n",
    "dataType = 'int64'\n",
    "  \n",
    "np.random.seed(s['seed']) \n",
    "\n",
    "\n",
    "\n",
    "#ile_with_filtered_embeddings = \"embeddings/filtered_nkjp+wiki-forms-restricted-300-cbow-ns.pkl\"\n",
    "\n",
    "#2vecs = pickle.load(open(file_with_filtered_embeddings,\"rb\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0 = load_stanford_data4(\"Data/labels.txt\", \"Data/parents.txt\",\"Data/tokens.txt\",\"Data/rules.txt\",w2vecs[\"words2ids\"],True,s['batch_size'],s['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import  csv\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from keras.preprocessing import sequence as seq\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:131: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:224: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    }
   ],
   "source": [
    "rnn = TreeLSTM( h_dim = s['h_dim'],\n",
    "            nc = s['nc'],\n",
    "        w2v_model_path = \"embeddings/filtered_w2v_allwiki_nkjpfull_300.pkl\",\n",
    "            max_phrase_length = 60,\n",
    "        emb_dropout_rate = s['emb_dropout_rate'],\n",
    "        h_dropout_rate = s['h_dropout_rate'],\n",
    "        l = 0.0001,\n",
    "        srng = RandomStreams(12345),\n",
    "        file_with_rules =  \"Data/rules.txt\",\n",
    "        rules_emb_dim = s[\"rules_emb_dim\"],\n",
    "        load_params= params\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rules = load_stanford_data4(\"Data/labels.txt\", \"Data/parents.txt\",\"Data/rules.txt\",\"Data/rules.txt\",rnn.rules2ids,True,s['batch_size'],s['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([127, 127,  18, 127,  47,  18,  29,  60, 127, 127,  18,  29, 127,\n",
       "        127,  60, 127,   5,  95,  18,  29,  58,  38,  78,  10,  42,  48,\n",
       "         48,  43,  80,  48,  39,  41]), array([[-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [ 1,  0, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [ 4,  3,  2, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [ 6,  5, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [ 9,  8,  7, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [11, 10, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [13, 12, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [15, 14, -1, -1],\n",
       "        [17, 16, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [19, 18, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [22, 21, 20, -1],\n",
       "        [24, 23, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [28, 27, 26, 25],\n",
       "        [-1, -1, -1, -1],\n",
       "        [30, 29, -1, -1]], dtype=int32), array([1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 1, 1, 1, 1, 1, 1, 1]), array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "        17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31])]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_rules[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rules = [x[0] for x in data_rules]\n",
    "\n",
    "data = [data0[i]+[data_rules[i]] for i in range(len(data0))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "71919"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = data[:40000]\n",
    "test_data = data[50000:]\n",
    "\n",
    "n_train = len(train_data)\n",
    "n_test = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40000"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "21919"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valid:  43.70 Valid root:  78.62  Test all:  43.34 Test root:  77.52    time:  0\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  80.75 Valid root:  86.81  Test all:  80.52 Test root:  86.10    time:  1659.1358036994934\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.01 Valid root:  88.29  Test all:  80.52 Test root:  87.07    time:  1650.8659930229187\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.26 Valid root:  89.09  Test all:  80.85 Test root:  87.91    time:  1652.8346195220947\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.63 Valid root:  89.16  Test all:  81.10 Test root:  87.99    time:  1650.6778011322021\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.70 Valid root:  89.71  Test all:  81.03 Test root:  88.21    time:  1647.353580713272\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.03 Valid root:  88.39  Test all:  80.50 Test root:  87.01    time:  1648.3011331558228\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.73 Valid root:  89.55  Test all:  80.96 Test root:  88.09    time:  1653.1562235355377\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.07 Valid root:  88.02  Test all:  80.31 Test root:  86.33    time:  1647.6487095355988\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.20 Valid root:  90.00  Test all:  81.29 Test root:  88.57    time:  1644.4925801753998\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.93 Valid root:  89.80  Test all:  81.17 Test root:  88.69    time:  1644.567925453186\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  81.92 Valid root:  89.98  Test all:  81.08 Test root:  88.32    time:  1649.4043600559235\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.09 Valid root:  90.20  Test all:  81.24 Test root:  88.37    time:  1645.771966457367\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.37 Valid root:  90.52  Test all:  81.40 Test root:  89.20    time:  1651.0886347293854\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.46 Valid root:  90.42  Test all:  81.58 Test root:  89.33    time:  1645.562195301056\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.48 Valid root:  90.78  Test all:  81.52 Test root:  89.17    time:  1645.3329231739044\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.46 Valid root:  90.65  Test all:  81.55 Test root:  89.07    time:  1645.4172048568726\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.26 Valid root:  90.49  Test all:  81.32 Test root:  89.47    time:  1648.1544635295868\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.41 Valid root:  90.92  Test all:  81.33 Test root:  89.38    time:  1710.798448085785\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.79 Valid root:  90.88  Test all:  81.70 Test root:  89.52    time:  1665.4968893527985\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.82 Valid root:  90.90  Test all:  81.63 Test root:  89.74    time:  1685.3213849067688\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-40-64330de43bad>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     37\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 39\u001b[0;31m         \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'lr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "for i in range(n_test):\n",
    "    pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "    for j in range(len(pred)):\n",
    "        counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "    counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "# Train\n",
    "counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "for i in range(len(train_data)):\n",
    "\n",
    "    pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "    for j in range(len(pred)):\n",
    "        counts[pred[j], train_data[i][2][j]] += 1\n",
    "    counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "    \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "    \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "    \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "    \"   time: \", 0)\n",
    "\n",
    "for e in range(1,50):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        rnn.train(train_data[i][0], train_data[i][4], train_data[i][1], train_data[i][2], train_data[i][3], s['lr'])\n",
    "\n",
    "   \n",
    "    counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(n_test):\n",
    "        pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "        counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "    # Train\n",
    "    counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(len(train_data)):\n",
    "\n",
    "        pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts[pred[j], train_data[i][2][j]] += 1\n",
    "        counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "        \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "        \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "        \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "        \"   time: \", time.time()-tic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.72 Valid root:  90.61  Test all:  81.64 Test root:  89.00    time:  1682.2205669879913 20\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.26 Valid root:  90.12  Test all:  81.22 Test root:  89.04    time:  1679.8865728378296 21\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.88 Valid root:  91.32  Test all:  81.78 Test root:  89.88    time:  1668.9164516925812 22\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.73 Valid root:  90.97  Test all:  81.52 Test root:  89.49    time:  1676.463739156723 23\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.83 Valid root:  91.30  Test all:  81.67 Test root:  89.94    time:  1667.9074738025665 24\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.92 Valid root:  91.30  Test all:  81.56 Test root:  89.61    time:  1681.1698541641235 25\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.00 Valid root:  91.36  Test all:  81.86 Test root:  89.89    time:  1671.6738905906677 26\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.11 Valid root:  91.47  Test all:  81.84 Test root:  89.67    time:  1666.0784938335419 27\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.14 Valid root:  91.52  Test all:  81.91 Test root:  90.18    time:  1671.40784740448 28\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.19 Valid root:  91.40  Test all:  81.77 Test root:  89.56    time:  1672.548271894455 29\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.30 Valid root:  91.58  Test all:  81.89 Test root:  90.00    time:  1673.6871211528778 30\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.95 Valid root:  91.28  Test all:  81.57 Test root:  89.92    time:  1674.316910982132 31\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  82.14 Valid root:  90.56  Test all:  80.86 Test root:  88.58    time:  1707.2288656234741 32\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.19 Valid root:  91.55  Test all:  81.77 Test root:  89.83    time:  1783.0885350704193 33\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.27 Valid root:  91.77  Test all:  81.88 Test root:  90.10    time:  1791.6920557022095 34\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.48 Valid root:  91.81  Test all:  82.01 Test root:  90.26    time:  1711.1713535785675 35\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.45 Valid root:  91.96  Test all:  82.00 Test root:  90.28    time:  1656.136815071106 36\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.56 Valid root:  91.81  Test all:  81.98 Test root:  90.01    time:  1656.019334077835 37\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.34 Valid root:  91.84  Test all:  81.77 Test root:  89.80    time:  1653.8657777309418 38\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.45 Valid root:  91.69  Test all:  82.05 Test root:  90.28    time:  1660.9149532318115 39\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.58 Valid root:  92.03  Test all:  82.03 Test root:  90.27    time:  1663.1954391002655 40\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.73 Valid root:  92.23  Test all:  82.14 Test root:  90.36    time:  1676.7091012001038 41\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.65 Valid root:  92.11  Test all:  82.06 Test root:  90.22    time:  1658.364329814911 42\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.36 Valid root:  91.58  Test all:  81.75 Test root:  89.61    time:  1655.1553382873535 43\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.55 Valid root:  91.88  Test all:  82.07 Test root:  90.37    time:  1651.874804019928 44\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.61 Valid root:  92.21  Test all:  82.09 Test root:  90.33    time:  1669.8985872268677 45\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.64 Valid root:  92.13  Test all:  81.95 Test root:  90.31    time:  1664.3495316505432 46\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.82 Valid root:  92.25  Test all:  82.15 Test root:  90.41    time:  1662.6986932754517 47\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.68 Valid root:  92.16  Test all:  82.02 Test root:  90.18    time:  1669.355253458023 48\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.84 Valid root:  92.36  Test all:  82.17 Test root:  90.45    time:  1664.6061971187592 49\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(50,150):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        rnn.train(train_data[i][0], train_data[i][4], train_data[i][1], train_data[i][2], train_data[i][3], 0.08)\n",
    "\n",
    "   \n",
    "    counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(n_test):\n",
    "        pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "        counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "    # Train\n",
    "    counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(len(train_data)):\n",
    "\n",
    "        pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts[pred[j], train_data[i][2][j]] += 1\n",
    "        counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "        \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "        \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "        \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "        \"   time: \", time.time()-tic, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.16 Valid root:  92.05  Test all:  81.66 Test root:  90.01    time:  1708.4119176864624 50\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.35 Valid root:  91.52  Test all:  81.65 Test root:  89.20    time:  1687.8758857250214 51\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.89 Valid root:  92.42  Test all:  82.13 Test root:  90.50    time:  1681.8958320617676 52\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.70 Valid root:  91.95  Test all:  82.13 Test root:  90.36    time:  1678.2370755672455 53\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.83 Valid root:  92.36  Test all:  82.12 Test root:  90.60    time:  1686.0400075912476 54\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.22 Valid root:  91.41  Test all:  81.40 Test root:  89.14    time:  1686.2209434509277 55\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.89 Valid root:  92.56  Test all:  81.98 Test root:  90.52    time:  1686.366648197174 56\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.68 Valid root:  92.25  Test all:  81.73 Test root:  89.94    time:  1688.5155863761902 57\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.99 Valid root:  92.41  Test all:  81.98 Test root:  90.33    time:  1687.6200289726257 58\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.72 Valid root:  92.40  Test all:  81.91 Test root:  90.08    time:  1681.586306810379 59\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.78 Valid root:  92.64  Test all:  82.01 Test root:  90.44    time:  1685.203265428543 60\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.10 Valid root:  92.77  Test all:  82.26 Test root:  90.59    time:  1687.3663494586945 61\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.80 Valid root:  92.46  Test all:  82.02 Test root:  90.38    time:  1686.1377389431 62\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.11 Valid root:  92.79  Test all:  82.31 Test root:  90.94    time:  1687.8322486877441 63\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.69 Valid root:  91.98  Test all:  81.77 Test root:  89.64    time:  1688.552395105362 64\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.97 Valid root:  92.81  Test all:  82.14 Test root:  90.82    time:  1682.6746304035187 65\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-43-4dd6e3430034>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    959\u001b[0m         \u001b[0mallow_gc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mallow_gc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    960\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 961\u001b[0;31m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[0m\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[1;32m    963\u001b[0m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(50,150):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        rnn.train(train_data[i][0], train_data[i][4], train_data[i][1], train_data[i][2], train_data[i][3], 0.1)\n",
    "\n",
    "   \n",
    "    counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(n_test):\n",
    "        pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "        counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "    # Train\n",
    "    counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(len(train_data)):\n",
    "\n",
    "        pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts[pred[j], train_data[i][2][j]] += 1\n",
    "        counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "        \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "        \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "        \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "        \"   time: \", time.time()-tic, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.24 Valid root:  92.82  Test all:  82.35 Test root:  90.43    time:  1708.090693950653 65\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.30 Valid root:  92.93  Test all:  82.33 Test root:  90.55    time:  1723.167875289917 66\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.25 Valid root:  92.81  Test all:  82.34 Test root:  90.53    time:  1718.3800265789032 67\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.29 Valid root:  92.97  Test all:  82.39 Test root:  90.78    time:  1723.3628902435303 68\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.31 Valid root:  92.95  Test all:  82.36 Test root:  90.71    time:  1721.8407082557678 69\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.27 Valid root:  93.07  Test all:  82.31 Test root:  90.83    time:  1711.331344127655 70\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.31 Valid root:  92.99  Test all:  82.33 Test root:  91.04    time:  1700.9491574764252 71\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.43 Valid root:  93.08  Test all:  82.40 Test root:  90.89    time:  1706.2167041301727 72\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.43 Valid root:  93.19  Test all:  82.34 Test root:  90.85    time:  1737.337217092514 73\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.37 Valid root:  93.06  Test all:  82.20 Test root:  90.77    time:  1779.5004189014435 74\n",
      "0\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-bc470d13e261>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.02\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/norbert/.theano/compiledir_Linux-4.13--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-3.6.3-64/scan_perform/mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(65,150):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        rnn.train(train_data[i][0], train_data[i][4], train_data[i][1], train_data[i][2], train_data[i][3], 0.02)\n",
    "\n",
    "   \n",
    "    counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(n_test):\n",
    "        pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "        counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "    # Train\n",
    "    counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(len(train_data)):\n",
    "\n",
    "        pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts[pred[j], train_data[i][2][j]] += 1\n",
    "        counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "        \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "        \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "        \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "        \"   time: \", time.time()-tic, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.41 Valid root:  93.01  Test all:  82.31 Test root:  90.75    time:  3064.566673517227 75\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.47 Valid root:  93.05  Test all:  82.36 Test root:  90.81    time:  1842.47593998909 76\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.44 Valid root:  93.09  Test all:  82.33 Test root:  90.76    time:  1736.1911389827728 77\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.42 Valid root:  93.06  Test all:  82.30 Test root:  90.73    time:  1715.9373154640198 78\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.48 Valid root:  93.11  Test all:  82.37 Test root:  90.89    time:  1713.4552013874054 79\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.48 Valid root:  93.11  Test all:  82.38 Test root:  90.86    time:  1719.0515496730804 80\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.43 Valid root:  93.08  Test all:  82.33 Test root:  90.75    time:  1723.5333609580994 81\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.44 Valid root:  93.07  Test all:  82.33 Test root:  90.76    time:  1707.033807516098 82\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-45-23ac4bc073e2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.001\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mrval\u001b[0;34m(p, i, o, n, allow_gc)\u001b[0m\n\u001b[1;32m    961\u001b[0m         def rval(p=p, i=node_input_storage, o=node_output_storage, n=node,\n\u001b[1;32m    962\u001b[0m                  allow_gc=allow_gc):\n\u001b[0;32m--> 963\u001b[0;31m             \u001b[0mr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    964\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    965\u001b[0m                 \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mo\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/scan_module/scan_op.py\u001b[0m in \u001b[0;36mp\u001b[0;34m(node, args, outs)\u001b[0m\n\u001b[1;32m    950\u001b[0m                                                 \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    951\u001b[0m                                                 \u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 952\u001b[0;31m                                                 self, node)\n\u001b[0m\u001b[1;32m    953\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mImportError\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtheano\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMissingGXX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    954\u001b[0m             \u001b[0mp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexecute\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mtheano/scan_module/scan_perform.pyx\u001b[0m in \u001b[0;36mtheano.scan_module.scan_perform.perform (/home/norbert/.theano/compiledir_Linux-4.13--generic-x86_64-with-Ubuntu-16.04-xenial-x86_64-3.6.3-64/scan_perform/mod.cpp:4490)\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/ifelse.py\u001b[0m in \u001b[0;36mthunk\u001b[0;34m()\u001b[0m\n\u001b[1;32m    243\u001b[0m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnode\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    244\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 245\u001b[0;31m         \u001b[0;32mdef\u001b[0m \u001b[0mthunk\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    246\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mcompute_map\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcond\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    247\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(75,150):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        rnn.train(train_data[i][0], train_data[i][4], train_data[i][1], train_data[i][2], train_data[i][3], 0.001)\n",
    "\n",
    "   \n",
    "    counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(n_test):\n",
    "        pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "        counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "    # Train\n",
    "    counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(len(train_data)):\n",
    "\n",
    "        pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts[pred[j], train_data[i][2][j]] += 1\n",
    "        counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "        \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "        \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "        \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "        \"   time: \", time.time()-tic, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.07 Valid root:  92.63  Test all:  82.13 Test root:  90.75    time:  1746.3360106945038 83\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.27 Valid root:  93.14  Test all:  82.29 Test root:  90.87    time:  1714.6816112995148 84\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.50 Valid root:  92.27  Test all:  81.74 Test root:  89.87    time:  1707.3038737773895 85\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.90 Valid root:  92.94  Test all:  82.11 Test root:  90.81    time:  1707.6317405700684 86\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.17 Valid root:  92.87  Test all:  82.31 Test root:  90.61    time:  1708.3425064086914 87\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.00 Valid root:  92.35  Test all:  81.92 Test root:  89.89    time:  1827.8167462348938 88\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.20 Valid root:  92.97  Test all:  82.14 Test root:  90.66    time:  1819.4957435131073 89\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.21 Valid root:  92.86  Test all:  82.18 Test root:  90.76    time:  1744.7963435649872 90\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.06 Valid root:  92.94  Test all:  82.03 Test root:  90.54    time:  1842.9916467666626 91\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.34 Valid root:  93.06  Test all:  82.38 Test root:  91.04    time:  1809.8672935962677 92\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.99 Valid root:  92.77  Test all:  82.00 Test root:  90.18    time:  1805.488248348236 93\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.19 Valid root:  93.08  Test all:  82.17 Test root:  90.81    time:  1804.4499099254608 94\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.04 Valid root:  93.00  Test all:  82.02 Test root:  90.80    time:  1806.7987110614777 95\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.21 Valid root:  92.70  Test all:  81.96 Test root:  90.40    time:  1807.8743574619293 96\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.10 Valid root:  93.13  Test all:  82.22 Test root:  90.83    time:  1809.3630051612854 97\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  83.55 Valid root:  92.73  Test all:  81.75 Test root:  90.26    time:  1809.4206411838531 98\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.12 Valid root:  92.99  Test all:  82.30 Test root:  90.73    time:  1806.9215610027313 99\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.03 Valid root:  92.81  Test all:  82.04 Test root:  90.43    time:  1806.7354440689087 100\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.39 Valid root:  93.34  Test all:  82.29 Test root:  90.89    time:  1809.348989725113 101\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.27 Valid root:  93.33  Test all:  82.18 Test root:  90.74    time:  1810.0142290592194 102\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.31 Valid root:  93.16  Test all:  82.28 Test root:  91.01    time:  1808.6143045425415 103\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.46 Valid root:  93.25  Test all:  82.32 Test root:  90.96    time:  1815.3555896282196 104\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.49 Valid root:  93.30  Test all:  82.36 Test root:  90.94    time:  1813.554625749588 105\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.32 Valid root:  93.41  Test all:  82.27 Test root:  90.91    time:  1816.284182548523 106\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.36 Valid root:  93.27  Test all:  82.16 Test root:  90.59    time:  1818.9609198570251 107\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.44 Valid root:  93.05  Test all:  82.24 Test root:  90.56    time:  1817.1633369922638 108\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.55 Valid root:  93.46  Test all:  82.36 Test root:  91.05    time:  1813.0342752933502 109\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.35 Valid root:  93.06  Test all:  82.19 Test root:  91.06    time:  1816.6018750667572 110\n",
      "0\n",
      "5000\n",
      "10000\n",
      "15000\n",
      "20000\n",
      "25000\n",
      "30000\n",
      "35000\n",
      "Valid:  84.49 Valid root:  93.51  Test all:  82.34 Test root:  91.19    time:  1815.5821998119354 111\n",
      "0\n",
      "5000\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-0538b23069d1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m             \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m         \u001b[0mrnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/theano/compile/function_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    901\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 903\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0moutput_subset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    904\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0moutput_subset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    905\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "for e in range(83,150):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        rnn.train(train_data[i][0], train_data[i][4], train_data[i][1], train_data[i][2], train_data[i][3], 0.1)\n",
    "\n",
    "   \n",
    "    counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_test_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(n_test):\n",
    "        pred = rnn.classify(test_data[i][0],test_data[i][4],test_data[i][1], test_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts_test[pred[j], test_data[i][2][j]] += 1\n",
    "        counts_test_root[pred[-1], test_data[i][2][-1]] += 1\n",
    "\n",
    "    # Train\n",
    "    counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    counts_root = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "    for i in range(len(train_data)):\n",
    "\n",
    "        pred  = rnn.classify(train_data[i][0], train_data[i][4] ,train_data[i][1], train_data[i][3])\n",
    "        for j in range(len(pred)):\n",
    "            counts[pred[j], train_data[i][2][j]] += 1\n",
    "        counts_root[pred[-1], train_data[i][2][-1]] += 1\n",
    "\n",
    "\n",
    "\n",
    "    print(\"Valid: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "        \"Valid root: \",\"%0.2f\" % (100 * np.diag(counts_root).sum()/float(counts_root.sum())),\n",
    "        \" Test all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "        \"Test root: \",\"%0.2f\" % (100 * np.diag(counts_test_root).sum()/float(counts_test_root.sum())), \n",
    "        \"   time: \", time.time()-tic, e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = [ (k, v.get_value())  if type(v)==theano.tensor.sharedvar.TensorSharedVariable else (k,v) for k, v in list(rnn.__dict__.items())]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(params,open(\"model_params.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = dict(pickle.load(open(\"model_params.pkl\",\"rb\")))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "data0_test = load_stanford_data4(\"Data/test2/labels.txt\", \"Data/test2/parents.txt\",\"Data/test2/tokens.txt\",\"Data/test2/rules.txt\",w2vecs[\"words2ids\"],True,s['batch_size'],s['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rules_test = load_stanford_data4(\"Data/test2/labels.txt\", \"Data/test2/parents.txt\",\"Data/test2/rules.txt\",\"Data/test2/rules.txt\",rnn.rules2ids,True,s['batch_size'],s['nc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_rules_test = [x[0] for x in data_rules_test]\n",
    "\n",
    "data_test = [data0_test[i]+[data_rules_test[i]] for i in range(len(data0_test))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "probs = []\n",
    "for i in range(len(data_test)):\n",
    "    pred = rnn.predict_proba(data_test[i][0],data_test[i][4],data_test[i][1], data_test[i][3])[-1][1]\n",
    "    probs.append(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2001"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.13334687,\n",
       " 8.3888835e-06,\n",
       " 0.0010396587,\n",
       " 4.6200694e-06,\n",
       " 5.0813065e-05,\n",
       " 1.4710424e-06,\n",
       " 2.0261099e-05,\n",
       " 3.289847e-06,\n",
       " 1.4634319e-06,\n",
       " 0.00012172688,\n",
       " 1.8303084e-06,\n",
       " 2.3695316e-05,\n",
       " 0.01863916,\n",
       " 1.8796135e-06,\n",
       " 4.4952594e-05,\n",
       " 1.7312494e-06,\n",
       " 2.489804e-05,\n",
       " 1.3020557e-05,\n",
       " 3.1925803e-05,\n",
       " 5.429791e-05,\n",
       " 4.196077e-05,\n",
       " 4.1475494e-05,\n",
       " 5.76528e-06,\n",
       " 8.790873e-07,\n",
       " 2.6987232e-06,\n",
       " 0.0002899247,\n",
       " 0.05050147,\n",
       " 1.1784717e-06,\n",
       " 0.0003152298,\n",
       " 7.109902e-05,\n",
       " 0.0001983568,\n",
       " 0.00057133636,\n",
       " 7.724816e-06,\n",
       " 0.00014834244,\n",
       " 9.692103e-06,\n",
       " 0.0033503277,\n",
       " 3.992597e-06,\n",
       " 5.3168696e-05,\n",
       " 0.000117437805,\n",
       " 1.6004777e-05,\n",
       " 6.539057e-05,\n",
       " 2.1992926e-05,\n",
       " 1.0912242e-05,\n",
       " 7.6280994e-05,\n",
       " 5.2460364e-06,\n",
       " 7.3081595e-05,\n",
       " 8.144737e-05,\n",
       " 1.4397174e-05,\n",
       " 6.1822852e-06,\n",
       " 1.658785e-05,\n",
       " 1.2030981e-05,\n",
       " 9.312199e-06,\n",
       " 0.00019822389,\n",
       " 0.0052587115,\n",
       " 0.00081432826,\n",
       " 3.5629741e-06,\n",
       " 9.307351e-06,\n",
       " 0.00015510345,\n",
       " 1.0968949e-05,\n",
       " 7.030539e-06,\n",
       " 5.0074805e-06,\n",
       " 6.1453115e-06,\n",
       " 2.8228587e-06,\n",
       " 3.7486498e-06,\n",
       " 1.4301316e-05,\n",
       " 1.3266325e-06,\n",
       " 1.0730317e-05,\n",
       " 1.6594464e-05,\n",
       " 1.6735402e-06,\n",
       " 8.700291e-06,\n",
       " 2.6172813e-05,\n",
       " 0.00013051779,\n",
       " 8.084965e-06,\n",
       " 5.483554e-05,\n",
       " 1.2153797e-05,\n",
       " 1.3478629e-05,\n",
       " 1.932376e-06,\n",
       " 7.001671e-05,\n",
       " 9.302408e-06,\n",
       " 0.0062965816,\n",
       " 9.907748e-07,\n",
       " 1.6036396e-06,\n",
       " 6.2852614e-06,\n",
       " 0.000251852,\n",
       " 2.4793171e-05,\n",
       " 1.6088623e-05,\n",
       " 4.0713954e-07,\n",
       " 1.5990033e-06,\n",
       " 4.385126e-05,\n",
       " 6.9087764e-05,\n",
       " 3.204094e-05,\n",
       " 3.0822373e-06,\n",
       " 6.434213e-06,\n",
       " 5.4155185e-05,\n",
       " 7.715648e-05,\n",
       " 1.4065533e-05,\n",
       " 8.094841e-05,\n",
       " 8.452274e-06,\n",
       " 7.803256e-07,\n",
       " 0.00017794677,\n",
       " 4.8403913e-06,\n",
       " 0.00086278614,\n",
       " 6.712194e-05,\n",
       " 0.025859497,\n",
       " 3.067306e-06,\n",
       " 1.0328978e-05,\n",
       " 9.930138e-07,\n",
       " 1.5877768e-06,\n",
       " 1.2383073e-05,\n",
       " 5.152706e-06,\n",
       " 1.3909213e-05,\n",
       " 0.00056928245,\n",
       " 1.4472916e-05,\n",
       " 1.8795397e-05,\n",
       " 4.0774985e-06,\n",
       " 3.9316405e-05,\n",
       " 7.961795e-05,\n",
       " 4.9726646e-06,\n",
       " 4.6472774e-06,\n",
       " 0.00022784575,\n",
       " 2.5461875e-06,\n",
       " 7.9791316e-05,\n",
       " 2.64324e-05,\n",
       " 3.0270642e-06,\n",
       " 5.5246524e-05,\n",
       " 1.4181959e-06,\n",
       " 8.800043e-06,\n",
       " 4.6235204e-05,\n",
       " 2.6652819e-05,\n",
       " 8.18751e-06,\n",
       " 6.140613e-06,\n",
       " 1.2444029e-05,\n",
       " 7.742724e-06,\n",
       " 4.656771e-06,\n",
       " 1.5624986e-05,\n",
       " 5.479629e-06,\n",
       " 9.704977e-06,\n",
       " 9.346909e-05,\n",
       " 8.183965e-06,\n",
       " 1.0706991e-05,\n",
       " 1.0857568e-05,\n",
       " 9.228014e-05,\n",
       " 9.073281e-06,\n",
       " 6.8863174e-06,\n",
       " 3.832817e-06,\n",
       " 0.00013432815,\n",
       " 9.424707e-06,\n",
       " 1.7967954e-05,\n",
       " 3.615448e-05,\n",
       " 5.6692927e-05,\n",
       " 0.00017307086,\n",
       " 2.3469115e-06,\n",
       " 1.4772135e-05,\n",
       " 1.3371289e-05,\n",
       " 0.000141575,\n",
       " 3.5007477e-06,\n",
       " 1.7365808e-05,\n",
       " 1.19442e-05,\n",
       " 8.308707e-05,\n",
       " 1.2075616e-05,\n",
       " 2.315082e-05,\n",
       " 1.1145954e-06,\n",
       " 4.7141988e-05,\n",
       " 4.2044765e-05,\n",
       " 3.5627736e-06,\n",
       " 2.2375503e-05,\n",
       " 1.9250027e-05,\n",
       " 2.0105356e-06,\n",
       " 1.4457631e-05,\n",
       " 6.2511044e-06,\n",
       " 2.3186822e-06,\n",
       " 0.00018604082,\n",
       " 3.7417885e-06,\n",
       " 2.5372567e-05,\n",
       " 1.955376e-06,\n",
       " 7.771931e-06,\n",
       " 0.019495666,\n",
       " 1.1378954e-05,\n",
       " 3.293336e-05,\n",
       " 2.1107396e-06,\n",
       " 1.4635417e-05,\n",
       " 5.125115e-05,\n",
       " 9.7943675e-06,\n",
       " 3.785751e-06,\n",
       " 1.31206e-05,\n",
       " 2.2820206e-05,\n",
       " 2.0814767e-05,\n",
       " 3.3805503e-05,\n",
       " 2.6959706e-06,\n",
       " 0.0005181706,\n",
       " 5.2847167e-06,\n",
       " 9.662417e-05,\n",
       " 3.560783e-06,\n",
       " 8.953381e-06,\n",
       " 9.034935e-06,\n",
       " 7.288778e-06,\n",
       " 0.00042016065,\n",
       " 2.8668841e-05,\n",
       " 9.7999175e-05,\n",
       " 0.002829116,\n",
       " 8.211196e-06,\n",
       " 9.822167e-06,\n",
       " 8.787312e-06,\n",
       " 2.3354196e-06,\n",
       " 6.3001567e-06,\n",
       " 5.3690797e-05,\n",
       " 1.5218998e-05,\n",
       " 3.876917e-05,\n",
       " 6.853912e-06,\n",
       " 5.0535837e-06,\n",
       " 2.0550546e-05,\n",
       " 1.5924043e-05,\n",
       " 1.532789e-05,\n",
       " 1.4400456e-05,\n",
       " 3.825165e-05,\n",
       " 7.0193914e-06,\n",
       " 0.00014046405,\n",
       " 7.718349e-05,\n",
       " 4.48689e-06,\n",
       " 1.8762194e-05,\n",
       " 9.627431e-05,\n",
       " 6.0569305e-06,\n",
       " 2.107386e-05,\n",
       " 5.913103e-06,\n",
       " 3.5850912e-06,\n",
       " 0.0016458663,\n",
       " 2.5142253e-06,\n",
       " 1.0782994e-05,\n",
       " 5.166837e-05,\n",
       " 1.9547311e-05,\n",
       " 1.1447011e-05,\n",
       " 6.272734e-06,\n",
       " 0.0001826703,\n",
       " 8.144079e-06,\n",
       " 7.4821687e-06,\n",
       " 3.0552515e-06,\n",
       " 1.2106057e-05,\n",
       " 4.0265622e-05,\n",
       " 1.8122171e-06,\n",
       " 8.475073e-05,\n",
       " 0.00020921935,\n",
       " 1.3235717e-05,\n",
       " 1.43279085e-05,\n",
       " 2.6418852e-06,\n",
       " 5.0170078e-05,\n",
       " 0.00013212372,\n",
       " 0.0004856708,\n",
       " 0.00011975081,\n",
       " 3.410176e-06,\n",
       " 2.9618293e-05,\n",
       " 3.9040237e-06,\n",
       " 2.393912e-05,\n",
       " 7.6968725e-05,\n",
       " 1.0965351e-05,\n",
       " 2.5917952e-05,\n",
       " 7.0230555e-05,\n",
       " 0.00043710225,\n",
       " 3.8155486e-06,\n",
       " 0.000104274855,\n",
       " 1.3998998e-05,\n",
       " 1.6201884e-05,\n",
       " 1.5043358e-05,\n",
       " 1.914724e-05,\n",
       " 5.6697468e-06,\n",
       " 4.791963e-06,\n",
       " 2.2797778e-05,\n",
       " 4.4781103e-05,\n",
       " 1.0429324e-05,\n",
       " 7.657062e-05,\n",
       " 6.5218633e-06,\n",
       " 1.6637294e-05,\n",
       " 4.6944724e-06,\n",
       " 1.692348e-05,\n",
       " 2.5159068e-06,\n",
       " 1.825818e-05,\n",
       " 0.00011265903,\n",
       " 9.1778446e-07,\n",
       " 1.7059245e-06,\n",
       " 4.686721e-05,\n",
       " 2.1771331e-05,\n",
       " 3.3448682e-06,\n",
       " 3.6438723e-06,\n",
       " 2.897359e-06,\n",
       " 1.349625e-05,\n",
       " 9.326142e-06,\n",
       " 2.990472e-05,\n",
       " 1.4576163e-05,\n",
       " 4.2881143e-06,\n",
       " 0.00011429456,\n",
       " 8.869891e-06,\n",
       " 1.0214543e-05,\n",
       " 1.2246082e-05,\n",
       " 8.489082e-05,\n",
       " 6.7775513e-06,\n",
       " 0.00015151016,\n",
       " 0.0009065243,\n",
       " 8.750866e-07,\n",
       " 5.8979414e-05,\n",
       " 7.5480074e-07,\n",
       " 1.7089358e-05,\n",
       " 2.5002519e-05,\n",
       " 2.7020271e-06,\n",
       " 8.0956823e-07,\n",
       " 1.5537495e-05,\n",
       " 5.517355e-05,\n",
       " 1.0205723e-06,\n",
       " 7.140607e-05,\n",
       " 4.9769774e-06,\n",
       " 0.00025494225,\n",
       " 2.0126497e-06,\n",
       " 4.1262083e-06,\n",
       " 8.259886e-05,\n",
       " 9.577233e-06,\n",
       " 2.1718035e-06,\n",
       " 1.4211028e-05,\n",
       " 5.262402e-06,\n",
       " 1.9105617e-05,\n",
       " 9.729152e-05,\n",
       " 2.1270864e-05,\n",
       " 2.6139114e-05,\n",
       " 2.125451e-06,\n",
       " 2.203857e-05,\n",
       " 7.445051e-05,\n",
       " 0.00010750937,\n",
       " 3.6008623e-05,\n",
       " 1.644444e-05,\n",
       " 1.70516e-06,\n",
       " 0.0006819584,\n",
       " 8.0066624e-05,\n",
       " 4.8302325e-05,\n",
       " 0.00012514656,\n",
       " 8.980334e-05,\n",
       " 1.7438115e-05,\n",
       " 2.30134e-05,\n",
       " 3.8563672e-07,\n",
       " 8.980334e-05,\n",
       " 4.186648e-06,\n",
       " 5.6416784e-06,\n",
       " 7.4404143e-06,\n",
       " 6.809518e-06,\n",
       " 1.1592689e-06,\n",
       " 5.133655e-06,\n",
       " 9.87498e-06,\n",
       " 5.682262e-06,\n",
       " 1.1222409e-06,\n",
       " 6.7061286e-05,\n",
       " 0.000101118945,\n",
       " 1.93201e-05,\n",
       " 3.6352685e-05,\n",
       " 5.8089663e-05,\n",
       " 4.087949e-06,\n",
       " 2.4650184e-05,\n",
       " 7.4704467e-06,\n",
       " 0.000106999636,\n",
       " 8.163979e-06,\n",
       " 1.2710573e-05,\n",
       " 2.3053817e-05,\n",
       " 2.3905037e-05,\n",
       " 3.4968068e-06,\n",
       " 5.306949e-06,\n",
       " 0.0014869247,\n",
       " 1.073906e-05,\n",
       " 9.872371e-06,\n",
       " 1.0964933e-05,\n",
       " 2.813444e-06,\n",
       " 4.813352e-06,\n",
       " 4.2762063e-06,\n",
       " 1.0298623e-05,\n",
       " 1.7016146e-05,\n",
       " 4.366944e-05,\n",
       " 4.5821885e-06,\n",
       " 1.6650341e-05,\n",
       " 1.6054812e-05,\n",
       " 4.0324626e-06,\n",
       " 0.00011197082,\n",
       " 1.8755738e-06,\n",
       " 4.3696627e-06,\n",
       " 4.856694e-05,\n",
       " 8.699017e-05,\n",
       " 2.5033843e-05,\n",
       " 6.660178e-05,\n",
       " 1.00209445e-05,\n",
       " 2.984754e-05,\n",
       " 4.998177e-06,\n",
       " 0.0026496374,\n",
       " 3.9157285e-06,\n",
       " 4.9968778e-05,\n",
       " 1.4953219e-05,\n",
       " 7.076191e-05,\n",
       " 4.52246e-06,\n",
       " 3.5537878e-06,\n",
       " 9.206717e-05,\n",
       " 2.2202437e-05,\n",
       " 2.7792012e-05,\n",
       " 4.2879634e-05,\n",
       " 1.2444029e-05,\n",
       " 1.8647655e-05,\n",
       " 5.0834074e-06,\n",
       " 1.7597187e-05,\n",
       " 0.0007897245,\n",
       " 3.7027057e-06,\n",
       " 1.2254704e-05,\n",
       " 2.4375951e-05,\n",
       " 2.8233e-05,\n",
       " 1.8417986e-05,\n",
       " 2.7104872e-05,\n",
       " 1.2514245e-05,\n",
       " 3.951166e-06,\n",
       " 5.3248955e-06,\n",
       " 5.872405e-06,\n",
       " 2.1154128e-06,\n",
       " 3.4936702e-06,\n",
       " 2.4917328e-05,\n",
       " 2.7392225e-06,\n",
       " 0.0001609692,\n",
       " 5.5195338e-05,\n",
       " 5.4286243e-06,\n",
       " 8.062413e-06,\n",
       " 8.21172e-06,\n",
       " 2.6618645e-06,\n",
       " 5.737083e-06,\n",
       " 9.122554e-06,\n",
       " 8.7805586e-07,\n",
       " 9.780014e-05,\n",
       " 1.1540829e-05,\n",
       " 5.0349668e-06,\n",
       " 8.960275e-06,\n",
       " 2.8234615e-05,\n",
       " 0.0005757781,\n",
       " 2.8806171e-05,\n",
       " 2.2362715e-06,\n",
       " 2.1584592e-05,\n",
       " 2.0734824e-06,\n",
       " 1.9951896e-05,\n",
       " 4.5948e-06,\n",
       " 9.780014e-05,\n",
       " 3.9627243e-06,\n",
       " 2.199666e-05,\n",
       " 4.3125897e-06,\n",
       " 7.3870906e-06,\n",
       " 3.807122e-05,\n",
       " 0.00037188726,\n",
       " 1.34824595e-05,\n",
       " 9.71433e-06,\n",
       " 2.0311632e-05,\n",
       " 4.8452407e-06,\n",
       " 2.242006e-05,\n",
       " 4.544046e-06,\n",
       " 0.00016705865,\n",
       " 8.6759866e-07,\n",
       " 7.0949136e-05,\n",
       " 0.00015158141,\n",
       " 2.2461556e-05,\n",
       " 3.0029694e-05,\n",
       " 5.479943e-06,\n",
       " 5.714057e-06,\n",
       " 6.7145616e-06,\n",
       " 1.1957384e-06,\n",
       " 3.397777e-05,\n",
       " 7.704804e-06,\n",
       " 9.447487e-05,\n",
       " 0.00016936859,\n",
       " 3.1149611e-06,\n",
       " 1.7840748e-05,\n",
       " 5.814592e-05,\n",
       " 2.223386e-05,\n",
       " 4.3598766e-06,\n",
       " 1.1456513e-05,\n",
       " 2.9709468e-05,\n",
       " 1.5108483e-06,\n",
       " 2.9116713e-06,\n",
       " 0.00011181588,\n",
       " 9.236527e-05,\n",
       " 1.8820242e-06,\n",
       " 7.780319e-05,\n",
       " 1.0485302e-05,\n",
       " 9.9295416e-05,\n",
       " 2.7354627e-05,\n",
       " 0.007163331,\n",
       " 9.551957e-06,\n",
       " 0.00045539252,\n",
       " 3.9292813e-06,\n",
       " 4.02845e-06,\n",
       " 0.00029718934,\n",
       " 5.349153e-06,\n",
       " 6.716074e-05,\n",
       " 4.375648e-05,\n",
       " 6.5934314e-06,\n",
       " 5.1660104e-06,\n",
       " 8.069051e-06,\n",
       " 9.3607537e-07,\n",
       " 5.03967e-05,\n",
       " 0.0001299655,\n",
       " 8.493655e-06,\n",
       " 1.9533298e-05,\n",
       " 0.0002817492,\n",
       " 2.990472e-05,\n",
       " 8.789211e-05,\n",
       " 2.3186003e-06,\n",
       " 2.1870239e-05,\n",
       " 0.0001826797,\n",
       " 6.3137313e-06,\n",
       " 1.8597024e-05,\n",
       " 1.7408936e-05,\n",
       " 5.423524e-05,\n",
       " 5.224279e-06,\n",
       " 3.4964867e-06,\n",
       " 0.00015679417,\n",
       " 2.3770639e-05,\n",
       " 2.9096784e-06,\n",
       " 1.9246687e-05,\n",
       " 5.9796043e-06,\n",
       " 2.000593e-05,\n",
       " 2.1389147e-05,\n",
       " 1.8476021e-06,\n",
       " 0.00736165,\n",
       " 1.1138539e-05,\n",
       " 3.4098062e-05,\n",
       " 1.2211341e-05,\n",
       " 9.4473966e-05,\n",
       " 0.001027711,\n",
       " 7.792949e-05,\n",
       " 2.5923886e-05,\n",
       " 6.4194232e-06,\n",
       " 0.00010887542,\n",
       " 3.17661e-06,\n",
       " 1.9880386e-05,\n",
       " 0.00012601269,\n",
       " 1.5373857e-06,\n",
       " 2.2772812e-05,\n",
       " 5.8760917e-05,\n",
       " 4.549243e-05,\n",
       " 2.3907727e-05,\n",
       " 4.5141824e-06,\n",
       " 5.834235e-06,\n",
       " 4.609081e-06,\n",
       " 1.5095723e-06,\n",
       " 0.0027053477,\n",
       " 0.021328993,\n",
       " 1.0111759e-06,\n",
       " 7.4628566e-05,\n",
       " 0.00040242155,\n",
       " 5.4574857e-06,\n",
       " 4.553106e-05,\n",
       " 2.6829232e-06,\n",
       " 7.8897145e-05,\n",
       " 5.565878e-05,\n",
       " 0.00013912334,\n",
       " 0.0001380765,\n",
       " 8.80236e-06,\n",
       " 3.0661115e-05,\n",
       " 4.2398526e-05,\n",
       " 2.1361466e-05,\n",
       " 6.543325e-05,\n",
       " 8.888198e-06,\n",
       " 6.9291896e-06,\n",
       " 3.0174317e-06,\n",
       " 8.9439945e-06,\n",
       " 0.00024813213,\n",
       " 6.595893e-05,\n",
       " 3.0275896e-06,\n",
       " 3.754074e-05,\n",
       " 7.241659e-07,\n",
       " 2.6910745e-06,\n",
       " 9.815781e-06,\n",
       " 2.1627655e-05,\n",
       " 2.297544e-05,\n",
       " 9.790605e-05,\n",
       " 2.213435e-06,\n",
       " 5.1302586e-06,\n",
       " 1.3781349e-05,\n",
       " 8.489832e-06,\n",
       " 0.0004626695,\n",
       " 0.00017450689,\n",
       " 0.00035161254,\n",
       " 1.8044514e-06,\n",
       " 2.2272037e-05,\n",
       " 1.0605145e-05,\n",
       " 9.2552983e-07,\n",
       " 3.3700865e-06,\n",
       " 0.00015853415,\n",
       " 2.0202351e-05,\n",
       " 9.490341e-05,\n",
       " 3.1940895e-06,\n",
       " 2.6005993e-05,\n",
       " 1.2178266e-06,\n",
       " 5.736919e-06,\n",
       " 4.4790618e-06,\n",
       " 1.5490004e-06,\n",
       " 4.601403e-07,\n",
       " 3.316339e-06,\n",
       " 2.7185201e-06,\n",
       " 5.696764e-05,\n",
       " 1.9749605e-06,\n",
       " 0.000101116246,\n",
       " 1.6568279e-06,\n",
       " 4.09895e-06,\n",
       " 5.3011972e-06,\n",
       " 3.4078756e-05,\n",
       " 2.5811569e-05,\n",
       " 5.566998e-05,\n",
       " 2.1845935e-06,\n",
       " 2.1261626e-06,\n",
       " 1.3475389e-05,\n",
       " 1.7501925e-05,\n",
       " 9.4031634e-07,\n",
       " 7.5071844e-06,\n",
       " 0.0031265572,\n",
       " 2.7936137e-06,\n",
       " 1.9207807e-06,\n",
       " 2.876447e-05,\n",
       " 6.084663e-06,\n",
       " 3.9376014e-06,\n",
       " 0.00018654583,\n",
       " 3.4031066e-06,\n",
       " 1.7102207e-05,\n",
       " 4.2190848e-05,\n",
       " 0.00069706846,\n",
       " 1.2960398e-05,\n",
       " 1.2545722e-06,\n",
       " 6.1412984e-06,\n",
       " 1.2681738e-06,\n",
       " 2.8250158e-06,\n",
       " 2.6618798e-06,\n",
       " 6.5323584e-06,\n",
       " 8.264026e-06,\n",
       " 9.250708e-06,\n",
       " 0.00040266715,\n",
       " 3.0538933e-05,\n",
       " 4.510013e-06,\n",
       " 2.27888e-06,\n",
       " 3.42307e-05,\n",
       " 0.00042016065,\n",
       " 1.0025598e-05,\n",
       " 0.00018604082,\n",
       " 4.446491e-06,\n",
       " 5.5866647e-05,\n",
       " 2.085389e-06,\n",
       " 7.1248134e-05,\n",
       " 5.8743653e-06,\n",
       " 6.191679e-06,\n",
       " 9.00148e-06,\n",
       " 1.2517551e-05,\n",
       " 2.701414e-05,\n",
       " 6.656511e-06,\n",
       " 0.00013065651,\n",
       " 6.246653e-06,\n",
       " 1.4466584e-06,\n",
       " 1.9327576e-06,\n",
       " 2.7225906e-05,\n",
       " 6.928642e-05,\n",
       " 3.2736963e-05,\n",
       " 8.220622e-06,\n",
       " 5.272484e-06,\n",
       " 6.023216e-06,\n",
       " 2.6398897e-05,\n",
       " 7.3705286e-07,\n",
       " 7.6540106e-05,\n",
       " 1.4585803e-06,\n",
       " 4.348275e-06,\n",
       " 3.090085e-05,\n",
       " 5.518881e-05,\n",
       " 2.2430153e-05,\n",
       " 1.4157584e-05,\n",
       " 1.0408293e-06,\n",
       " 3.4644196e-05,\n",
       " 2.2514505e-05,\n",
       " 8.512185e-05,\n",
       " 5.226109e-05,\n",
       " 8.707679e-06,\n",
       " 1.04390665e-05,\n",
       " 1.9877264e-06,\n",
       " 5.280354e-06,\n",
       " 8.353456e-07,\n",
       " 8.981241e-05,\n",
       " 0.00028205774,\n",
       " 0.0003669399,\n",
       " 0.00016847129,\n",
       " 0.0025393846,\n",
       " 1.3520395e-06,\n",
       " 1.1799106e-05,\n",
       " 2.25702e-06,\n",
       " 6.416424e-06,\n",
       " 1.4827914e-05,\n",
       " 4.0602903e-05,\n",
       " 6.2307954e-05,\n",
       " 9.241669e-06,\n",
       " 2.7177477e-06,\n",
       " 8.382177e-05,\n",
       " 1.7236006e-06,\n",
       " 6.089766e-05,\n",
       " 2.742081e-05,\n",
       " 1.5803678e-05,\n",
       " 0.0001567281,\n",
       " 5.4180186e-05,\n",
       " 0.00014225201,\n",
       " 6.747189e-06,\n",
       " 3.0181252e-05,\n",
       " 2.4152891e-06,\n",
       " 0.00011391364,\n",
       " 9.174588e-06,\n",
       " 2.6808113e-05,\n",
       " 1.4913443e-05,\n",
       " 1.8320843e-06,\n",
       " 0.009730916,\n",
       " 4.388314e-05,\n",
       " 3.017196e-05,\n",
       " 1.5389158e-05,\n",
       " 4.309465e-06,\n",
       " 1.9652358e-05,\n",
       " 6.645119e-06,\n",
       " 0.0010857955,\n",
       " 0.0003509282,\n",
       " 8.2555394e-05,\n",
       " 5.2045092e-05,\n",
       " 7.646059e-05,\n",
       " 5.2563373e-05,\n",
       " 7.637054e-07,\n",
       " 1.4977367e-05,\n",
       " 1.6405453e-05,\n",
       " 4.1544713e-06,\n",
       " 6.0754896e-06,\n",
       " 1.98056e-05,\n",
       " 1.48280415e-05,\n",
       " 6.5106283e-06,\n",
       " 8.9783825e-06,\n",
       " 8.425933e-05,\n",
       " 2.3349185e-06,\n",
       " 1.423615e-05,\n",
       " 4.003166e-06,\n",
       " 9.3513645e-06,\n",
       " 3.3506726e-06,\n",
       " 9.2721435e-05,\n",
       " 3.0391835e-05,\n",
       " 1.2466135e-05,\n",
       " 5.423284e-06,\n",
       " 4.4516073e-06,\n",
       " 0.0027848976,\n",
       " 0.00028770094,\n",
       " 8.894651e-06,\n",
       " 1.0594339e-05,\n",
       " 0.017302357,\n",
       " 3.118002e-05,\n",
       " 0.00020156382,\n",
       " 3.9165858e-05,\n",
       " 1.0257368e-05,\n",
       " 4.61171e-06,\n",
       " 5.300275e-05,\n",
       " 1.3253224e-05,\n",
       " 0.00035122375,\n",
       " 2.2078371e-05,\n",
       " 2.413233e-06,\n",
       " 9.568744e-05,\n",
       " 1.4074724e-05,\n",
       " 1.7926926e-05,\n",
       " 0.000120884564,\n",
       " 7.3525393e-06,\n",
       " 1.9658355e-06,\n",
       " 1.4710424e-06,\n",
       " 2.6964517e-05,\n",
       " 1.7839115e-05,\n",
       " 9.457914e-06,\n",
       " 5.5454915e-05,\n",
       " 1.1926786e-05,\n",
       " 1.1410608e-05,\n",
       " 1.2014078e-06,\n",
       " 1.0676199e-05,\n",
       " 2.1725704e-05,\n",
       " 0.00010614923,\n",
       " 5.003442e-06,\n",
       " 0.00014848326,\n",
       " 5.0813065e-05,\n",
       " 4.0624777e-06,\n",
       " 7.8904144e-05,\n",
       " 0.00026887117,\n",
       " 1.4501016e-05,\n",
       " 6.0265298e-05,\n",
       " 3.1030515e-05,\n",
       " 1.9079662e-06,\n",
       " 5.368634e-05,\n",
       " 3.8483475e-05,\n",
       " 0.00012460821,\n",
       " 5.5232385e-06,\n",
       " 6.192494e-06,\n",
       " 1.8488464e-06,\n",
       " 2.4603236e-05,\n",
       " 2.1006841e-05,\n",
       " 3.0452238e-05,\n",
       " 1.6429642e-05,\n",
       " 5.340111e-06,\n",
       " 5.0663166e-05,\n",
       " 6.47655e-06,\n",
       " 0.00036218567,\n",
       " 9.157962e-06,\n",
       " 3.3707995e-05,\n",
       " 4.054695e-05,\n",
       " 2.9939249e-05,\n",
       " 3.0463223e-06,\n",
       " 5.572527e-05,\n",
       " 6.218663e-06,\n",
       " 9.75338e-07,\n",
       " 2.3285334e-05,\n",
       " 1.05989875e-05,\n",
       " 6.4387415e-05,\n",
       " 1.3743477e-06,\n",
       " 5.333404e-05,\n",
       " 0.00031107696,\n",
       " 0.00028007638,\n",
       " 6.83132e-06,\n",
       " 1.3027537e-05,\n",
       " 3.0419846e-05,\n",
       " 0.00027717452,\n",
       " 1.3599494e-05,\n",
       " 4.1387443e-06,\n",
       " 8.1388294e-05,\n",
       " 1.3282592e-05,\n",
       " 2.2312504e-06,\n",
       " 4.8825814e-06,\n",
       " 9.80274e-05,\n",
       " 1.45443655e-05,\n",
       " 7.1772756e-06,\n",
       " 2.7708904e-06,\n",
       " 3.5061385e-05,\n",
       " 0.0001166731,\n",
       " 1.3941558e-06,\n",
       " 2.9142661e-06,\n",
       " 2.1130692e-05,\n",
       " 1.8949675e-05,\n",
       " 0.00019465179,\n",
       " 4.4454137e-06,\n",
       " 3.21946e-06,\n",
       " 2.6203113e-06,\n",
       " 0.0003530853,\n",
       " 2.7110404e-05,\n",
       " 1.5365459e-06,\n",
       " 6.959607e-06,\n",
       " 6.735989e-05,\n",
       " 4.3831856e-06,\n",
       " 3.709536e-05,\n",
       " 5.0717696e-05,\n",
       " 8.722766e-05,\n",
       " 8.976722e-06,\n",
       " 2.9718422e-05,\n",
       " 5.9985152e-05,\n",
       " 9.34434e-06,\n",
       " 3.945315e-06,\n",
       " 1.0893828e-05,\n",
       " 1.7173039e-05,\n",
       " 0.00031629787,\n",
       " 7.851344e-06,\n",
       " 5.532691e-06,\n",
       " 2.3890907e-05,\n",
       " 0.023069428,\n",
       " 1.508315e-05,\n",
       " 9.934155e-06,\n",
       " 1.2497443e-06,\n",
       " 0.00010404076,\n",
       " 7.808236e-07,\n",
       " 0.00015186018,\n",
       " 2.9985797e-05,\n",
       " 6.4422304e-05,\n",
       " 0.00048927474,\n",
       " 2.899103e-06,\n",
       " 0.0001347858,\n",
       " 3.8066064e-05,\n",
       " 4.5989083e-05,\n",
       " 1.1077034e-05,\n",
       " 2.852845e-06,\n",
       " 0.000108047905,\n",
       " 3.361679e-05,\n",
       " 5.37875e-05,\n",
       " 8.450791e-06,\n",
       " 3.9260676e-06,\n",
       " 6.998403e-06,\n",
       " 0.00014539364,\n",
       " 0.0001758448,\n",
       " 9.902497e-06,\n",
       " 8.0879425e-07,\n",
       " 2.3622666e-05,\n",
       " 1.7645435e-06,\n",
       " 9.2171405e-07,\n",
       " 0.00036218567,\n",
       " 0.00020504325,\n",
       " 8.272668e-06,\n",
       " 2.7890408e-05,\n",
       " 0.00092524383,\n",
       " 1.8557765e-05,\n",
       " 1.6222984e-06,\n",
       " 1.36572135e-05,\n",
       " 5.0621446e-05,\n",
       " 3.4775749e-06,\n",
       " 1.8309473e-06,\n",
       " 8.1923856e-05,\n",
       " 4.9128204e-07,\n",
       " 3.0838485e-06,\n",
       " 4.2484107e-06,\n",
       " 0.0015397912,\n",
       " 1.490128e-06,\n",
       " 1.1370687e-05,\n",
       " 0.00014389251,\n",
       " 7.990011e-06,\n",
       " 2.7974663e-06,\n",
       " 2.0410818e-05,\n",
       " 2.8510065e-06,\n",
       " 6.7146702e-06,\n",
       " 5.628589e-05,\n",
       " 3.842025e-06,\n",
       " 6.013171e-05,\n",
       " 3.1934742e-06,\n",
       " 2.9957664e-06,\n",
       " 0.00014394561,\n",
       " 6.020224e-06,\n",
       " 2.8244795e-05,\n",
       " 3.0264115e-05,\n",
       " 0.000105416504,\n",
       " 1.306557e-06,\n",
       " 5.09857e-06,\n",
       " 5.871353e-05,\n",
       " 0.000104710394,\n",
       " 3.232776e-06,\n",
       " 0.00012080252,\n",
       " 2.7258744e-05,\n",
       " 1.8093039e-06,\n",
       " 0.00025897298,\n",
       " 3.1544184e-06,\n",
       " 4.781404e-06,\n",
       " 9.206717e-05,\n",
       " 6.817635e-05,\n",
       " 4.7444246e-05,\n",
       " 7.001971e-05,\n",
       " 1.4850104e-05,\n",
       " 6.6135335e-06,\n",
       " 6.824861e-06,\n",
       " 3.250598e-05,\n",
       " 1.7272901e-05,\n",
       " 8.714551e-05,\n",
       " 5.8659234e-06,\n",
       " 1.0008919e-05,\n",
       " 1.1812594e-05,\n",
       " 1.0548076e-05,\n",
       " 1.963089e-05,\n",
       " 0.020645004,\n",
       " 0.00036318717,\n",
       " 4.9729965e-06,\n",
       " 6.294865e-06,\n",
       " 3.2437763e-06,\n",
       " 1.2605816e-05,\n",
       " 1.8492115e-05,\n",
       " 5.8495166e-06,\n",
       " 0.003928794,\n",
       " 3.3796412e-05,\n",
       " 8.826434e-06,\n",
       " 2.4773715e-06,\n",
       " 8.537353e-06,\n",
       " 3.1224892e-05,\n",
       " 1.5535719e-06,\n",
       " 4.2710595e-05,\n",
       " 4.9998805e-05,\n",
       " 3.5659416e-06,\n",
       " 3.262511e-05,\n",
       " 5.768151e-05,\n",
       " 1.0912804e-05,\n",
       " 3.8974954e-06,\n",
       " 2.045072e-05,\n",
       " 9.323794e-06,\n",
       " 6.8878544e-06,\n",
       " 4.4965022e-06,\n",
       " 1.2529398e-05,\n",
       " 9.276168e-05,\n",
       " 2.480071e-06,\n",
       " 5.4343545e-05,\n",
       " 7.5586495e-06,\n",
       " 0.0001027102,\n",
       " 3.6485566e-05,\n",
       " 3.8281352e-05,\n",
       " 1.9538697e-06,\n",
       " 0.0015004635,\n",
       " 0.00013127117,\n",
       " 1.6294231e-06,\n",
       " 2.7989847e-06,\n",
       " 3.1965435e-05,\n",
       " 3.6608282e-05,\n",
       " 2.9036744e-05,\n",
       " 1.5435737e-05,\n",
       " 2.3780885e-06,\n",
       " 6.7869136e-05,\n",
       " 0.00018598036,\n",
       " 1.7876853e-05,\n",
       " 1.1221446e-05,\n",
       " 6.4779642e-06,\n",
       " 9.140625e-07,\n",
       " 0.00040546054,\n",
       " 6.53115e-06,\n",
       " 4.3611867e-06,\n",
       " 2.390727e-05,\n",
       " 3.5735702e-05,\n",
       " 2.57067e-05,\n",
       " 7.385765e-05,\n",
       " 0.00040841068,\n",
       " 1.2879645e-05,\n",
       " ...]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "f1 = pickle.load(open(\"f1_2.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.0,\n",
       " 0.75,\n",
       " 0.849056603773585,\n",
       " 0.7177033492822966,\n",
       " 0.75,\n",
       " 0.7081339712918661,\n",
       " 0.7707317073170732,\n",
       " 0.6570048309178744,\n",
       " 0.7203791469194313,\n",
       " 0.75,\n",
       " 0.6255924170616113,\n",
       " 0.8115942028985507,\n",
       " 0.8909952606635071,\n",
       " 0.7867298578199053,\n",
       " 0.6540284360189573,\n",
       " 0.7169811320754716,\n",
       " 0.6826923076923077,\n",
       " 0.7677725118483413,\n",
       " 0.6729857819905213,\n",
       " 0.8058252427184467,\n",
       " 0.7246376811594204,\n",
       " 0.7692307692307694,\n",
       " 0.6923076923076923,\n",
       " 0.6411483253588517,\n",
       " 0.6919431279620852,\n",
       " 0.7902439024390245,\n",
       " 0.8056872037914692,\n",
       " 0.6919431279620852,\n",
       " 0.8502415458937197,\n",
       " 0.7609756097560976,\n",
       " 0.7019230769230769,\n",
       " 0.7536231884057971,\n",
       " 0.6504854368932039,\n",
       " 0.7902439024390245,\n",
       " 0.7867298578199053,\n",
       " 0.7980769230769232,\n",
       " 0.6602870813397129,\n",
       " 0.8095238095238095,\n",
       " 0.7307692307692307,\n",
       " 0.714975845410628,\n",
       " 0.7655502392344498,\n",
       " 0.7559808612440192,\n",
       " 0.6919431279620852,\n",
       " 0.7281553398058253,\n",
       " 0.7264150943396226,\n",
       " 0.8212560386473429,\n",
       " 0.7980769230769232,\n",
       " 0.7281553398058253,\n",
       " 0.7238095238095237,\n",
       " 0.8436018957345971,\n",
       " 0.6923076923076923,\n",
       " 0.7772511848341233,\n",
       " 0.8229665071770336,\n",
       " 0.7904761904761907,\n",
       " 0.8365384615384617,\n",
       " 0.6507177033492824,\n",
       " 0.7053140096618357,\n",
       " 0.7317073170731707,\n",
       " 0.8038277511961722,\n",
       " 0.6285714285714286,\n",
       " 0.7677725118483413,\n",
       " 0.6730769230769231,\n",
       " 0.6538461538461539,\n",
       " 0.7298578199052131,\n",
       " 0.7333333333333333,\n",
       " 0.7417840375586854,\n",
       " 0.7368421052631579,\n",
       " 0.7962085308056872,\n",
       " 0.7547169811320755,\n",
       " 0.7238095238095237,\n",
       " 0.7211538461538461,\n",
       " 0.7219512195121951,\n",
       " 0.7788461538461539,\n",
       " 0.7053140096618357,\n",
       " 0.6220095693779905,\n",
       " 0.784688995215311,\n",
       " 0.7169811320754716,\n",
       " 0.8252427184466018,\n",
       " 0.7109004739336493,\n",
       " 0.8653846153846154,\n",
       " 0.7393364928909952,\n",
       " 0.7014218009478673,\n",
       " 0.7358490566037735,\n",
       " 0.7632850241545893,\n",
       " 0.7559808612440192,\n",
       " 0.7307692307692307,\n",
       " 0.6540284360189573,\n",
       " 0.7177033492822966,\n",
       " 0.6985645933014353,\n",
       " 0.7087378640776698,\n",
       " 0.7403846153846154,\n",
       " 0.7211538461538461,\n",
       " 0.6666666666666666,\n",
       " 0.7333333333333333,\n",
       " 0.7729468599033816,\n",
       " 0.7417840375586854,\n",
       " 0.7707317073170732,\n",
       " 0.6376811594202898,\n",
       " 0.6857142857142856,\n",
       " 0.7902439024390245,\n",
       " 0.7014218009478673,\n",
       " 0.7632850241545893,\n",
       " 0.8173076923076923,\n",
       " 0.7677725118483413,\n",
       " 0.6376811594202898,\n",
       " 0.7547169811320755,\n",
       " 0.7238095238095237,\n",
       " 0.7358490566037735,\n",
       " 0.7788461538461539,\n",
       " 0.6794258373205742,\n",
       " 0.7830188679245284,\n",
       " 0.7393364928909952,\n",
       " 0.7904761904761907,\n",
       " 0.6407766990291263,\n",
       " 0.7809523809523811,\n",
       " 0.7317073170731707,\n",
       " 0.7766990291262137,\n",
       " 0.6796116504854369,\n",
       " 0.6761904761904762,\n",
       " 0.7368421052631579,\n",
       " 0.6602870813397129,\n",
       " 0.8349514563106797,\n",
       " 0.7655502392344498,\n",
       " 0.75,\n",
       " 0.7980769230769232,\n",
       " 0.7488151658767772,\n",
       " 0.6509433962264151,\n",
       " 0.7751196172248804,\n",
       " 0.7281553398058253,\n",
       " 0.6731707317073171,\n",
       " 0.7632850241545893,\n",
       " 0.7619047619047619,\n",
       " 0.714975845410628,\n",
       " 0.7142857142857143,\n",
       " 0.7609756097560976,\n",
       " 0.7830188679245284,\n",
       " 0.7047619047619048,\n",
       " 0.7142857142857143,\n",
       " 0.6796116504854369,\n",
       " 0.7142857142857143,\n",
       " 0.7488151658767772,\n",
       " 0.7830188679245284,\n",
       " 0.6729857819905213,\n",
       " 0.7942583732057417,\n",
       " 0.6698564593301435,\n",
       " 0.838095238095238,\n",
       " 0.6923076923076923,\n",
       " 0.6442307692307693,\n",
       " 0.7475728155339807,\n",
       " 0.7699530516431925,\n",
       " 0.7281553398058253,\n",
       " 0.6919431279620852,\n",
       " 0.7393364928909952,\n",
       " 0.7109004739336493,\n",
       " 0.7087378640776698,\n",
       " 0.6602870813397129,\n",
       " 0.6796116504854369,\n",
       " 0.8190476190476191,\n",
       " 0.6538461538461539,\n",
       " 0.7246376811594204,\n",
       " 0.7632850241545893,\n",
       " 0.6824644549763034,\n",
       " 0.7980769230769232,\n",
       " 0.7081339712918661,\n",
       " 0.6666666666666666,\n",
       " 0.7203791469194313,\n",
       " 0.737864077669903,\n",
       " 0.6952380952380952,\n",
       " 0.7547169811320755,\n",
       " 0.6634615384615384,\n",
       " 0.6985645933014353,\n",
       " 0.7942583732057417,\n",
       " 0.6161137440758294,\n",
       " 0.7729468599033816,\n",
       " 0.6824644549763034,\n",
       " 0.7788461538461539,\n",
       " 0.7980769230769232,\n",
       " 0.7772511848341233,\n",
       " 0.7766990291262137,\n",
       " 0.6824644549763034,\n",
       " 0.7019230769230769,\n",
       " 0.6985645933014353,\n",
       " 0.7393364928909952,\n",
       " 0.6602870813397129,\n",
       " 0.7464114832535885,\n",
       " 0.7177033492822966,\n",
       " 0.7019230769230769,\n",
       " 0.7735849056603775,\n",
       " 0.7488151658767772,\n",
       " 0.8019323671497585,\n",
       " 0.820754716981132,\n",
       " 0.7536231884057971,\n",
       " 0.7393364928909952,\n",
       " 0.6380952380952382,\n",
       " 0.7203791469194313,\n",
       " 0.6760563380281691,\n",
       " 0.8461538461538461,\n",
       " 0.7830188679245284,\n",
       " 0.6893203883495145,\n",
       " 0.8365384615384617,\n",
       " 0.6666666666666666,\n",
       " 0.7246376811594204,\n",
       " 0.6634615384615384,\n",
       " 0.7203791469194313,\n",
       " 0.7475728155339807,\n",
       " 0.7403846153846154,\n",
       " 0.7572815533980582,\n",
       " 0.7809523809523811,\n",
       " 0.7488151658767772,\n",
       " 0.7464114832535885,\n",
       " 0.7632850241545893,\n",
       " 0.7081339712918661,\n",
       " 0.7619047619047619,\n",
       " 0.7488151658767772,\n",
       " 0.6794258373205742,\n",
       " 0.7281553398058253,\n",
       " 0.7655502392344498,\n",
       " 0.7655502392344498,\n",
       " 0.7115384615384616,\n",
       " 0.7184466019417476,\n",
       " 0.7464114832535885,\n",
       " 0.7735849056603775,\n",
       " 0.7464114832535885,\n",
       " 0.7523809523809524,\n",
       " 0.7641509433962264,\n",
       " 0.8173076923076923,\n",
       " 0.7109004739336493,\n",
       " 0.6601941747572816,\n",
       " 0.7788461538461539,\n",
       " 0.7177033492822966,\n",
       " 0.7053140096618357,\n",
       " 0.6796116504854369,\n",
       " 0.7317073170731707,\n",
       " 0.6956521739130435,\n",
       " 0.7714285714285715,\n",
       " 0.6601941747572816,\n",
       " 0.7081339712918661,\n",
       " 0.7572815533980582,\n",
       " 0.6919431279620852,\n",
       " 0.7488151658767772,\n",
       " 0.784688995215311,\n",
       " 0.7830188679245284,\n",
       " 0.7523809523809524,\n",
       " 0.7075471698113207,\n",
       " 0.7087378640776698,\n",
       " 0.7735849056603775,\n",
       " 0.7523809523809524,\n",
       " 0.7403846153846154,\n",
       " 0.6666666666666666,\n",
       " 0.7403846153846154,\n",
       " 0.7452830188679245,\n",
       " 0.7358490566037735,\n",
       " 0.7884615384615384,\n",
       " 0.7333333333333333,\n",
       " 0.7272727272727273,\n",
       " 0.75,\n",
       " 0.854368932038835,\n",
       " 0.714975845410628,\n",
       " 0.8133971291866028,\n",
       " 0.7177033492822966,\n",
       " 0.6666666666666666,\n",
       " 0.7669902912621359,\n",
       " 0.7464114832535885,\n",
       " 0.6761904761904762,\n",
       " 0.7047619047619048,\n",
       " 0.7428571428571428,\n",
       " 0.7559808612440192,\n",
       " 0.7177033492822966,\n",
       " 0.7087378640776698,\n",
       " 0.7793427230046949,\n",
       " 0.7707317073170732,\n",
       " 0.7014218009478673,\n",
       " 0.75,\n",
       " 0.6310679611650485,\n",
       " 0.7596153846153846,\n",
       " 0.7596153846153846,\n",
       " 0.6445497630331753,\n",
       " 0.7203791469194313,\n",
       " 0.8502415458937197,\n",
       " 0.714975845410628,\n",
       " 0.7924528301886793,\n",
       " 0.6919431279620852,\n",
       " 0.7867298578199053,\n",
       " 0.7559808612440192,\n",
       " 0.7867298578199053,\n",
       " 0.7692307692307694,\n",
       " 0.7177033492822966,\n",
       " 0.6634615384615384,\n",
       " 0.8133971291866028,\n",
       " 0.8095238095238095,\n",
       " 0.6981132075471698,\n",
       " 0.7619047619047619,\n",
       " 0.7751196172248804,\n",
       " 0.7677725118483413,\n",
       " 0.7632850241545893,\n",
       " 0.7942583732057417,\n",
       " 0.6698564593301435,\n",
       " 0.7177033492822966,\n",
       " 0.7488151658767772,\n",
       " 0.7619047619047619,\n",
       " 0.7559808612440192,\n",
       " 0.7904761904761907,\n",
       " 0.6346153846153846,\n",
       " 0.7142857142857143,\n",
       " 0.8325358851674641,\n",
       " 0.6729857819905213,\n",
       " 0.8076923076923077,\n",
       " 0.6857142857142856,\n",
       " 0.8133971291866028,\n",
       " 0.6952380952380952,\n",
       " 0.7523809523809524,\n",
       " 0.6796116504854369,\n",
       " 0.8229665071770336,\n",
       " 0.7109004739336493,\n",
       " 0.8,\n",
       " 0.7523809523809524,\n",
       " 0.7219512195121951,\n",
       " 0.7772511848341233,\n",
       " 0.6923076923076923,\n",
       " 0.6859903381642511,\n",
       " 0.6476190476190476,\n",
       " 0.7655502392344498,\n",
       " 0.7867298578199053,\n",
       " 0.7632850241545893,\n",
       " 0.7184466019417476,\n",
       " 0.6666666666666666,\n",
       " 0.7428571428571428,\n",
       " 0.7523809523809524,\n",
       " 0.6893203883495145,\n",
       " 0.7980769230769232,\n",
       " 0.7019230769230769,\n",
       " 0.8173076923076923,\n",
       " 0.7169811320754716,\n",
       " 0.7439613526570049,\n",
       " 0.6666666666666666,\n",
       " 0.8173076923076923,\n",
       " 0.7714285714285715,\n",
       " 0.6478873239436619,\n",
       " 0.7488151658767772,\n",
       " 0.6956521739130435,\n",
       " 0.6540284360189573,\n",
       " 0.7867298578199053,\n",
       " 0.6634615384615384,\n",
       " 0.7014218009478673,\n",
       " 0.6760563380281691,\n",
       " 0.6889952153110048,\n",
       " 0.7788461538461539,\n",
       " 0.7464114832535885,\n",
       " 0.7751196172248804,\n",
       " 0.7714285714285715,\n",
       " 0.7428571428571428,\n",
       " 0.7632850241545893,\n",
       " 0.7867298578199053,\n",
       " 0.7655502392344498,\n",
       " 0.6666666666666666,\n",
       " 0.7428571428571428,\n",
       " 0.7735849056603775,\n",
       " 0.8076923076923077,\n",
       " 0.6601941747572816,\n",
       " 0.7655502392344498,\n",
       " 0.7142857142857143,\n",
       " 0.6666666666666666,\n",
       " 0.6538461538461539,\n",
       " 0.6411483253588517,\n",
       " 0.6572769953051644,\n",
       " 0.6956521739130435,\n",
       " 0.7047619047619048,\n",
       " 0.7333333333333333,\n",
       " 0.7014218009478673,\n",
       " 0.8421052631578947,\n",
       " 0.7136150234741785,\n",
       " 0.676328502415459,\n",
       " 0.8190476190476191,\n",
       " 0.7547169811320755,\n",
       " 0.6889952153110048,\n",
       " 0.8,\n",
       " 0.7053140096618357,\n",
       " 0.8133971291866028,\n",
       " 0.7559808612440192,\n",
       " 0.7475728155339807,\n",
       " 0.7464114832535885,\n",
       " 0.7368421052631579,\n",
       " 0.6540284360189573,\n",
       " 0.6952380952380952,\n",
       " 0.784688995215311,\n",
       " 0.7729468599033816,\n",
       " 0.6952380952380952,\n",
       " 0.6826923076923077,\n",
       " 0.676328502415459,\n",
       " 0.7714285714285715,\n",
       " 0.7867298578199053,\n",
       " 0.7169811320754716,\n",
       " 0.7864077669902914,\n",
       " 0.6923076923076923,\n",
       " 0.7751196172248804,\n",
       " 0.7619047619047619,\n",
       " 0.8019323671497585,\n",
       " 0.7142857142857143,\n",
       " 0.7238095238095237,\n",
       " 0.8076923076923077,\n",
       " 0.7368421052631579,\n",
       " 0.6730769230769231,\n",
       " 0.7342995169082125,\n",
       " 0.7298578199052131,\n",
       " 0.7169811320754716,\n",
       " 0.8019323671497585,\n",
       " 0.6886792452830188,\n",
       " 0.6730769230769231,\n",
       " 0.7272727272727273,\n",
       " 0.7115384615384616,\n",
       " 0.6824644549763034,\n",
       " 0.7464114832535885,\n",
       " 0.8019323671497585,\n",
       " 0.6634615384615384,\n",
       " 0.75,\n",
       " 0.6698564593301435,\n",
       " 0.6985645933014353,\n",
       " 0.6985645933014353,\n",
       " 0.7109004739336493,\n",
       " 0.7417840375586854,\n",
       " 0.7393364928909952,\n",
       " 0.7177033492822966,\n",
       " 0.6792452830188679,\n",
       " 0.7641509433962264,\n",
       " 0.8056872037914692,\n",
       " 0.7677725118483413,\n",
       " 0.7342995169082125,\n",
       " 0.7439613526570049,\n",
       " 0.7177033492822966,\n",
       " 0.6796116504854369,\n",
       " 0.6919431279620852,\n",
       " 0.7403846153846154,\n",
       " 0.631578947368421,\n",
       " 0.6666666666666666,\n",
       " 0.7238095238095237,\n",
       " 0.7641509433962264,\n",
       " 0.6346153846153846,\n",
       " 0.7403846153846154,\n",
       " 0.7368421052631579,\n",
       " 0.7417840375586854,\n",
       " 0.6384976525821597,\n",
       " 0.8195121951219512,\n",
       " 0.7414634146341462,\n",
       " 0.6634615384615384,\n",
       " 0.6857142857142856,\n",
       " 0.6509433962264151,\n",
       " 0.7358490566037735,\n",
       " 0.7053140096618357,\n",
       " 0.7572815533980582,\n",
       " 0.6824644549763034,\n",
       " 0.7669902912621359,\n",
       " 0.7014218009478673,\n",
       " 0.782608695652174,\n",
       " 0.7699530516431925,\n",
       " 0.7014218009478673,\n",
       " 0.7511737089201879,\n",
       " 0.6570048309178744,\n",
       " 0.7014218009478673,\n",
       " 0.7729468599033816,\n",
       " 0.6796116504854369,\n",
       " 0.6666666666666666,\n",
       " 0.7864077669902914,\n",
       " 0.7177033492822966,\n",
       " 0.7809523809523811,\n",
       " 0.7692307692307694,\n",
       " 0.6926829268292682,\n",
       " 0.7368421052631579,\n",
       " 0.7677725118483413,\n",
       " 0.7047619047619048,\n",
       " 0.784688995215311,\n",
       " 0.6698564593301435,\n",
       " 0.6985645933014353,\n",
       " 0.7536231884057971,\n",
       " 0.6602870813397129,\n",
       " 0.782608695652174,\n",
       " 0.7053140096618357,\n",
       " 0.7830188679245284,\n",
       " 0.7368421052631579,\n",
       " 0.7488151658767772,\n",
       " 0.6796116504854369,\n",
       " 0.8405797101449275,\n",
       " 0.6792452830188679,\n",
       " 0.6470588235294118,\n",
       " 0.75,\n",
       " 0.6985645933014353,\n",
       " 0.7393364928909952,\n",
       " 0.7596153846153846,\n",
       " 0.7121951219512195,\n",
       " 0.7238095238095237,\n",
       " 0.6538461538461539,\n",
       " 0.6571428571428571,\n",
       " 0.7298578199052131,\n",
       " 0.7342995169082125,\n",
       " 0.6473429951690821,\n",
       " 0.8019323671497585,\n",
       " 0.8390243902439024,\n",
       " 0.8076923076923077,\n",
       " 0.8173076923076923,\n",
       " 0.6985645933014353,\n",
       " 0.6796116504854369,\n",
       " 0.7962085308056872,\n",
       " 0.676328502415459,\n",
       " 0.7464114832535885,\n",
       " 0.8019323671497585,\n",
       " 0.7211538461538461,\n",
       " 0.7383177570093458,\n",
       " 0.7368421052631579,\n",
       " 0.7475728155339807,\n",
       " 0.6603773584905661,\n",
       " 0.7075471698113207,\n",
       " 0.7142857142857143,\n",
       " 0.7452830188679245,\n",
       " 0.7632850241545893,\n",
       " 0.7358490566037735,\n",
       " 0.6571428571428571,\n",
       " 0.8341232227488152,\n",
       " 0.7272727272727273,\n",
       " 0.676328502415459,\n",
       " 0.7019230769230769,\n",
       " 0.7307692307692307,\n",
       " 0.8269230769230769,\n",
       " 0.7559808612440192,\n",
       " 0.7053140096618357,\n",
       " 0.6699029126213593,\n",
       " 0.7464114832535885,\n",
       " 0.7511737089201879,\n",
       " 0.737864077669903,\n",
       " 0.8173076923076923,\n",
       " 0.6635071090047393,\n",
       " 0.7333333333333333,\n",
       " 0.7464114832535885,\n",
       " 0.7884615384615384,\n",
       " 0.7439613526570049,\n",
       " 0.7904761904761907,\n",
       " 0.7632850241545893,\n",
       " 0.6761904761904762,\n",
       " 0.6854460093896714,\n",
       " 0.7735849056603775,\n",
       " 0.8461538461538461,\n",
       " 0.6886792452830188,\n",
       " 0.7729468599033816,\n",
       " 0.7751196172248804,\n",
       " 0.6985645933014353,\n",
       " 0.6666666666666666,\n",
       " 0.7203791469194313,\n",
       " 0.7368421052631579,\n",
       " 0.7751196172248804,\n",
       " 0.7081339712918661,\n",
       " 0.7714285714285715,\n",
       " 0.6504854368932039,\n",
       " 0.7729468599033816,\n",
       " 0.784688995215311,\n",
       " 0.7523809523809524,\n",
       " 0.7475728155339807,\n",
       " 0.7464114832535885,\n",
       " 0.7464114832535885,\n",
       " 0.8,\n",
       " 0.6407766990291263,\n",
       " 0.8252427184466018,\n",
       " 0.7559808612440192,\n",
       " 0.6981132075471698,\n",
       " 0.6889952153110048,\n",
       " 0.6857142857142856,\n",
       " 0.7081339712918661,\n",
       " 0.7428571428571428,\n",
       " 0.7053140096618357,\n",
       " 0.8212560386473429,\n",
       " 0.7536231884057971,\n",
       " 0.6794258373205742,\n",
       " 0.7019230769230769,\n",
       " 0.8038277511961722,\n",
       " 0.714975845410628,\n",
       " 0.7254901960784315,\n",
       " 0.7439613526570049,\n",
       " 0.8133971291866028,\n",
       " 0.7109004739336493,\n",
       " 0.7692307692307694,\n",
       " 0.6542056074766356,\n",
       " 0.6919431279620852,\n",
       " 0.7751196172248804,\n",
       " 0.7582938388625592,\n",
       " 0.8229665071770336,\n",
       " 0.8229665071770336,\n",
       " 0.6952380952380952,\n",
       " 0.7464114832535885,\n",
       " 0.6380952380952382,\n",
       " 0.7019230769230769,\n",
       " 0.6919431279620852,\n",
       " 0.6919431279620852,\n",
       " 0.6255924170616113,\n",
       " 0.7014218009478673,\n",
       " 0.6919431279620852,\n",
       " 0.7788461538461539,\n",
       " 0.6952380952380952,\n",
       " 0.7632850241545893,\n",
       " 0.7136150234741785,\n",
       " 0.7804878048780488,\n",
       " 0.7109004739336493,\n",
       " 0.839622641509434,\n",
       " 0.7439613526570049,\n",
       " 0.7655502392344498,\n",
       " 0.6220095693779905,\n",
       " 0.7523809523809524,\n",
       " 0.7109004739336493,\n",
       " 0.7272727272727273,\n",
       " 0.7203791469194313,\n",
       " 0.7177033492822966,\n",
       " 0.7582938388625592,\n",
       " 0.7464114832535885,\n",
       " 0.6857142857142856,\n",
       " 0.7699530516431925,\n",
       " 0.7211538461538461,\n",
       " 0.6538461538461539,\n",
       " 0.7572815533980582,\n",
       " 0.6183574879227053,\n",
       " 0.7109004739336493,\n",
       " 0.8476190476190476,\n",
       " 0.7735849056603775,\n",
       " 0.7272727272727273,\n",
       " 0.7264150943396226,\n",
       " 0.7053140096618357,\n",
       " 0.7109004739336493,\n",
       " 0.7272727272727273,\n",
       " 0.6666666666666666,\n",
       " 0.6504854368932039,\n",
       " 0.6666666666666666,\n",
       " 0.6889952153110048,\n",
       " 0.8557692307692308,\n",
       " 0.6857142857142856,\n",
       " 0.6919431279620852,\n",
       " 0.7962085308056872,\n",
       " 0.7559808612440192,\n",
       " 0.8076923076923077,\n",
       " 0.6952380952380952,\n",
       " 0.8325358851674641,\n",
       " 0.6981132075471698,\n",
       " 0.7547169811320755,\n",
       " 0.7075471698113207,\n",
       " 0.7692307692307694,\n",
       " 0.6473429951690821,\n",
       " 0.7619047619047619,\n",
       " 0.676328502415459,\n",
       " 0.6952380952380952,\n",
       " 0.6956521739130435,\n",
       " 0.6376811594202898,\n",
       " 0.6540284360189573,\n",
       " 0.7393364928909952,\n",
       " 0.6952380952380952,\n",
       " 0.6603773584905661,\n",
       " 0.7536231884057971,\n",
       " 0.7692307692307694,\n",
       " 0.7559808612440192,\n",
       " 0.6889952153110048,\n",
       " 0.7042253521126761,\n",
       " 0.838095238095238,\n",
       " 0.6507177033492824,\n",
       " 0.6824644549763034,\n",
       " 0.7922705314009661,\n",
       " 0.6285714285714286,\n",
       " 0.7655502392344498,\n",
       " 0.6504854368932039,\n",
       " 0.7572815533980582,\n",
       " 0.7864077669902914,\n",
       " 0.7641509433962264,\n",
       " 0.6919431279620852,\n",
       " 0.7523809523809524,\n",
       " 0.6634615384615384,\n",
       " 0.7368421052631579,\n",
       " 0.7980769230769232,\n",
       " 0.6794258373205742,\n",
       " 0.6889952153110048,\n",
       " 0.6666666666666666,\n",
       " 0.7019230769230769,\n",
       " 0.6602870813397129,\n",
       " 0.8,\n",
       " 0.7281553398058253,\n",
       " 0.7669902912621359,\n",
       " 0.7692307692307694,\n",
       " 0.7488151658767772,\n",
       " 0.7358490566037735,\n",
       " 0.6859903381642511,\n",
       " 0.6923076923076923,\n",
       " 0.7264150943396226,\n",
       " 0.7156862745098039,\n",
       " 0.7596153846153846,\n",
       " 0.7619047619047619,\n",
       " 0.7358490566037735,\n",
       " 0.6255924170616113,\n",
       " 0.7751196172248804,\n",
       " 0.6985645933014353,\n",
       " 0.8803827751196172,\n",
       " 0.7619047619047619,\n",
       " 0.6509433962264151,\n",
       " 0.6923076923076923,\n",
       " 0.6889952153110048,\n",
       " 0.7942583732057417,\n",
       " 0.6602870813397129,\n",
       " 0.6730769230769231,\n",
       " 0.6761904761904762,\n",
       " 0.7669902912621359,\n",
       " 0.7714285714285715,\n",
       " 0.7788461538461539,\n",
       " 0.7714285714285715,\n",
       " 0.8056872037914692,\n",
       " 0.8056872037914692,\n",
       " 0.6602870813397129,\n",
       " 0.7087378640776698,\n",
       " 0.8018867924528302,\n",
       " 0.7115384615384616,\n",
       " 0.75,\n",
       " 0.7439613526570049,\n",
       " 0.7751196172248804,\n",
       " 0.7922705314009661,\n",
       " 0.7904761904761907,\n",
       " 0.6952380952380952,\n",
       " 0.7922705314009661,\n",
       " 0.7559808612440192,\n",
       " 0.6571428571428571,\n",
       " 0.8,\n",
       " 0.7980769230769232,\n",
       " 0.6857142857142856,\n",
       " 0.7342995169082125,\n",
       " 0.737864077669903,\n",
       " 0.7439613526570049,\n",
       " 0.7751196172248804,\n",
       " 0.7087378640776698,\n",
       " 0.8502415458937197,\n",
       " 0.7793427230046949,\n",
       " 0.7523809523809524,\n",
       " 0.7307692307692307,\n",
       " 0.7053140096618357,\n",
       " 0.7488151658767772,\n",
       " 0.7942583732057417,\n",
       " 0.7053140096618357,\n",
       " 0.6478873239436619,\n",
       " 0.7203791469194313,\n",
       " 0.6571428571428571,\n",
       " 0.8038277511961722,\n",
       " 0.7609756097560976,\n",
       " 0.7692307692307694,\n",
       " 0.6889952153110048,\n",
       " 0.8269230769230769,\n",
       " 0.6504854368932039,\n",
       " 0.7582938388625592,\n",
       " 0.7523809523809524,\n",
       " 0.7014218009478673,\n",
       " 0.7677725118483413,\n",
       " 0.7962085308056872,\n",
       " 0.7596153846153846,\n",
       " 0.7677725118483413,\n",
       " 0.6666666666666666,\n",
       " 0.7142857142857143,\n",
       " 0.7572815533980582,\n",
       " 0.7809523809523811,\n",
       " 0.7169811320754716,\n",
       " 0.7729468599033816,\n",
       " 0.7042253521126761,\n",
       " 0.7452830188679245,\n",
       " 0.7081339712918661,\n",
       " 0.7523809523809524,\n",
       " 0.7523809523809524,\n",
       " 0.7772511848341233,\n",
       " 0.7024390243902439,\n",
       " 0.7428571428571428,\n",
       " 0.6923076923076923,\n",
       " 0.6635071090047393,\n",
       " 0.7053140096618357,\n",
       " 0.7246376811594204,\n",
       " 0.7368421052631579,\n",
       " 0.676328502415459,\n",
       " 0.7669902912621359,\n",
       " 0.75,\n",
       " 0.7081339712918661,\n",
       " 0.7788461538461539,\n",
       " 0.7439613526570049,\n",
       " 0.8,\n",
       " 0.7439613526570049,\n",
       " 0.6504854368932039,\n",
       " 0.6666666666666666,\n",
       " 0.7609756097560976,\n",
       " 0.6699029126213593,\n",
       " 0.8056872037914692,\n",
       " 0.6948356807511737,\n",
       " 0.7342995169082125,\n",
       " 0.7014218009478673,\n",
       " 0.7136150234741785,\n",
       " 0.6796116504854369,\n",
       " 0.6857142857142856,\n",
       " 0.7450980392156863,\n",
       " 0.7512195121951221,\n",
       " 0.7203791469194313,\n",
       " 0.6540284360189573,\n",
       " 0.7393364928909952,\n",
       " 0.7075471698113207,\n",
       " 0.7596153846153846,\n",
       " 0.7087378640776698,\n",
       " 0.6985645933014353,\n",
       " 0.7053140096618357,\n",
       " 0.7669902912621359,\n",
       " 0.7177033492822966,\n",
       " 0.6635071090047393,\n",
       " 0.6570048309178744,\n",
       " 0.7368421052631579,\n",
       " 0.6601941747572816,\n",
       " 0.7075471698113207,\n",
       " 0.676328502415459,\n",
       " 0.7333333333333333,\n",
       " 0.7609756097560976,\n",
       " 0.6376811594202898,\n",
       " 0.7632850241545893,\n",
       " 0.7476635514018692,\n",
       " 0.7238095238095237,\n",
       " 0.7177033492822966,\n",
       " 0.6956521739130435,\n",
       " 0.7368421052631579,\n",
       " 0.7075471698113207,\n",
       " 0.6952380952380952,\n",
       " 0.6407766990291263,\n",
       " 0.7342995169082125,\n",
       " 0.7298578199052131,\n",
       " 0.7246376811594204,\n",
       " 0.6540284360189573,\n",
       " 0.7298578199052131,\n",
       " 0.7788461538461539,\n",
       " 0.7393364928909952,\n",
       " 0.6824644549763034,\n",
       " 0.7751196172248804,\n",
       " 0.7087378640776698,\n",
       " 0.7464114832535885,\n",
       " 0.6439024390243901,\n",
       " 0.6889952153110048,\n",
       " 0.7238095238095237,\n",
       " 0.8133971291866028,\n",
       " 0.8173076923076923,\n",
       " 0.7203791469194313,\n",
       " 0.6666666666666666,\n",
       " 0.737864077669903,\n",
       " 0.7042253521126761,\n",
       " 0.7246376811594204,\n",
       " 0.6889952153110048,\n",
       " 0.7087378640776698,\n",
       " 0.7428571428571428,\n",
       " 0.7655502392344498,\n",
       " 0.7352941176470589,\n",
       " 0.8056872037914692,\n",
       " 0.7081339712918661,\n",
       " 0.7307692307692307,\n",
       " 0.6796116504854369,\n",
       " 0.7804878048780488,\n",
       " 0.7177033492822966,\n",
       " 0.7238095238095237,\n",
       " 0.7922705314009661,\n",
       " 0.8325358851674641,\n",
       " 0.7714285714285715,\n",
       " 0.6476190476190476,\n",
       " 0.7238095238095237,\n",
       " 0.8,\n",
       " 0.7358490566037735,\n",
       " 0.7980769230769232,\n",
       " 0.8,\n",
       " 0.7980769230769232,\n",
       " 0.8309178743961352,\n",
       " 0.7136150234741785,\n",
       " 0.8056872037914692,\n",
       " 0.7830188679245284,\n",
       " 0.7735849056603775,\n",
       " 0.7053140096618357,\n",
       " 0.7087378640776698,\n",
       " 0.7751196172248804,\n",
       " 0.7729468599033816,\n",
       " 0.6730769230769231,\n",
       " 0.784688995215311,\n",
       " 0.7830188679245284,\n",
       " 0.7081339712918661,\n",
       " 0.7632850241545893,\n",
       " 0.7230046948356808,\n",
       " 0.8,\n",
       " 0.6698564593301435,\n",
       " 0.838095238095238,\n",
       " 0.6889952153110048,\n",
       " 0.6411483253588517,\n",
       " 0.8113207547169812,\n",
       " 0.7902439024390245,\n",
       " 0.6509433962264151,\n",
       " 0.6666666666666666,\n",
       " 0.7452830188679245,\n",
       " 0.782608695652174,\n",
       " 0.6602870813397129,\n",
       " 0.7342995169082125,\n",
       " 0.7238095238095237,\n",
       " 0.6376811594202898,\n",
       " 0.7169811320754716,\n",
       " 0.782608695652174,\n",
       " 0.7169811320754716,\n",
       " 0.6985645933014353,\n",
       " 0.6886792452830188,\n",
       " 0.839622641509434,\n",
       " 0.6603773584905661,\n",
       " 0.6829268292682926,\n",
       " 0.7439613526570049,\n",
       " 0.7452830188679245,\n",
       " 0.6729857819905213,\n",
       " 0.7692307692307694,\n",
       " 0.7196261682242991,\n",
       " 0.6602870813397129,\n",
       " 0.7582938388625592,\n",
       " 0.6794258373205742,\n",
       " 0.8,\n",
       " 0.7677725118483413,\n",
       " 0.6919431279620852,\n",
       " 0.784688995215311,\n",
       " 0.7238095238095237,\n",
       " 0.6893203883495145,\n",
       " 0.7439613526570049,\n",
       " 0.7272727272727273,\n",
       " 0.7488151658767772,\n",
       " 0.7281553398058253,\n",
       " 0.6990291262135924,\n",
       " 0.7596153846153846,\n",
       " 0.6372549019607843,\n",
       " 0.7512195121951221,\n",
       " 0.6699029126213593,\n",
       " 0.6698564593301435,\n",
       " 0.7475728155339807,\n",
       " 0.7677725118483413,\n",
       " 0.7203791469194313,\n",
       " 0.7169811320754716,\n",
       " 0.7246376811594204,\n",
       " 0.7358490566037735,\n",
       " 0.7788461538461539,\n",
       " 0.7342995169082125,\n",
       " 0.6698564593301435,\n",
       " 0.6956521739130435,\n",
       " 0.6990291262135924,\n",
       " 0.7511737089201879,\n",
       " 0.7729468599033816,\n",
       " 0.6504854368932039,\n",
       " 0.8056872037914692,\n",
       " 0.7961165048543689,\n",
       " 0.7428571428571428,\n",
       " 0.7547169811320755,\n",
       " 0.8212560386473429,\n",
       " 0.6796116504854369,\n",
       " 0.631578947368421,\n",
       " 0.6761904761904762,\n",
       " 0.7464114832535885,\n",
       " 0.7238095238095237,\n",
       " 0.7142857142857143,\n",
       " 0.6826923076923077,\n",
       " 0.7307692307692307,\n",
       " 0.7536231884057971,\n",
       " 0.6796116504854369,\n",
       " 0.6952380952380952,\n",
       " 0.6952380952380952,\n",
       " 0.7729468599033816,\n",
       " 0.7075471698113207,\n",
       " 0.7428571428571428,\n",
       " 0.782608695652174,\n",
       " 0.7047619047619048,\n",
       " 0.7368421052631579,\n",
       " 0.7655502392344498,\n",
       " 0.7677725118483413,\n",
       " 0.6985645933014353,\n",
       " 0.6923076923076923,\n",
       " 0.6923076923076923,\n",
       " 0.6634615384615384,\n",
       " 0.6761904761904762,\n",
       " 0.6255924170616113,\n",
       " 0.6923076923076923,\n",
       " 0.7298578199052131,\n",
       " 0.6760563380281691,\n",
       " 0.7439613526570049,\n",
       " 0.7254901960784315,\n",
       " 0.7464114832535885,\n",
       " 0.6985645933014353,\n",
       " 0.7203791469194313,\n",
       " 0.7772511848341233,\n",
       " 0.7307692307692307,\n",
       " 0.7523809523809524,\n",
       " 0.7211538461538461,\n",
       " 0.7596153846153846,\n",
       " 0.7439613526570049,\n",
       " 0.6473429951690821,\n",
       " 0.7281553398058253,\n",
       " 0.7238095238095237,\n",
       " 0.7523809523809524,\n",
       " 0.7536231884057971,\n",
       " 0.8019323671497585,\n",
       " 0.6923076923076923,\n",
       " 0.6822429906542056,\n",
       " 0.6285714285714286,\n",
       " 0.7596153846153846,\n",
       " 0.676328502415459,\n",
       " 0.6886792452830188,\n",
       " 0.7053140096618357,\n",
       " 0.7536231884057971,\n",
       " 0.7559808612440192,\n",
       " 0.7203791469194313,\n",
       " 0.8056872037914692,\n",
       " 0.7655502392344498,\n",
       " ...]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.        , 0.19632425],\n",
       "       [0.19632425, 1.        ]])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(probs,f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9944280da0>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99442be7b8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(f1,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x7f9927866f98>"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f99442a15c0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(f1,probs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
