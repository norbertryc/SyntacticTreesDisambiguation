{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import xml.etree.ElementTree as ET\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from pprint import pprint\n",
    "from keras.preprocessing import sequence as seq\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _check_sentence(xml_tree, accept_tags=[\"forest\",\"tree\"]):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja sprawdza poprawnosc wypowiedzenia i arumentu: \n",
    "    - czy istnieje dla niego poprawne drzewo - wypowiedzenie jest poprawne jesli base_answer na polu \"type\" ma wartosc \"FULL\".\n",
    "    - arumentem powinno byc drzewo o tagu korzenia rownym \"forest\" lub \"tree\".\n",
    "    [W oryginalnych plikach z lasami jest to \"forest\", natomiast gdy z lasu tworzone sa pojedyncze drzewa,\n",
    "    to maja one tag \"tree\"]\n",
    "    \n",
    "    xml_tree - las drzew lub drzewo [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "    \n",
    "    if type(xml_tree) != ET.ElementTree:\n",
    "        raise AssertionError(\"Argument xml_tree is not not ElementTree\")\n",
    "    \n",
    "    \n",
    "    if type(accept_tags) == str:\n",
    "        accept_tags = [accept_tags]\n",
    "    \n",
    "    \n",
    "    if not xml_tree.getroot().tag in accept_tags:\n",
    "        raise AssertionError('Argument in not in [' + \",\".join(accept_tags) + '] - it has tag \"' + xml_tree.getroot().tag + '\"' )\n",
    "    \n",
    "    \n",
    "    base_answer_type = xml_tree.getroot().find('.//answer-data//base-answer').attrib[\"type\"]\n",
    "    correct = base_answer_type == \"FULL\"\n",
    "\n",
    "    if not correct:\n",
    "        raise AssertionError(\"Sentence is not correct: Node <base-answer> has type value \" + base_answer_type  + \" instead of 'FULL'\")\n",
    "        \n",
    "    pass\n",
    "\n",
    "\n",
    "def number_of_trees_in_forest(forest):\n",
    "\n",
    "    \"\"\"\n",
    "    Funkcja zwraca liczbe drzew w lesie forest.\n",
    "    \n",
    "    forest - las drzew [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "    \n",
    "    _check_sentence(forest,\"forest\")\n",
    "    \n",
    "    return int(forest.find(\"stats\").attrib[\"trees\"])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_node(tree, node_id):\n",
    "    return(tree.find(\".//node[@nid='\" + str(node_id) + \"']\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_ambigous(node):\n",
    "    if len(node.findall(\"children\"))>1:\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_terminal(node):\n",
    "    if node.find(\"terminal\"):\n",
    "        return(True)\n",
    "    else:\n",
    "        return(False)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_abmigous_node_to_disjunctive_nodes(node, root, max_id_of_conjunctive_nodes):\n",
    " \n",
    "    \"\"\"\n",
    "    Funkcja modyfikuje node przez referencje!\n",
    "    \"\"\"\n",
    "\n",
    "    number_of_disjunctive_nodes = 0\n",
    "\n",
    "    childrens = node.findall(\"children\")\n",
    "\n",
    "    disjunctive_children = ET.Element('children')\n",
    "\n",
    "    node.set(\"type\",\"conjunctive_node_with_disjunctive_children\")\n",
    "    \n",
    "    for children in list(childrens):\n",
    "\n",
    "        new_disjunctive_node = ET.SubElement(root, 'node')\n",
    "        new_disjunctive_node.set(\"type\", \"disjunctive\")\n",
    "        number_of_disjunctive_nodes += 1\n",
    "\n",
    "        new_id = str(max_id_of_conjunctive_nodes+number_of_disjunctive_nodes)\n",
    "        new_disjunctive_node.set(\"nid\",new_id)\n",
    "\n",
    "        disjuntive_child = ET.SubElement(disjunctive_children, 'child')\n",
    "        disjuntive_child.set(\"nid\",new_id)\n",
    "\n",
    "        new_disjunctive_node.set(\"chosen\",children.attrib.get(\"chosen\",\"false\"))\n",
    "        category = ET.SubElement(new_disjunctive_node, 'nonterminal')\n",
    "        category = ET.SubElement(category, 'category')\n",
    "        category.text = \"disjunctive_node\"\n",
    "        new_disjunctive_node.append(deepcopy(children))\n",
    "\n",
    "        node.remove(children)\n",
    "\n",
    "    node.append(disjunctive_children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_maximum_node_id(tree):\n",
    "    return(np.max([int(node.attrib[\"nid\"]) for node in tree.findall(\"node\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_graph_with_con_and_dis_nodes(tree):\n",
    "    \n",
    "    max_id_of_conjunctive_nodes = get_maximum_node_id(tree)\n",
    "    root = tree.getroot()\n",
    "\n",
    "    for node_id in range(max_id_of_conjunctive_nodes+1):\n",
    "\n",
    "        node = get_node(tree, node_id)\n",
    "        node.set(\"type\", \"terminal\" if is_terminal(node) else \"conjunctive\")\n",
    "\n",
    "        if is_ambigous(node):\n",
    "\n",
    "            transform_abmigous_node_to_disjunctive_nodes(node, root, get_maximum_node_id(tree))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse('../Składnica-frazowa-171220/NKJP_1M_0402000001/morph_3-p/morph_3.9-s.xml')\n",
    "#ET.dump(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree = ET.parse(\"../Składnica-frazowa-171220/NKJP_1M_2002000137/morph_3-p/morph_3.36-s.xml\")\n",
    "#ET.dump(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_to_graph_with_con_and_dis_nodes(tree)\n",
    "#ET.dump(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def terminals(tree):\n",
    "\n",
    "    terminal_nodes = [x for x in tree.findall(\"node[terminal]\")]\n",
    "\n",
    "    terminals = [[(x.attrib[\"nid\"],\n",
    "                   x.find(\"terminal//orth\").text.replace(\" \", \"\"),  # zdarzaja sie przypadki ze token zawiera w sobie spacje i potem wyglada to jakby bylo wiecej tokenow i sie dlugosc nie zgadza\n",
    "                   x.find(\"terminal//base\").text, \n",
    "                   x.find(\"terminal//f\").text)]  for x in terminal_nodes]\n",
    "\n",
    "    ids = [x[0][0] for x in terminals]\n",
    "\n",
    "    return terminals, ids \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ids(tree):\n",
    "    \n",
    "    _ , ids = terminals(tree) \n",
    "    \n",
    "    while \"0\" not in ids:\n",
    "\n",
    "        for nid in ids:\n",
    "            t = time.time()\n",
    "            parents = tree.findall(\".//children/child[@nid='\"+str(nid)+\"']....\")\n",
    "\n",
    "            for parent in parents:\n",
    "                childs = parent.findall(\"children/child\")\n",
    "                childs_ids = [child.attrib[\"nid\"] for child in childs]\n",
    "                if np.all([child_id in ids for child_id in childs_ids]) and parent.attrib[\"nid\"] not in ids:\n",
    "                    ids.append(parent.attrib[\"nid\"])\n",
    "\n",
    "    return(ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def type_of_node(node):\n",
    "    return(node.attrib[\"type\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def token(terminal):\n",
    "    assert is_terminal(terminal)\n",
    "    return(terminal.find(\"terminal//orth\").text.replace(\" \", \"\")) # zdarzaja sie sytuacje, ze w tokenie jest spacja co psuje strukture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_head(tree, node_id):\n",
    "    \n",
    "    node = get_node(tree, node_id)\n",
    "    \n",
    "    if type_of_node(node) == \"terminal\":\n",
    "        return(token(node))\n",
    "    \n",
    "\n",
    "    if type_of_node(node) == \"disjunctive\":      \n",
    "        try:\n",
    "            head_child_id = node.find(\"children/child[@head='true']\").attrib[\"nid\"]\n",
    "            return(get_head(tree, head_child_id))\n",
    "        except:\n",
    "            return(\"__head_unknown__\")\n",
    "    \n",
    "    \n",
    "    children = node.findall(\"children\")\n",
    "    childs = node.findall(\"children/child\")\n",
    "    if len(children)==1 and type_of_node(get_node(tree,childs[0].attrib[\"nid\"])) != \"disjunctive\": # wierzcholek jest koniunktywny i ma dzieci koninktywne\n",
    "        try:\n",
    "            head_child_id = node.find(\"children/child[@head='true']\").attrib[\"nid\"]\n",
    "            return(get_head(tree, head_child_id))\n",
    "        except:\n",
    "            return(\"__head_unknown__\")\n",
    "    \n",
    "        \n",
    "    else: #mamy wierzcholek koniunktywny, ktorego dzieci sa dysjunktywne\n",
    "        \n",
    "        child_ids = [child.attrib[\"nid\"] for child in node.findall(\"children/child\")]\n",
    "        heads = [get_head(tree, child_id) for child_id in child_ids]\n",
    "        if len(set(heads))==1: #wszystkie opcje maja taka sama glowe\n",
    "            return(heads[0])# to glowa wierzcholka dysjunktywnego jest wyznaczona, bo niezalezo od opcji\n",
    "        else:\n",
    "            return(\"__node_with_undetermined_head__\")\n",
    "        #MOZNA TEZ ROZWAZYC CZY NIE POWINNA BYC TO SREDNIA Z EMBEDDINGOW MOZLIWYCH HEAD'OW\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children_rule(tree, node):\n",
    "    \n",
    "    if is_terminal(node):\n",
    "        return(\"__terminal__\")\n",
    "    \n",
    "    \n",
    "    children = node.find(\"children\")\n",
    "    \n",
    "    if \"rule\" in children.attrib.keys():\n",
    "        return(children.attrib[\"rule\"])\n",
    "    else:\n",
    "        children_rules = [get_children_rule(tree,get_node(tree,child.attrib[\"nid\"])) for child in children.findall(\"child\")]\n",
    "        if len(set(children_rules))==1:\n",
    "            return(children_rules[0])\n",
    "        else:\n",
    "            return(\"__node_with_undetermined_children_rule__\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info(tree, nid):\n",
    "    \n",
    "    node = get_node(tree, nid)\n",
    "    \n",
    "    if type_of_node(node) == \"terminal\":\n",
    "        \n",
    "        infos = [get_children_rule(tree, node),\n",
    "                 node.find(\"terminal//base\").text, \n",
    "                 node.find(\"terminal//f\").text]\n",
    "    else:\n",
    "        \n",
    "        \n",
    "        children_rule = get_children_rule(tree, node)\n",
    "        \n",
    "        infos = [x.text for x in node.find(\"nonterminal\").getchildren()]\n",
    "        categories = infos[0]\n",
    "        attributes = \":\".join(infos[1:]) if len(infos)>1 else \"None\"\n",
    "        infos = [children_rule, categories, attributes]\n",
    "        \n",
    "        # JESLI NA ZBIORZE TESTOWYM POJAWIA SIE KOMBINACJA ATRYBUTOW, KTOREJ NIE BYLO W ZBIORZE TRENINGOWYM, \n",
    "        # TO PRZYPISAC W JEJ MIEJSCE NAJBARDZIEJ PODOBNA \n",
    "        # - TYLKO TRZEBA MERYTORYCZNIE WLASCIWIE OKRESLIC PODOBIENSTWO\n",
    "        \n",
    "    return(infos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_children_positions_in_graph(tree, node_id, ids):\n",
    "    \n",
    "    node = get_node(tree,node_id)\n",
    "    \n",
    "    if is_terminal(node):\n",
    "        return([-1])\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        children_ids = [child.attrib[\"nid\"] for child in node.findall(\"children/child\")]\n",
    "        children_positions = [ids.index(child_id) for child_id in children_ids]\n",
    "        return(children_positions)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_chosen(node):\n",
    "    if node.attrib[\"chosen\"]==\"true\":\n",
    "        return(1)\n",
    "    else:\n",
    "        return(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labels(tree, ids):\n",
    "    labels = [-1 if type_of_node(get_node(tree,node_id)) != \"disjunctive\" else is_chosen(get_node(tree,node_id)) for node_id in ids]\n",
    "    return(labels)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<forest grammar_no=\"1505562921\" sent_id=\"NKJP_1M_2002000137/morph_3-p/morph_3.36-s\">\n",
      "  <text>Niby tak.</text>\n",
      "  <startnode from=\"0\" to=\"3\">wypowiedzenie</startnode>\n",
      "  <stats cputime=\"0.006228415000000001\" inferences=\"18193\" nodes=\"20\" trees=\"6\" />\n",
      "    <answer-data>\n",
      "        <base-answer type=\"FULL\" username=\"none\">\n",
      "            <comment>AUTO</comment>\n",
      "        </base-answer>\n",
      "        <extra-answer type=\"FULL\" username=\"alicjaw\">\n",
      "            <comment>AUTO</comment>\n",
      "        </extra-answer>\n",
      "        <extra-answer type=\"FULL\" username=\"agataw\">\n",
      "            <comment>AUTO</comment>\n",
      "        </extra-answer>\n",
      "    </answer-data>\n",
      "  <node chosen=\"true\" from=\"0\" nid=\"0\" subtrees=\"6\" to=\"3\" type=\"conjunctive_node_with_disjunctive_children\">\n",
      "    <nonterminal>\n",
      "      <category>wypowiedzenie</category>\n",
      "    </nonterminal>\n",
      "    <children><child nid=\"20\" /><child nid=\"21\" /><child nid=\"22\" /></children></node>\n",
      "  <node chosen=\"false\" from=\"0\" nid=\"1\" subtrees=\"2\" to=\"2\" type=\"conjunctive_node_with_disjunctive_children\">\n",
      "    <nonterminal>\n",
      "      <category>zdanie</category>\n",
      "      <f type=\"wyróżnik\">bc([xp(pron)])</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"tryb\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children><child nid=\"23\" /><child nid=\"24\" /></children></node>\n",
      "  <node chosen=\"false\" from=\"0\" nid=\"2\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fw</category>\n",
      "      <f type=\"tfw\">xp(pron)</f>\n",
      "      <f type=\"lex\">[pos,tak]</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"poz\">pre</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"wy9\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"3\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"0\" nid=\"3\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fps</category>\n",
      "      <f type=\"lex\">tak</f>\n",
      "      <f type=\"stopień\">row</f>\n",
      "      <f type=\"klasa\">mod</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"true\" rule=\"psm3\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"4\" to=\"1\" />\n",
      "      <child from=\"1\" head=\"true\" nid=\"6\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"0\" nid=\"4\" subtrees=\"1\" to=\"1\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>modpart</category>\n",
      "      <f type=\"klasa\">fpt</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"true\" rule=\"mp1\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"5\" to=\"1\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"0\" nid=\"5\" subtrees=\"1\" to=\"1\" type=\"terminal\">\n",
      "    <terminal disamb=\"true\" interp_id=\"morph_3.34.3.1-msd\" token_id=\"morph_3.34-seg\">\n",
      "      <orth>Niby</orth>\n",
      "      <base>niby</base>\n",
      "      <f type=\"tag\">qub</f>\n",
      "    </terminal>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"1\" nid=\"6\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fps</category>\n",
      "      <f type=\"lex\">tak</f>\n",
      "      <f type=\"stopień\">row</f>\n",
      "      <f type=\"klasa\">tk</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"true\" rule=\"ps1\">\n",
      "      <child from=\"1\" head=\"true\" nid=\"7\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"1\" nid=\"7\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>formaprzys</category>\n",
      "      <f type=\"lex\">tak</f>\n",
      "      <f type=\"stopień\">row</f>\n",
      "      <f type=\"klasa\">tk</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"true\" rule=\"eps4\">\n",
      "      <child from=\"1\" head=\"true\" nid=\"8\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"1\" nid=\"8\" subtrees=\"1\" to=\"2\" type=\"terminal\">\n",
      "    <terminal disamb=\"true\" interp_id=\"morph_3.35.1.2-msd\" token_id=\"morph_3.35-seg\">\n",
      "      <orth>tak</orth>\n",
      "      <base>tak</base>\n",
      "      <f type=\"tag\">padv</f>\n",
      "    </terminal>\n",
      "  </node>\n",
      "  <node chosen=\"false\" from=\"0\" nid=\"9\" subtrees=\"1\" to=\"1\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fl</category>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"lu4\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"10\" to=\"1\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"false\" from=\"0\" nid=\"10\" subtrees=\"1\" to=\"1\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>modpart</category>\n",
      "      <f type=\"klasa\">fin</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"mp1\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"5\" to=\"1\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"false\" from=\"1\" nid=\"11\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fw</category>\n",
      "      <f type=\"tfw\">xp(pron)</f>\n",
      "      <f type=\"lex\">[pos,tak]</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"poz\">post</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"wy9\">\n",
      "      <child from=\"1\" head=\"true\" nid=\"6\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"2\" nid=\"12\" subtrees=\"1\" to=\"3\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>znakkonca</category>\n",
      "      <f type=\"dest\">neut</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"true\" rule=\"int2\">\n",
      "      <child from=\"2\" head=\"true\" nid=\"13\" to=\"3\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"2\" nid=\"13\" subtrees=\"1\" to=\"3\" type=\"terminal\">\n",
      "    <terminal disamb=\"true\" interp_id=\"morph_3.36.1.1-msd\" nps=\"true\" token_id=\"morph_3.36-seg\">\n",
      "      <orth>.</orth>\n",
      "      <base>.</base>\n",
      "      <f type=\"tag\">interp</f>\n",
      "    </terminal>\n",
      "  </node>\n",
      "  <node chosen=\"false\" from=\"0\" nid=\"14\" subtrees=\"2\" to=\"2\" type=\"conjunctive_node_with_disjunctive_children\">\n",
      "    <nonterminal>\n",
      "      <category>zdanie</category>\n",
      "      <f type=\"wyróżnik\">bc([xp(mod)])</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"tryb\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children><child nid=\"25\" /><child nid=\"26\" /></children></node>\n",
      "  <node chosen=\"false\" from=\"0\" nid=\"15\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fw</category>\n",
      "      <f type=\"tfw\">xp(mod)</f>\n",
      "      <f type=\"lex\">[pos,tak]</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"poz\">pre</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"wy9\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"3\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"false\" from=\"1\" nid=\"16\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fw</category>\n",
      "      <f type=\"tfw\">xp(mod)</f>\n",
      "      <f type=\"lex\">[pos,tak]</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"poz\">post</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"wy9\">\n",
      "      <child from=\"1\" head=\"true\" nid=\"6\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"true\" from=\"0\" nid=\"17\" subtrees=\"2\" to=\"2\" type=\"conjunctive_node_with_disjunctive_children\">\n",
      "    <nonterminal>\n",
      "      <category>zdanie</category>\n",
      "      <f type=\"wyróżnik\">bc([])</f>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"tryb\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children><child nid=\"27\" /><child nid=\"28\" /></children></node>\n",
      "  <node chosen=\"true\" from=\"0\" nid=\"18\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fl</category>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"true\" rule=\"lu3\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"3\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "  <node chosen=\"false\" from=\"1\" nid=\"19\" subtrees=\"1\" to=\"2\" type=\"conjunctive\">\n",
      "    <nonterminal>\n",
      "      <category>fl</category>\n",
      "      <f type=\"aspekt\">_</f>\n",
      "      <f type=\"czas\">_</f>\n",
      "      <f type=\"rodzaj\">_</f>\n",
      "      <f type=\"liczba\">_</f>\n",
      "      <f type=\"osoba\">_</f>\n",
      "      <f type=\"neg\">_</f>\n",
      "      <f type=\"dest\">neut</f>\n",
      "      <f type=\"ink\">ni</f>\n",
      "    </nonterminal>\n",
      "    <children chosen=\"false\" rule=\"lu3\">\n",
      "      <child from=\"1\" head=\"true\" nid=\"6\" to=\"2\" />\n",
      "    </children>\n",
      "  </node>\n",
      "<node chosen=\"false\" nid=\"20\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"w\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"1\" to=\"2\" />\n",
      "      <child from=\"2\" head=\"false\" nid=\"12\" to=\"3\" />\n",
      "    </children>\n",
      "    </node><node chosen=\"false\" nid=\"21\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"w\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"14\" to=\"2\" />\n",
      "      <child from=\"2\" head=\"false\" nid=\"12\" to=\"3\" />\n",
      "    </children>\n",
      "    </node><node chosen=\"true\" nid=\"22\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"true\" rule=\"w\">\n",
      "      <child from=\"0\" head=\"true\" nid=\"17\" to=\"2\" />\n",
      "      <child from=\"2\" head=\"false\" nid=\"12\" to=\"3\" />\n",
      "    </children>\n",
      "  </node><node chosen=\"false\" nid=\"23\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"bc1\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"2\" to=\"2\" />\n",
      "    </children>\n",
      "    </node><node chosen=\"false\" nid=\"24\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"bc2\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"9\" to=\"1\" />\n",
      "      <child from=\"1\" head=\"false\" nid=\"11\" to=\"2\" />\n",
      "    </children>\n",
      "  </node><node chosen=\"false\" nid=\"25\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"bc1\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"15\" to=\"2\" />\n",
      "    </children>\n",
      "    </node><node chosen=\"false\" nid=\"26\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"bc2\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"9\" to=\"1\" />\n",
      "      <child from=\"1\" head=\"false\" nid=\"16\" to=\"2\" />\n",
      "    </children>\n",
      "  </node><node chosen=\"true\" nid=\"27\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"true\" rule=\"bc2\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"18\" to=\"2\" />\n",
      "    </children>\n",
      "    </node><node chosen=\"false\" nid=\"28\" type=\"disjunctive\"><nonterminal><category>disjunctive_node</category></nonterminal><children chosen=\"false\" rule=\"bc2\">\n",
      "      <child from=\"0\" head=\"false\" nid=\"9\" to=\"1\" />\n",
      "      <child from=\"1\" head=\"false\" nid=\"19\" to=\"2\" />\n",
      "    </children>\n",
      "  </node></forest>\n"
     ]
    }
   ],
   "source": [
    "ET.dump(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Element 'node' at 0x7f1ee56c0e58>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node = get_node(tree, 5)\n",
    "node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "category = node.find(\".//category\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_rule(tree, node_id):\n",
    "    \n",
    "    node = get_node(tree, node_id)\n",
    "    \n",
    "    node_type = type_of_node(node)\n",
    "    \n",
    "    if node_type == \"conjunctive\" or node_type == \"conjunctive_node_with_disjunctive_children\":\n",
    "        \n",
    "        rule = node.find(\".//category\").text\n",
    "    \n",
    "    elif node_type == \"terminal\":\n",
    "        \n",
    "        rule = \"terminal\"\n",
    "    \n",
    "    elif node_type == \"disjunctive\":\n",
    "        \n",
    "        rule = \"disjunctive_node\" # to siedzi w: node.find(\".//category\").text\n",
    "    \n",
    "    return(rule)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_representation(tree, words2ids, rules2ids):\n",
    "    \n",
    "    ids = get_ids(tree)\n",
    "    children_matrix = seq.pad_sequences([get_children_positions_in_graph(tree,x,ids) for x in ids],value=-1, padding='post')\n",
    "    labels = get_labels(tree, ids)\n",
    "    heads = [words2ids.get(get_head(tree,x),-1) for x in ids]\n",
    "    rules = [rules2ids.get(get_rule(tree,x),-1) for x in ids]\n",
    "    \n",
    "    types = [int(type_of_node(get_node(tree,i)) == \"conjunctive_node_with_disjunctive_children\")+\n",
    "             2*int(type_of_node(get_node(tree,i)) == \"disjunctive\")\n",
    "             for i in ids]\n",
    "    return([heads, \n",
    "            rules,\n",
    "             children_matrix,\n",
    "             labels,\n",
    "             list(range(len(children_matrix))),\n",
    "           types])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import os\n",
    "import itertools\n",
    "import pickle\n",
    "import  csv\n",
    "from collections import Counter, OrderedDict\n",
    "\n",
    "from keras.preprocessing import sequence as seq\n",
    "\n",
    "import os    \n",
    "os.environ['THEANO_FLAGS'] = \"optimizer = None\"\n",
    "\n",
    "import theano\n",
    "from theano import tensor as T\n",
    "from theano.ifelse import ifelse\n",
    "from theano.sandbox.rng_mrg import MRG_RandomStreams as RandomStreams \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TreeLSTM(object):  \n",
    "\n",
    "    def __init__(self, h_dim, nc, w2v_model_path, file_with_rules, \n",
    "                 rules_emb_dim, max_phrase_length, emb_dropout_rate, h_dropout_rate, l, srng,\n",
    "                load_params=None): \n",
    "\n",
    "        '''\n",
    "\n",
    "        - dropout stanu ukrytego (LSTM_1)\n",
    "        - dropout embeddinga (LSTM_1)\n",
    "        - regularyzacja l2 (LSTM_1)\n",
    "        - indywidualna obsluga lisci - struktura taka sama, macierze te same, ale uczymy: h_aggregated_0, hidden_state_0, cell_state_0, zamiast brac w te miejsca 0\n",
    "\n",
    "\n",
    "        nh :: dimension of hidden state\n",
    "        nc :: number of classes\n",
    "        '''\n",
    "\n",
    "        self.max_phrase_length = max_phrase_length\n",
    "\n",
    "        w2vecs = pickle.load(open(w2v_model_path,\"rb\"))\n",
    "        self.emb = theano.shared(w2vecs[\"vectors\"].astype(theano.config.floatX))\n",
    "        self.words2ids = w2vecs[\"words2ids\"]\n",
    "\n",
    "        emb_dim = w2vecs[\"vectors\"].shape[1]\n",
    "        del w2vecs\n",
    "\n",
    "        \n",
    "        r = open(file_with_rules,\"r\")\n",
    "        rules = [x.split() for x in r.readlines()]\n",
    "        r.close()\n",
    "        unique_rules = set()\n",
    "        for i in range(len(rules)):\n",
    "            for j in range(len(rules[i])):\n",
    "                unique_rules.add(rules[i][j])\n",
    "        \n",
    "        unique_rules.add(\"terminal\")\n",
    "        unique_rules.add(\"disjunctive_node\")\n",
    "        \n",
    "        number_of_uniue_rules = len(unique_rules)\n",
    " \n",
    "        r = 0.05\n",
    "\n",
    "        self.rules2ids = dict(zip(unique_rules,range(number_of_uniue_rules)))\n",
    "        self.emb_rules = theano.shared(r * np.random.uniform(-1,1,(number_of_uniue_rules+1, rules_emb_dim)).astype(theano.config.floatX))\n",
    "        \n",
    "   \n",
    "\n",
    "        self.W_i = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_i = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_i = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_f = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_f = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_f = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "        \n",
    "        self.W_o = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_o = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_o = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_u = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_u = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_u = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_y   = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, nc)).astype(theano.config.floatX))\n",
    "        self.b_y   = theano.shared(r * np.random.uniform(-1.0, 1.0, nc).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "\n",
    "        self.W_i_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_i_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_i_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_f_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_f_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_f_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "        \n",
    "        self.W_o_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_o_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_o_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        self.W_u_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (emb_dim+rules_emb_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.U_u_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, (h_dim, h_dim) ).astype(theano.config.floatX))\n",
    "        self.b_u_dis = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "        \n",
    "        \n",
    "\n",
    "\n",
    "        self.h_aggregated_0 = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "        self.cell_state_0 = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "        self.hidden_state_0 = theano.shared(r * np.random.uniform(-1.0, 1.0, h_dim ).astype(theano.config.floatX))\n",
    "\n",
    "\n",
    "\n",
    "        self.srng = srng\n",
    "        self.h_dropout_rate = h_dropout_rate\n",
    "        self.emb_dropout_rate = emb_dropout_rate\n",
    "        self.l = l\n",
    "\n",
    "\n",
    "        if load_params:\n",
    "            load_params = pickle.load(open(load_params,\"rb\"))\n",
    "            if type(load_params)==list:\n",
    "                load_params = dict(load_params)\n",
    "            for key in load_params.keys():\n",
    "                if key not in ['emb', 'emb_rules', 'W_i', 'U_i', 'b_i', 'W_f', 'U_f', 'b_f', 'W_o', 'U_o', 'b_o', 'W_u', 'U_u', 'b_u', 'W_y', 'b_y', 'h_aggregated_0', 'cell_state_0', 'hidden_state_0']:\n",
    "                    setattr(self, key, load_params[key])\n",
    "                else:\n",
    "                    setattr(self, key, theano.shared(load_params[key]))\n",
    "        \n",
    "        \n",
    "\n",
    "        def one_step(word_id, rule_id, word_children_positions, y_true, k, node_type, hidden_states, cell_states, learning_rate):\n",
    "\n",
    "            x = T.concatenate( [self.emb[word_id], self.emb_rules[rule_id] ])\n",
    "\n",
    "            #dropout:\n",
    "            mask1 = self.srng.binomial(n=1, p=1-self.emb_dropout_rate, size=(emb_dim+rules_emb_dim,), dtype='floatX')\n",
    "            x = x * mask1\n",
    "\n",
    "\n",
    "            tmp = word_children_positions>=0.0\n",
    "            number_of_children = tmp.sum(dtype = theano.config.floatX) \n",
    "                  \n",
    "            #idx_tmp = tmp.nonzero()                                    \n",
    "      \n",
    "            h_aggregated = ifelse(T.gt(number_of_children, 0.0), \n",
    "                                  ifelse(T.eq(node_type,1),\n",
    "                                           hidden_states[word_children_positions].mean(axis=0),\n",
    "                                           hidden_states[word_children_positions].sum(axis=0)), \n",
    "                                  self.h_aggregated_0)\n",
    "\n",
    "   \n",
    "            i = ifelse(T.eq(node_type,1),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_i_dis) + T.dot(h_aggregated, self.U_i_dis) + self.b_i_dis),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_i) + T.dot(h_aggregated, self.U_i) + self.b_i))             \n",
    "\n",
    "            o = ifelse(T.eq(node_type,1),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_o_dis) + T.dot(h_aggregated, self.U_o_dis) + self.b_o_dis),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_o) + T.dot(h_aggregated, self.U_o) + self.b_o))             \n",
    "\n",
    "            u = ifelse(T.eq(node_type,1),\n",
    "                         T.tanh(\tT.dot(x, self.W_u_dis) + T.dot(h_aggregated, self.U_u_dis) + self.b_u_dis),\n",
    "                         T.tanh(\tT.dot(x, self.W_u) + T.dot(h_aggregated, self.U_u) + self.b_u))            \n",
    "\n",
    "            f_c = ifelse(T.gt(number_of_children, 0.0), \n",
    "                 ifelse(T.eq(node_type,1),\n",
    "                (T.nnet.sigmoid( T.dot(x, self.W_f_dis ) + T.dot(hidden_states[word_children_positions], self.U_f_dis)  + self.b_f_dis )*cell_states[word_children_positions]).sum(axis=0),          \n",
    "                (T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(hidden_states[word_children_positions], self.U_f)  + self.b_f )*cell_states[word_children_positions]).sum(axis=0)),\n",
    "                T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(self.hidden_state_0, self.U_f)  + self.b_f ) * self.cell_state_0\n",
    "            )\n",
    "\n",
    "\n",
    "            c = i*u + f_c\n",
    "\n",
    "            h = o * T.tanh(c)\n",
    "            \n",
    "            #dropout:\n",
    "            mask = self.srng.binomial(n=1, p=1-self.h_dropout_rate, size=(h_dim,), dtype='floatX')\n",
    "            h = h * mask\n",
    "\n",
    "            current_cell_state = cell_states[k]\n",
    "            cell_states_new = T.set_subtensor(current_cell_state, c)\n",
    "\n",
    "            current_hidden_state = hidden_states[k]\n",
    "            hidden_states_new = T.set_subtensor(current_hidden_state, h)\n",
    "\n",
    "\n",
    "            y_prob = T.nnet.softmax(T.dot(h,self.W_y) + self.b_y)[0]\n",
    "\n",
    "            cross_entropy = ifelse(T.eq(node_type,2), -T.log(y_prob[y_true]), 0.0)\t\t\t\t\t\t      \n",
    "\n",
    "            return cross_entropy, hidden_states_new, cell_states_new  \n",
    "\n",
    "\n",
    "        y = T.vector('y',dtype=dataType)\n",
    "        learning_rate = T.scalar('lr',dtype=theano.config.floatX)\n",
    "        words = T.vector(dtype=dataType)\n",
    "        rules = T.vector(dtype=dataType)\n",
    "        children_positions = T.matrix(dtype=dataType)\n",
    "        words_indexes = T.vector(dtype=dataType)\n",
    "        node_types = T.vector(dtype=dataType)\n",
    "\n",
    "        [cross_entropy_vector, _, _] , _ = theano.scan(fn=one_step, \\\n",
    "                                 sequences = [words, rules, children_positions, y, words_indexes, node_types],\n",
    "                                 outputs_info = [None,\n",
    "                                                 T.zeros((T.shape(words)[0]+1,h_dim), dtype = theano.config.floatX),\n",
    "                                                 T.zeros((T.shape(words)[0]+1,h_dim), dtype = theano.config.floatX)],\n",
    "                                 non_sequences = learning_rate)#,\n",
    "                                 #n_steps = words.shape[0])\n",
    "\n",
    "        cost = T.mean(cross_entropy_vector) #+ self.l * (self.emb_rules**2).sum() \n",
    "        \n",
    "        updates = OrderedDict([\n",
    "            (self.W_i, self.W_i-learning_rate*T.grad(cost, self.W_i)),\n",
    "            (self.W_f, self.W_f-learning_rate*T.grad(cost, self.W_f)),\n",
    "            (self.W_o, self.W_o-learning_rate*T.grad(cost, self.W_o)),\n",
    "            (self.W_u, self.W_u-learning_rate*T.grad(cost, self.W_u)),\n",
    "            (self.W_y, self.W_y-learning_rate*T.grad(cost, self.W_y)),\n",
    "\n",
    "            (self.U_i, self.U_i-learning_rate*T.grad(cost, self.U_i)),\n",
    "            (self.U_f, self.U_f-learning_rate*T.grad(cost, self.U_f)),\n",
    "            (self.U_o, self.U_o-learning_rate*T.grad(cost, self.U_o)),\n",
    "            (self.U_u, self.U_u-learning_rate*T.grad(cost, self.U_u)),\n",
    "\n",
    "            #(self.emb, self.emb-learning_rate*T.grad(cost, self.emb)), #SPROBOWAC TU 0.1 ZAMIAST LR, A DLA POLSKICH BEZ AKTUALIZACJI EMB\n",
    "            #(self.emb_rules, self.emb_rules-learning_rate*T.grad(cost, self.emb_rules)),\n",
    "            (self.b_i, self.b_i-learning_rate*T.grad(cost,self.b_i)),\n",
    "                        (self.b_f, self.b_f-learning_rate*T.grad(cost,self.b_f)),\n",
    "                        (self.b_o, self.b_o-learning_rate*T.grad(cost,self.b_o)),\n",
    "                        (self.b_u, self.b_u-learning_rate*T.grad(cost,self.b_u)),\n",
    "                        (self.b_y, self.b_y-learning_rate*T.grad(cost,self.b_y)),\n",
    "\n",
    "            (self.W_i_dis, self.W_i_dis-learning_rate*T.grad(cost, self.W_i_dis)),\n",
    "            (self.W_f_dis, self.W_f_dis-learning_rate*T.grad(cost, self.W_f_dis)),\n",
    "            (self.W_o_dis, self.W_o_dis-learning_rate*T.grad(cost, self.W_o_dis)),\n",
    "            (self.W_u_dis, self.W_u_dis-learning_rate*T.grad(cost, self.W_u_dis)),\n",
    "\n",
    "            (self.U_i_dis, self.U_i_dis-learning_rate*T.grad(cost, self.U_i_dis)),\n",
    "            (self.U_f_dis, self.U_f_dis-learning_rate*T.grad(cost, self.U_f_dis)),\n",
    "            (self.U_o_dis, self.U_o_dis-learning_rate*T.grad(cost, self.U_o_dis)),\n",
    "            (self.U_u_dis, self.U_u_dis-learning_rate*T.grad(cost, self.U_u_dis)),\n",
    "\n",
    "            #(self.emb, self.emb-learning_rate*T.grad(cost, self.emb)), #SPROBOWAC TU 0.1 ZAMIAST LR, A DLA POLSKICH BEZ AKTUALIZACJI EMB\n",
    "            #(self.emb_rules, self.emb_rules-learning_rate*T.grad(cost, self.emb_rules)),\n",
    "            (self.b_i_dis, self.b_i_dis-learning_rate*T.grad(cost,self.b_i_dis)),\n",
    "                        (self.b_f_dis, self.b_f_dis-learning_rate*T.grad(cost,self.b_f_dis)),\n",
    "                        (self.b_o_dis, self.b_o_dis-learning_rate*T.grad(cost,self.b_o_dis)),\n",
    "                        (self.b_u_dis, self.b_u_dis-learning_rate*T.grad(cost,self.b_u_dis)),            \n",
    "            \n",
    "            \n",
    "            \n",
    "            (self.h_aggregated_0, self.h_aggregated_0-learning_rate*T.grad(cost,self.h_aggregated_0)),\n",
    "            (self.cell_state_0, self.cell_state_0-learning_rate*T.grad(cost,self.cell_state_0)),\n",
    "            (self.hidden_state_0, self.hidden_state_0-learning_rate*T.grad(cost,self.hidden_state_0))\n",
    "\n",
    "            ])\n",
    "\n",
    "        self.train = theano.function( inputs  = [words, rules, children_positions, y, words_indexes, node_types, learning_rate],\n",
    "                                      outputs = [],\n",
    "                                      updates = updates,\n",
    "                                      allow_input_downcast=True,\n",
    "                                      mode='FAST_RUN'\n",
    "                                      )\n",
    "\n",
    "\n",
    "        def one_step_classify(word_id, rule_id, word_children_positions, k, node_type, hidden_states, cell_states):\n",
    "\n",
    "            x = T.concatenate( [self.emb[word_id], self.emb_rules[rule_id] ])\n",
    "\n",
    "            x = (1-self.emb_dropout_rate) * x\n",
    "\n",
    "            tmp = word_children_positions>=0.0\n",
    "            number_of_children = tmp.sum(dtype = theano.config.floatX) \n",
    "            #idx_tmp = tmp.nonzero()                                                                   # indeksy realne dzieci - czyli te, gdzie nie ma -1        \n",
    "\n",
    "            h_aggregated = ifelse(T.gt(number_of_children, 0.0), \n",
    "                                  ifelse(T.eq(node_type,1),\n",
    "                                           hidden_states[word_children_positions].mean(axis=0),\n",
    "                                           hidden_states[word_children_positions].sum(axis=0)), \n",
    "                                  self.h_aggregated_0)\n",
    "\n",
    "\n",
    "            i = ifelse(T.eq(node_type,1),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_i_dis) + T.dot(h_aggregated, self.U_i_dis) + self.b_i_dis),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_i) + T.dot(h_aggregated, self.U_i) + self.b_i))             \n",
    "\n",
    "            o = ifelse(T.eq(node_type,1),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_o_dis) + T.dot(h_aggregated, self.U_o_dis) + self.b_o_dis),\n",
    "                         T.nnet.sigmoid(\tT.dot(x, self.W_o) + T.dot(h_aggregated, self.U_o) + self.b_o))             \n",
    "\n",
    "            u = ifelse(T.eq(node_type,1),\n",
    "                         T.tanh(\tT.dot(x, self.W_u_dis) + T.dot(h_aggregated, self.U_u_dis) + self.b_u_dis),\n",
    "                         T.tanh(\tT.dot(x, self.W_u) + T.dot(h_aggregated, self.U_u) + self.b_u))            \n",
    "\n",
    "            f_c = ifelse(T.gt(number_of_children, 0.0), \n",
    "                 ifelse(T.eq(node_type,1),\n",
    "                    (T.nnet.sigmoid( T.dot(x, self.W_f_dis ) + T.dot(hidden_states[word_children_positions], self.U_f_dis)  + self.b_f_dis )*cell_states[word_children_positions]).sum(axis=0),          \n",
    "                    (T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(hidden_states[word_children_positions], self.U_f)  + self.b_f )*cell_states[word_children_positions]).sum(axis=0)),\n",
    "                T.nnet.sigmoid( T.dot(x, self.W_f ) + T.dot(self.hidden_state_0, self.U_f)  + self.b_f ) * self.cell_state_0\n",
    "            )\n",
    "\n",
    "            c = i*u + f_c\n",
    "\n",
    "            h = o * T.tanh(c)\n",
    "            # podczas uczenia zerowalismy 1-dropout_rate procent wspolrzednych, wiec trzeba to \n",
    "            h = h * (1-self.h_dropout_rate)\n",
    "\n",
    "            current_cell_state = cell_states[k]\n",
    "            cell_states_new = T.set_subtensor(current_cell_state, c)\n",
    "\n",
    "            current_hidden_state = hidden_states[k]\n",
    "            hidden_states_new = T.set_subtensor(current_hidden_state, h)\n",
    "\n",
    "\n",
    "            y_prob = ifelse(T.eq(node_type,2),T.nnet.softmax(T.dot(h,self.W_y) + self.b_y)[0],-1*T.ones(nc))            \n",
    "\n",
    "            return  y_prob, hidden_states_new, cell_states_new\n",
    "\n",
    "\n",
    "        [y_probs_classify, _ , _ ], _ = theano.scan(\n",
    "                 fn=one_step_classify, \n",
    "                                 sequences = [words, rules, children_positions, words_indexes, node_types],\n",
    "                 outputs_info = [None,\n",
    "                                 T.zeros((T.shape(words)[0]+1,h_dim), dtype = theano.config.floatX),\n",
    "                                 T.zeros((T.shape(words)[0]+1,h_dim), dtype = theano.config.floatX)])\n",
    "\n",
    "        predictions, _ = theano.scan(lambda i: T.argmax(y_probs_classify[i]), \n",
    "                                     sequences = [words_indexes])\n",
    "        \n",
    "        probs, _ = theano.scan(lambda i: y_probs_classify[i], \n",
    "                                     sequences = [words_indexes])\n",
    "\n",
    "        self.classify = theano.function(inputs=[words, rules, children_positions, words_indexes, node_types], \n",
    "                                     outputs=predictions,\n",
    "                                     allow_input_downcast=True,\n",
    "                                     mode='FAST_RUN' \n",
    "                                     )\n",
    "\n",
    "        self.predict_proba = theano.function(inputs=[words, rules, children_positions,words_indexes, node_types], \n",
    "                             outputs=probs,\n",
    "                             allow_input_downcast=True,\n",
    "                             mode='FAST_RUN' \n",
    "                             )\n",
    "\n",
    "        self.calculate_loss = theano.function(inputs=[words, rules, children_positions, y, words_indexes, node_types, learning_rate], \n",
    "                     outputs=cost,\n",
    "                     allow_input_downcast=True,\n",
    "                     mode='FAST_RUN' \n",
    "                     )\n",
    "        \n",
    "    def save_model(self,path):\n",
    "        params = [ (k, v.get_value())  if type(v)==theano.tensor.sharedvar.TensorSharedVariable else (k,v) for k, v in list(self.__dict__.items())]\n",
    "        params = dict(params)\n",
    "        pickle.dump(params,open(path,\"wb\"))\n",
    "\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:170: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n",
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:296: UserWarning: DEPRECATION: If x is a vector, Softmax will not automatically pad x anymore in next releases. If you need it, please do it manually. The vector case is gonna be supported soon and the output will be a vector.\n"
     ]
    }
   ],
   "source": [
    "s = {'lr':0.05,\n",
    "         'nepochs':80,\n",
    "         'seed':345,\n",
    "         'nc':2,        # number of y classes\n",
    "         'h_dim': 100,\n",
    "         'h_dropout_rate': 0,\n",
    "         'emb_dropout_rate': 0,\n",
    "         'time_without_improvement': 10,\n",
    "         'batch_size': 1,\n",
    "         'w2v_DIM': str(300),\n",
    "         \"rules_emb_dim\": 50\n",
    "         }  \n",
    "\n",
    "dataType = 'int64'\n",
    "  \n",
    "np.random.seed(s['seed']) \n",
    "\n",
    "#ile_with_filtered_embeddings = \"embeddings/filtered_nkjp+wiki-forms-restricted-300-cbow-ns.pkl\"\n",
    "#2vecs = pickle.load(open(file_with_filtered_embeddings,\"rb\"))\n",
    "\n",
    "rnn = TreeLSTM( h_dim = s['h_dim'],\n",
    "            nc = s['nc'],\n",
    "        w2v_model_path = \"embeddings/filtered_train_and_test_w2v_allwiki_nkjpfull_300.pkl\",\n",
    "            max_phrase_length = 1000,\n",
    "        emb_dropout_rate = s['emb_dropout_rate'],\n",
    "        h_dropout_rate = s['h_dropout_rate'],\n",
    "        l = 0.0001,\n",
    "        srng = RandomStreams(12345),\n",
    "        file_with_rules =  \"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Składnica_preprocessed_training_data/rules.txt\",\n",
    "        rules_emb_dim = s[\"rules_emb_dim\"],\n",
    "        load_params= False#\"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Model/model_params_116.pkl\"\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "10\n",
      "20\n",
      "30\n",
      "40\n",
      "50\n",
      "60\n",
      "70\n",
      "80\n",
      "90\n",
      "100\n",
      "110\n",
      "120\n",
      "130\n",
      "140\n",
      "150\n",
      "160\n",
      "170\n",
      "180\n",
      "190\n",
      "200\n",
      "210\n",
      "220\n",
      "230\n",
      "240\n",
      "250\n",
      "260\n",
      "270\n",
      "280\n",
      "290\n",
      "300\n",
      "310\n",
      "320\n",
      "330\n",
      "340\n",
      "350\n",
      "360\n",
      "370\n",
      "380\n",
      "390\n",
      "400\n",
      "410\n",
      "420\n",
      "430\n",
      "440\n",
      "450\n",
      "460\n",
      "470\n",
      "480\n",
      "490\n",
      "500\n",
      "510\n",
      "520\n",
      "530\n",
      "540\n",
      "550\n",
      "560\n",
      "570\n",
      "580\n",
      "590\n",
      "600\n",
      "610\n",
      "620\n",
      "630\n",
      "640\n",
      "650\n",
      "660\n",
      "670\n",
      "680\n",
      "690\n",
      "700\n",
      "710\n",
      "720\n",
      "730\n",
      "740\n",
      "750\n",
      "760\n",
      "770\n",
      "780\n",
      "790\n",
      "800\n",
      "810\n",
      "820\n",
      "830\n",
      "840\n",
      "850\n",
      "860\n",
      "870\n",
      "880\n",
      "890\n",
      "900\n",
      "910\n",
      "920\n",
      "930\n",
      "940\n",
      "950\n",
      "960\n",
      "970\n",
      "980\n",
      "990\n",
      "1000\n",
      "1010\n",
      "1020\n",
      "1030\n",
      "1040\n",
      "1050\n",
      "1060\n",
      "1070\n",
      "1080\n",
      "1090\n",
      "1100\n",
      "1110\n",
      "1120\n",
      "1130\n",
      "1140\n",
      "1150\n",
      "1160\n",
      "1170\n",
      "1180\n",
      "1190\n",
      "1200\n",
      "1210\n",
      "1220\n",
      "1230\n",
      "1240\n",
      "1250\n",
      "1260\n",
      "1270\n",
      "1280\n",
      "1290\n",
      "1300\n",
      "1310\n",
      "1320\n",
      "1330\n",
      "1340\n",
      "1350\n",
      "1360\n",
      "1370\n",
      "1380\n",
      "1390\n",
      "1400\n",
      "1410\n",
      "1420\n",
      "1430\n",
      "1440\n",
      "1450\n",
      "1460\n",
      "1470\n",
      "1480\n",
      "1490\n",
      "1500\n",
      "1510\n",
      "1520\n",
      "1530\n",
      "1540\n",
      "1550\n",
      "1560\n",
      "1570\n",
      "1580\n",
      "1590\n",
      "1600\n",
      "1610\n",
      "1620\n",
      "1630\n",
      "1640\n",
      "1650\n",
      "1660\n",
      "1670\n",
      "1680\n",
      "1690\n",
      "1700\n",
      "1710\n",
      "1720\n",
      "1730\n",
      "1740\n",
      "1750\n",
      "1760\n",
      "1770\n",
      "1780\n",
      "1790\n",
      "1800\n",
      "1810\n",
      "1820\n",
      "1830\n",
      "1840\n",
      "1850\n",
      "1860\n",
      "1870\n",
      "1880\n",
      "1890\n",
      "1900\n",
      "1910\n",
      "1920\n",
      "1930\n",
      "1940\n",
      "1950\n",
      "1960\n",
      "1970\n",
      "1980\n",
      "1990\n",
      "2000\n",
      "2010\n",
      "2020\n",
      "2030\n",
      "2040\n",
      "2050\n",
      "2060\n",
      "2070\n",
      "2080\n",
      "2090\n",
      "2100\n",
      "2110\n",
      "2120\n",
      "2130\n",
      "2140\n",
      "2150\n",
      "2160\n",
      "2170\n",
      "2180\n",
      "2190\n",
      "2200\n",
      "2210\n",
      "2220\n",
      "2230\n",
      "2240\n",
      "2250\n",
      "2260\n",
      "2270\n",
      "2280\n",
      "2290\n",
      "2300\n",
      "2310\n",
      "2320\n",
      "2330\n",
      "2340\n",
      "2350\n",
      "2360\n",
      "2370\n",
      "2380\n",
      "2390\n",
      "2400\n",
      "2410\n",
      "2420\n",
      "2430\n",
      "2440\n",
      "2450\n",
      "2460\n",
      "2470\n",
      "2480\n",
      "2490\n",
      "2500\n",
      "2510\n",
      "2520\n",
      "2530\n",
      "2540\n",
      "2550\n",
      "2560\n",
      "2570\n",
      "2580\n",
      "2590\n",
      "2600\n",
      "2610\n",
      "2620\n",
      "2630\n",
      "2640\n",
      "2650\n",
      "2660\n",
      "2670\n",
      "2680\n",
      "2690\n",
      "2700\n",
      "2710\n",
      "2720\n",
      "2730\n",
      "2740\n",
      "2750\n",
      "2760\n",
      "2770\n",
      "2780\n",
      "2790\n",
      "2800\n",
      "2810\n",
      "2820\n",
      "2830\n",
      "2840\n",
      "2850\n",
      "2860\n",
      "2870\n",
      "2880\n",
      "2890\n",
      "2900\n",
      "2910\n",
      "2920\n",
      "2930\n",
      "2940\n",
      "2950\n",
      "2960\n",
      "2970\n",
      "2980\n",
      "2990\n",
      "3000\n",
      "3010\n",
      "3020\n",
      "3030\n",
      "3040\n",
      "3050\n",
      "3060\n",
      "3070\n",
      "3080\n",
      "3090\n",
      "3100\n",
      "3110\n",
      "3120\n",
      "3130\n",
      "3140\n",
      "3150\n",
      "3160\n",
      "3170\n",
      "3180\n",
      "3190\n",
      "3200\n",
      "3210\n",
      "3220\n",
      "3230\n",
      "3240\n",
      "3250\n",
      "3260\n",
      "3270\n",
      "3280\n",
      "3290\n",
      "3300\n",
      "3310\n",
      "3320\n",
      "3330\n",
      "3340\n",
      "3350\n",
      "3360\n",
      "3370\n",
      "3380\n",
      "3390\n",
      "3400\n",
      "3410\n",
      "3420\n",
      "3430\n",
      "3440\n",
      "3450\n",
      "3460\n",
      "3470\n",
      "3480\n",
      "3490\n",
      "3500\n",
      "3510\n",
      "3520\n",
      "3530\n",
      "3540\n",
      "3550\n",
      "3560\n",
      "3570\n",
      "3580\n",
      "3590\n",
      "3600\n",
      "3610\n",
      "3620\n",
      "3630\n",
      "3640\n",
      "3650\n",
      "3660\n",
      "3670\n",
      "3680\n",
      "3690\n",
      "3700\n",
      "3710\n",
      "3720\n",
      "3730\n",
      "3740\n",
      "3750\n",
      "3760\n",
      "3770\n",
      "3780\n",
      "3790\n",
      "3800\n",
      "3810\n",
      "3820\n",
      "3830\n",
      "3840\n",
      "3850\n",
      "3860\n",
      "3870\n",
      "3880\n",
      "3890\n",
      "3900\n",
      "3910\n",
      "3920\n",
      "3930\n",
      "3940\n",
      "3950\n",
      "3960\n",
      "3970\n",
      "3980\n",
      "3990\n",
      "4000\n",
      "4010\n",
      "4020\n",
      "4030\n",
      "4040\n",
      "4050\n",
      "4060\n",
      "4070\n",
      "4080\n",
      "4090\n",
      "4100\n",
      "4110\n",
      "4120\n",
      "4130\n",
      "4140\n",
      "4150\n",
      "4160\n",
      "4170\n",
      "4180\n",
      "4190\n",
      "4200\n",
      "4210\n",
      "4220\n",
      "4230\n",
      "4240\n",
      "4250\n",
      "4260\n",
      "4270\n",
      "4280\n",
      "4290\n",
      "4300\n",
      "4310\n",
      "4320\n",
      "4330\n",
      "4340\n",
      "4350\n",
      "4360\n",
      "4370\n",
      "4380\n",
      "4390\n",
      "4400\n",
      "4410\n",
      "4420\n",
      "4430\n",
      "4440\n",
      "4450\n",
      "4460\n",
      "4470\n",
      "4480\n",
      "4490\n",
      "4500\n",
      "4510\n",
      "4520\n",
      "4530\n",
      "4540\n",
      "4550\n",
      "4560\n",
      "4570\n",
      "4580\n",
      "4590\n",
      "4600\n",
      "4610\n",
      "4620\n",
      "4630\n",
      "4640\n",
      "4650\n",
      "4660\n",
      "4670\n",
      "4680\n",
      "4690\n",
      "4700\n",
      "4710\n",
      "4720\n",
      "4730\n",
      "4740\n",
      "4750\n",
      "4760\n",
      "4770\n",
      "4780\n",
      "4790\n",
      "4800\n",
      "4810\n",
      "4820\n",
      "4830\n",
      "4840\n",
      "4850\n",
      "4860\n",
      "4870\n",
      "4880\n",
      "4890\n",
      "4900\n",
      "4910\n",
      "4920\n",
      "4930\n",
      "4940\n",
      "4950\n",
      "4960\n",
      "4970\n",
      "4980\n",
      "4990\n",
      "5000\n",
      "5010\n",
      "5020\n",
      "5030\n",
      "5040\n",
      "5050\n",
      "5060\n",
      "5070\n",
      "5080\n",
      "5090\n",
      "5100\n",
      "5110\n",
      "5120\n",
      "5130\n",
      "5140\n",
      "5150\n",
      "5160\n",
      "5170\n",
      "5180\n",
      "5190\n",
      "5200\n",
      "5210\n",
      "5220\n",
      "5230\n",
      "5240\n",
      "5250\n",
      "5260\n",
      "5270\n",
      "5280\n",
      "5290\n",
      "5300\n",
      "5310\n",
      "5320\n",
      "5330\n",
      "5340\n",
      "5350\n",
      "5360\n",
      "5370\n",
      "5380\n",
      "5390\n",
      "5400\n",
      "5410\n",
      "5420\n",
      "5430\n",
      "5440\n",
      "5450\n",
      "5460\n",
      "5470\n",
      "5480\n",
      "5490\n",
      "5500\n",
      "5510\n",
      "5520\n",
      "5530\n",
      "5540\n",
      "5550\n",
      "5560\n",
      "5570\n",
      "5580\n",
      "5590\n",
      "5600\n",
      "5610\n",
      "5620\n",
      "5630\n",
      "5640\n",
      "5650\n",
      "5660\n",
      "5670\n",
      "5680\n",
      "5690\n",
      "5700\n",
      "5710\n",
      "5720\n",
      "5730\n",
      "5740\n",
      "5750\n",
      "5760\n",
      "5770\n",
      "5780\n",
      "5790\n",
      "5800\n",
      "5810\n",
      "5820\n",
      "5830\n",
      "5840\n",
      "5850\n",
      "5860\n",
      "5870\n",
      "5880\n",
      "5890\n",
      "5900\n",
      "5910\n",
      "5920\n",
      "5930\n",
      "5940\n",
      "5950\n",
      "5960\n",
      "5970\n",
      "5980\n",
      "5990\n",
      "6000\n",
      "6010\n",
      "6020\n",
      "6030\n",
      "6040\n",
      "6050\n",
      "6060\n",
      "6070\n",
      "6080\n",
      "6090\n",
      "6100\n",
      "6110\n",
      "6120\n",
      "6130\n",
      "6140\n",
      "6150\n",
      "6160\n",
      "6170\n",
      "6180\n",
      "6190\n",
      "6200\n",
      "6210\n",
      "6220\n",
      "6230\n",
      "6240\n",
      "6250\n",
      "6260\n",
      "6270\n",
      "6280\n",
      "6290\n",
      "6300\n",
      "6310\n",
      "6320\n",
      "6330\n",
      "6340\n",
      "6350\n",
      "6360\n",
      "6370\n",
      "6380\n",
      "6390\n",
      "6400\n",
      "6410\n",
      "6420\n",
      "6430\n",
      "6440\n",
      "6450\n",
      "6460\n",
      "6470\n",
      "6480\n",
      "6490\n",
      "6500\n",
      "6510\n",
      "6520\n",
      "6530\n",
      "6540\n",
      "6550\n",
      "6560\n",
      "6570\n",
      "6580\n",
      "6590\n",
      "6600\n",
      "6610\n",
      "6620\n",
      "6630\n",
      "6640\n",
      "6650\n",
      "6660\n",
      "6670\n",
      "6680\n",
      "6690\n",
      "6700\n",
      "6710\n",
      "6720\n",
      "6730\n",
      "6740\n",
      "6750\n",
      "6760\n",
      "6770\n",
      "6780\n",
      "6790\n",
      "6800\n",
      "6810\n",
      "6820\n",
      "6830\n",
      "6840\n",
      "6850\n",
      "6860\n",
      "6870\n",
      "6880\n",
      "6890\n",
      "6900\n",
      "6910\n",
      "6920\n",
      "6930\n",
      "6940\n",
      "6950\n",
      "6960\n",
      "6970\n",
      "6980\n",
      "6990\n",
      "7000\n",
      "7010\n",
      "7020\n",
      "7030\n",
      "7040\n",
      "7050\n",
      "7060\n",
      "7070\n",
      "7080\n",
      "7090\n",
      "7100\n",
      "7110\n",
      "7120\n",
      "7130\n",
      "7140\n",
      "7150\n",
      "7160\n",
      "7170\n",
      "7180\n",
      "7190\n",
      "7200\n",
      "7210\n",
      "7220\n",
      "7230\n",
      "7240\n",
      "7250\n",
      "7260\n",
      "7270\n",
      "7280\n",
      "7290\n",
      "7300\n",
      "7310\n",
      "7320\n",
      "7330\n",
      "7340\n",
      "7350\n",
      "7360\n",
      "7370\n",
      "7380\n",
      "7390\n",
      "7400\n",
      "7410\n",
      "7420\n",
      "7430\n",
      "7440\n",
      "7450\n",
      "7460\n",
      "7470\n",
      "7480\n",
      "7490\n",
      "7500\n",
      "7510\n",
      "7520\n",
      "7530\n",
      "7540\n",
      "7550\n",
      "7560\n",
      "7570\n",
      "7580\n",
      "7590\n",
      "7600\n",
      "7610\n",
      "7620\n",
      "7630\n",
      "7640\n",
      "7650\n",
      "7660\n",
      "7670\n",
      "7680\n",
      "7690\n",
      "7700\n",
      "7710\n",
      "7720\n",
      "7730\n",
      "7740\n",
      "7750\n",
      "7760\n",
      "7770\n",
      "7780\n",
      "7790\n",
      "7800\n",
      "7810\n",
      "7820\n",
      "7830\n",
      "7840\n",
      "7850\n",
      "7860\n",
      "7870\n",
      "7880\n",
      "7890\n",
      "7900\n",
      "7910\n",
      "7920\n",
      "7930\n",
      "7940\n",
      "7950\n",
      "7960\n",
      "7970\n",
      "7980\n",
      "7990\n",
      "8000\n",
      "8010\n",
      "8020\n",
      "8030\n",
      "8040\n",
      "8050\n",
      "8060\n",
      "8070\n",
      "8080\n",
      "8090\n",
      "8100\n",
      "8110\n",
      "8120\n",
      "8130\n",
      "8140\n",
      "8150\n",
      "8160\n",
      "8170\n",
      "8180\n",
      "8190\n",
      "8200\n",
      "8210\n",
      "8220\n",
      "8230\n",
      "8240\n",
      "8250\n",
      "8260\n",
      "8270\n",
      "8280\n",
      "8290\n",
      "8300\n",
      "8310\n",
      "8320\n",
      "8330\n",
      "8340\n",
      "8350\n",
      "8360\n",
      "8370\n",
      "8380\n",
      "8390\n",
      "8400\n",
      "8410\n",
      "8420\n",
      "8430\n",
      "8440\n",
      "8450\n",
      "8460\n",
      "8470\n",
      "8480\n",
      "8490\n",
      "8500\n",
      "8510\n",
      "8520\n",
      "8530\n",
      "8540\n",
      "8550\n",
      "8560\n",
      "8570\n",
      "8580\n",
      "8590\n",
      "8600\n",
      "8610\n",
      "8620\n",
      "8630\n",
      "8640\n",
      "8650\n",
      "8660\n",
      "8670\n",
      "8680\n",
      "8690\n",
      "8700\n",
      "8710\n",
      "8720\n",
      "8730\n",
      "8740\n",
      "8750\n",
      "8760\n",
      "8770\n",
      "8780\n",
      "8790\n",
      "8800\n",
      "8810\n",
      "8820\n",
      "8830\n",
      "8840\n",
      "8850\n",
      "8860\n",
      "8870\n",
      "8880\n",
      "8890\n",
      "8900\n",
      "8910\n",
      "8920\n",
      "8930\n",
      "8940\n",
      "8950\n",
      "8960\n",
      "8970\n",
      "8980\n",
      "8990\n",
      "9000\n",
      "9010\n",
      "9020\n",
      "9030\n",
      "9040\n",
      "9050\n",
      "9060\n",
      "9070\n",
      "9080\n",
      "9090\n",
      "9100\n",
      "9110\n",
      "9120\n",
      "9130\n",
      "9140\n",
      "9150\n",
      "9160\n",
      "9170\n",
      "9180\n",
      "9190\n",
      "9200\n",
      "9210\n",
      "9220\n",
      "9230\n",
      "9240\n",
      "9250\n",
      "9260\n",
      "9270\n",
      "9280\n",
      "9290\n",
      "9300\n",
      "9310\n",
      "9320\n",
      "9330\n",
      "9340\n",
      "9350\n",
      "9360\n",
      "9370\n",
      "9380\n",
      "9390\n",
      "9400\n",
      "9410\n",
      "9420\n",
      "9430\n",
      "9440\n",
      "9450\n",
      "9460\n",
      "9470\n",
      "9480\n",
      "9490\n",
      "9500\n"
     ]
    }
   ],
   "source": [
    "data_folder = \"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Składnica_raw_data/Train/*.xml\"\n",
    "files = glob.glob(data_folder,recursive=True)\n",
    "data = []\n",
    "for i, file in enumerate(files):\n",
    "    if i % 10 == 0:\n",
    "        print(i)\n",
    "    forest = ET.parse(file)\n",
    "    if number_of_trees_in_forest(forest) < 100000:\n",
    "        transform_to_graph_with_con_and_dis_nodes(forest)\n",
    "        data.append(get_representation(forest,rnn.words2ids,rnn.rules2ids))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[1367,\n",
       "  77,\n",
       "  136,\n",
       "  6,\n",
       "  16496,\n",
       "  -1,\n",
       "  1367,\n",
       "  77,\n",
       "  136,\n",
       "  6,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  -1,\n",
       "  1367,\n",
       "  77,\n",
       "  77,\n",
       "  136,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  1367,\n",
       "  1367,\n",
       "  77,\n",
       "  136,\n",
       "  136,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  1367,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496,\n",
       "  16496],\n",
       " [15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  15,\n",
       "  48,\n",
       "  69,\n",
       "  39,\n",
       "  74,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  37,\n",
       "  10,\n",
       "  67,\n",
       "  67,\n",
       "  67,\n",
       "  60,\n",
       "  109,\n",
       "  109,\n",
       "  109,\n",
       "  109,\n",
       "  54,\n",
       "  67,\n",
       "  54,\n",
       "  54,\n",
       "  70,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  42,\n",
       "  42,\n",
       "  54,\n",
       "  42,\n",
       "  42,\n",
       "  38,\n",
       "  110],\n",
       " array([[-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [-1, -1, -1, -1],\n",
       "        [ 0, -1, -1, -1],\n",
       "        [ 1, -1, -1, -1],\n",
       "        [ 2, -1, -1, -1],\n",
       "        [ 3, -1, -1, -1],\n",
       "        [ 4, -1, -1, -1],\n",
       "        [ 4, -1, -1, -1],\n",
       "        [ 4, -1, -1, -1],\n",
       "        [ 4, -1, -1, -1],\n",
       "        [ 5, -1, -1, -1],\n",
       "        [ 6, -1, -1, -1],\n",
       "        [ 7, -1, -1, -1],\n",
       "        [ 7, -1, -1, -1],\n",
       "        [ 8, -1, -1, -1],\n",
       "        [ 9, 10, -1, -1],\n",
       "        [ 9, 11, -1, -1],\n",
       "        [ 9, 12, -1, -1],\n",
       "        [ 9, 13, -1, -1],\n",
       "        [15, -1, -1, -1],\n",
       "        [15, 17, -1, -1],\n",
       "        [16, -1, -1, -1],\n",
       "        [18, -1, -1, -1],\n",
       "        [18, -1, -1, -1],\n",
       "        [19, -1, -1, -1],\n",
       "        [20, -1, -1, -1],\n",
       "        [21, -1, -1, -1],\n",
       "        [22, -1, -1, -1],\n",
       "        [23, 25, 26, 28],\n",
       "        [23, 25, 27, 29],\n",
       "        [24, -1, -1, -1],\n",
       "        [34, 26, 30, -1],\n",
       "        [34, 27, 31, -1],\n",
       "        [32, 33, 35, 36],\n",
       "        [37, 14, -1, -1]], dtype=int32),\n",
       " [-1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  -1,\n",
       "  0,\n",
       "  1,\n",
       "  -1,\n",
       "  0,\n",
       "  0,\n",
       "  -1,\n",
       "  -1],\n",
       " [0,\n",
       "  1,\n",
       "  2,\n",
       "  3,\n",
       "  4,\n",
       "  5,\n",
       "  6,\n",
       "  7,\n",
       "  8,\n",
       "  9,\n",
       "  10,\n",
       "  11,\n",
       "  12,\n",
       "  13,\n",
       "  14,\n",
       "  15,\n",
       "  16,\n",
       "  17,\n",
       "  18,\n",
       "  19,\n",
       "  20,\n",
       "  21,\n",
       "  22,\n",
       "  23,\n",
       "  24,\n",
       "  25,\n",
       "  26,\n",
       "  27,\n",
       "  28,\n",
       "  29,\n",
       "  30,\n",
       "  31,\n",
       "  32,\n",
       "  33,\n",
       "  34,\n",
       "  35,\n",
       "  36,\n",
       "  37,\n",
       "  38],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  0,\n",
       "  2,\n",
       "  2,\n",
       "  1,\n",
       "  0]]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(data,open(\"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Składnica_preprocessed_training_data/data_as_graphs.pkl\",\"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pickle.load(open(\"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Składnica_preprocessed_training_data/data_as_graphs.pkl\",\"rb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9051"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(8051, 1000)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#train_ind = pickle.load(open(\"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Model/train_observations\",\"rb\"))\n",
    "#validation_ind = pickle.load(open(\"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Model/validation_observations\",\"rb\"))\n",
    "\n",
    "train_data = data[:8051]\n",
    "validation_data = data[8051:]\n",
    "\n",
    "n_train = len(train_data)\n",
    "n_val = len(validation_data)\n",
    "\n",
    "n_train, n_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "s[\"lr\"] = 0.2 # jesli bedzie skakac: 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "for e in range(100):\n",
    "\n",
    "    tic = time.time()\n",
    "    \n",
    "    random.shuffle(train_data)\n",
    "\n",
    "    tic = time.time()\n",
    "    for i in range(n_train):\n",
    "\n",
    "        if i % 1000 == 0:\n",
    "            print(i)\n",
    "            \n",
    "        if len(data[i][0]) < 6000:\n",
    "            rnn.train(train_data[i][0], train_data[i][1], train_data[i][2], train_data[i][3], train_data[i][4], train_data[i][5], s['lr'])\n",
    "\n",
    "        if i % 5000 == 0:\n",
    "        \n",
    "            loss = 0\n",
    "            counts_test = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "            for k in range(n_val)[::10]:\n",
    "                pred = rnn.classify(validation_data[k][0],validation_data[k][1],validation_data[k][2], validation_data[k][4], validation_data[k][5])\n",
    "                for j in range(len(pred)):\n",
    "                    if validation_data[k][5][j]==2:\n",
    "                        counts_test[pred[j], validation_data[k][3][j]] += 1\n",
    "\n",
    "\n",
    "            # Train\n",
    "            counts = np.zeros((s['nc'],s['nc']),dtype='int')\n",
    "            for k in range(n_train)[::20]:\n",
    "\n",
    "                pred  = rnn.classify(train_data[k][0], train_data[k][1] ,train_data[k][2], train_data[k][4], train_data[k][5])\n",
    "                for j in range(len(pred)):\n",
    "                    if train_data[k][5][j]==2:\n",
    "                        counts[pred[j], train_data[k][3][j]] += 1\n",
    "\n",
    "\n",
    "\n",
    "            print(e, \" Train: \", \"%0.2f\" % (100 * np.diag(counts).sum()/float(counts.sum())),\n",
    "                \" Valid all: \",\"%0.2f\" % (100 * np.diag(counts_test).sum()/float(counts_test.sum())),\n",
    "                \"   time: \", time.time()-tic)\n",
    "        \n",
    "        \n",
    "    \n",
    "    if e>0:# and e%3==0:\n",
    "        rnn.save_model(\"/home/norbert/Doktorat/SyntacticTreesDisambiguation/Model/model_forest_params_\"+str(e)+\".pkl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_random_tree(forest, random_state=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja zwraca losowe drzewo z upakowanego lasu (forest).\n",
    "    Dla lasu, w ktorym nie ma poprawnego drzewa funkcja wyrzuca blad.\n",
    "    \n",
    "    forest - las drzew [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "\n",
    "    # sprawdzenie poprawnosci lasu i ewentualne wypisanie komunikatu\n",
    "    _check_sentence(forest,\"forest\")\n",
    "    \n",
    "    # ustawiamy ziarno\n",
    "    if random_state is not None:\n",
    "        np.random.seed(random_state)\n",
    "            \n",
    "            \n",
    "    root_old = forest.getroot()\n",
    "    root_new = ET.Element(\"tree\",root_old.attrib)\n",
    "    \n",
    "    \n",
    "    # las sklada sie z drzew (wezly \"node\") oraz dodatkowych danych (inne wezly) -\n",
    "    # tresc wypowiedzenia, statystyki lasu, itd. - i tutaj przepisujemy te wezly\n",
    "    features = root_old.getchildren()\n",
    "    for feature in features:\n",
    "        if feature.tag != \"node\": \n",
    "            feature_copy = deepcopy(feature)\n",
    "            if feature_copy.tag == \"stats\":\n",
    "                feature_copy.tag = \"forest-stats\"\n",
    "                \n",
    "            root_new.append(feature_copy) # modyfikujemy tag wezla wiec potrzebna kopia, zeby nie zmodyfikowac oryginalnego drzewa\n",
    "    \n",
    "    # definiujemy wezel ze statystykami drzewa\n",
    "    # robimy to w tym iejscu zeby zachowac logiczna kolejnosc wezlow - zeby wypisywalo sie to na poczatku\n",
    "    # wartosci nadamy nizej\n",
    "    ET.SubElement(root_new, \"tree-stats\", {\"height\":\"0\",\"nodes\":\"0\"})\n",
    "            \n",
    "            \n",
    "    # definiujemy rekurencyjna funkcje, ktora bedzie przechodzic po lesie i\n",
    "    # kolekcjonowac wezly, tworzac losowe drzewo.\n",
    "    # drzewo jest tworzone na korzeniu root_new.\n",
    "    def add_random_children(current_node_old):\n",
    "        \n",
    "        current_node_new = ET.SubElement(root_new, current_node_old.tag, current_node_old.attrib)\n",
    "        \n",
    "        features = current_node_old.getchildren()\n",
    "        # kazdy \"node\" jest terminalem albo nieterminalem i ma opis wlasnosci\n",
    "        # i tutaj wyciagamy te wlasnosci z wezla innego niz \"children\"\n",
    "        for feature in features:\n",
    "            if feature.tag != \"children\": \n",
    "                current_node_new.append(feature)\n",
    "        \n",
    "        children_old = current_node_old.findall(\"children\")\n",
    "        if len(children_old) == 0: #jestesmy w lisciu wiec konczymy dzialanie funkcji\n",
    "            return None\n",
    "        random_children_old = children_old[np.random.choice(len(children_old),1)[0]]\n",
    "        random_children_new = ET.SubElement(current_node_new, random_children_old.tag, random_children_old.attrib)\n",
    "        for child_old in random_children_old.getchildren():\n",
    "            x = ET.SubElement(random_children_new, child_old.tag, child_old.attrib)\n",
    "            next_node = root_old.find('.//node[@nid=\"' + x.attrib[\"nid\"] + '\"]')\n",
    "            add_random_children(next_node)\n",
    "        \n",
    "    \n",
    "        # wezel startowy (przyjmujemy, ze node z id=0 jest zawsze pierwszy):\n",
    "    # TODO: upewnic sie czy to jest poprawne podejscie - czy moze byc inny wezel poczatkowym\n",
    "    node_0 = root_old.find('.//node[@nid=\"0\"]') \n",
    "    \n",
    "    # konstruujemy drzewo:\n",
    "    add_random_children(node_0)\n",
    "    \n",
    "    new_tree = ET.ElementTree(root_new)\n",
    "    \n",
    "    th = _tree_height(new_tree, node_id=0)\n",
    "    \n",
    "    root_new.find(\"tree-stats\").attrib[\"height\"] = str(th)\n",
    "    root_new.find(\"tree-stats\").attrib[\"nodes\"] = str(len(root_new.findall(\"node\")))\n",
    "    \n",
    "    return new_tree\n",
    "       \n",
    " \n",
    "\n",
    "def number_of_trees_in_forest(forest):\n",
    "\n",
    "    \"\"\"\n",
    "    Funkcja zwraca liczbe drzew w lesie forest.\n",
    "    \n",
    "    forest - las drzew [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "    \n",
    "    _check_sentence(forest,\"forest\")\n",
    "    \n",
    "    return int(forest.find(\"stats\").attrib[\"trees\"])\n",
    "    \n",
    "    \n",
    "def get_random_negative_tree(forest, random_state=None):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja zwraca losowe negatywne (niepoprawne) drzewo z lasu forest.\n",
    "    \n",
    "    Gdy las sklada sie tylko z jednego drzewa (poprawnego) to zwracana jest wartosc None.\n",
    "    \n",
    "    forest - las drzew [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "    \n",
    "    _check_sentence(forest,\"forest\")\n",
    "    \n",
    "    \n",
    "    number_of_trees = number_of_trees_in_forest(forest)\n",
    "    \n",
    "    if number_of_trees == 1:\n",
    "        Warning(\"There is only one tree in the forest\")\n",
    "        return None\n",
    "    \n",
    "    else:\n",
    "        while True:\n",
    "            tree = get_random_tree(forest,random_state)\n",
    "            if not is_positive(tree):\n",
    "                return tree\n",
    "    \n",
    "    \n",
    "\n",
    "def get_subtree_label(tree, node):\n",
    "    \n",
    "    if node.find(\"children\") is None:\n",
    "        return 1\n",
    "    \n",
    "    if node.find(\"children\").attrib.get(\"chosen\",\"false\") == \"false\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(np.all([get_subtree_label(tree, tree.find(\".//node[@nid='\"+ x.attrib[\"nid\"] + \"']\")) for x in node.find(\"children\").findall(\"child\")]))\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dependency_tree(tree):\n",
    "\n",
    "    dep_tree, ids = terminals(tree)\n",
    "    n_terminals = len(dep_tree)\n",
    "    \n",
    "    for nid in ids:\n",
    "\n",
    "        parents = tree.findall(\".//children/child[@nid='\"+str(nid)+\"']....\")\n",
    "        print(parents)\n",
    "        for parent in parents:\n",
    "            print(parent.attrib[\"nid\"])\n",
    "            if parent is not None:\n",
    "                loc =  np.where([str(nid) in [x[0] for x in branch] and len(branch[-1])>=2 for branch in dep_tree])[0]\n",
    "                print(ids)\n",
    "                print(loc)\n",
    "                if parent.attrib[\"nid\"] not in ids:\n",
    "                    ids.append(parent.attrib[\"nid\"])\n",
    "\n",
    "\n",
    "                if len(parent.findall(\"children/child\"))==1:\n",
    "\n",
    "                    dep_tree[loc[0]].append(tuple([parent.attrib[\"nid\"]] +[x.text for x in parent.find(\"nonterminal\").getchildren()]))\n",
    "\n",
    "                    if parent.attrib[\"nid\"] == \"0\":\n",
    "\n",
    "                        if parent.attrib[\"nid\"] not in [branch[0][0] for branch in dep_tree]:\n",
    "                            dep_tree.append([tuple([parent.attrib[\"nid\"]] +[x.text for x in parent.find(\"nonterminal\").getchildren()])])\n",
    "\n",
    "\n",
    "                else:\n",
    "\n",
    "                    dep_tree[loc[0]].append((parent.attrib[\"nid\"],))\n",
    "\n",
    "                    if parent.attrib[\"nid\"] not in [branch[0][0] for branch in dep_tree]:\n",
    "                        dep_tree.append([tuple([parent.attrib[\"nid\"]] +[x.text for x in parent.find(\"nonterminal\").getchildren()])])\n",
    "            else:\n",
    "                pass\n",
    "            #labels.append(get_subtree_label(tree, tree.find(\".//node[@nid='\" + str(nid) + \"']\")))\n",
    "            \n",
    "    heads = [x[-2][0] if len(x)>1 else x[0][0]  for x in dep_tree]       \n",
    "    labels = [get_subtree_label(tree, tree.find(\".//node[@nid='\" + str(nid) + \"']\")) for nid in heads]\n",
    "\n",
    "    return(dep_tree, labels, n_terminals)                                           \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_to_dependency_format(tree):\n",
    "    \n",
    "    dep_tree, labels, n_terminals = dependency_tree(tree)\n",
    "    \n",
    "    values = [[x[1] for x in branch[:-1]] for branch in dep_tree]\n",
    "    \n",
    "    top_node_ids = [branch[-1][0] for branch in dep_tree]\n",
    "    \n",
    "    for i in range(n_terminals,len(values)):\n",
    "        if len(values[i])>0:\n",
    "            values[i] = [get_head(tree, top_node_ids[i])]+values[i]\n",
    "        else:\n",
    "            values[i] = [get_head(tree, top_node_ids[i]),\"__wypowiedzenie__\"]\n",
    "\n",
    "\n",
    "    tokens_and_rules = [(y[0],\"-\".join(y[1:])) if len(y)>1 else (y[0],\"__brak__\") for y in values]\n",
    "\n",
    "    nodes_ids = [[x[0] for x in branch] for branch in dep_tree]\n",
    "    \n",
    "    parent_ids = [0]*len(nodes_ids)\n",
    "    firsts = [x[0] for x in nodes_ids]\n",
    "\n",
    "\n",
    "    for i in range(len(nodes_ids)):\n",
    "        last = nodes_ids[i][-1]\n",
    "\n",
    "        if len(nodes_ids[i])==1 and last == \"0\":\n",
    "            parent_ids[i] = 0\n",
    "        else:\n",
    "            parent_ids[i] = np.where([last == x for x in firsts])[0][0] + 1 # \"+1\" po to zeby format danych zgadzal sie z tymi ze stanfordu \n",
    "                                                                            # - numerujemy tokeny od 1, a nie od 0\n",
    "\n",
    "    nodes_used_in_tree = [x[0] for branch in dep_tree for x in branch]    \n",
    "    \n",
    "    dependency_data = list(zip([x[0] for x in tokens_and_rules],[x[1] for x in tokens_and_rules], parent_ids, labels))\n",
    "    \n",
    "    return(dependency_data, nodes_used_in_tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "def write_dependency_format(dep_tree, folder, overwrite=False):\n",
    "    \n",
    "    if not overwrite:\n",
    "        mode = \"a+\"\n",
    "    else:\n",
    "        mode = \"w\"\n",
    "    \n",
    "    tokens = [x[0] for x in dep_tree[0]]\n",
    "    with open(folder+\"/tokens.txt\", mode) as f:\n",
    "        f.write(\" \".join(tokens) + \"\\n\")\n",
    "        \n",
    "    rules = [x[1] for x in dep_tree[0]]\n",
    "    with open(folder+\"/rules.txt\", mode) as f:\n",
    "        f.write(\" \".join(rules) + \"\\n\")\n",
    "        \n",
    "    parents = [str(x[2]) for x in dep_tree[0]]\n",
    "    with open(folder+\"/parents.txt\", mode) as f:\n",
    "        f.write(\" \".join(parents) + \"\\n\")\n",
    "        \n",
    "    labels = [str(x[3]) for x in dep_tree[0]]\n",
    "    with open(folder+\"/labels.txt\", mode) as f:\n",
    "        f.write(\" \".join(labels) + \"\\n\")\n",
    "\n",
    "    nodes_used_in_tree = dep_tree[1]\n",
    "    with open(folder+\"/nodes_used_in_tree.txt\", mode) as f:\n",
    "        f.write(\" \".join(nodes_used_in_tree) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "write_dependency_format(dep_tree, \"Data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_folder = \"../Składnica-frazowa-171220/**/*.xml\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "../Składnica-frazowa-171220/NKJP_1M_2002000137/morph_3-p/morph_3.36-s.xml\n"
     ]
    }
   ],
   "source": [
    "import glob\n",
    "\n",
    "j = 1\n",
    "trees, labels = [],[]\n",
    "for filename in glob.iglob(data_folder, recursive=True):\n",
    "    \n",
    "    forest = ET.parse(filename)\n",
    " \n",
    "    try:\n",
    "        num_trees = number_of_trees_in_forest(forest)\n",
    "        if num_trees<10 and num_trees>5:\n",
    "            print(filename)\n",
    "            break\n",
    "        \n",
    "        if num_trees<100000:\n",
    "            \n",
    "            if j % 100 ==0:\n",
    "                print(j)\n",
    "                print(num_trees)\n",
    "            \n",
    "            trees.append(get_positive_tree(forest))\n",
    "            labels.append(1)\n",
    "        \n",
    "            \n",
    "            if num_trees < 10:\n",
    "\n",
    "                trees.append(get_random_negative_tree(forest))\n",
    "                labels.append(0)\n",
    "\n",
    "            elif num_trees<20:\n",
    "                for i in range(3):\n",
    "                    trees.append(get_random_negative_tree(forest))\n",
    "                    labels.append(0)\n",
    "            elif num_trees<30:\n",
    "                for i in range(4):\n",
    "                    trees.append(get_random_negative_tree(forest))\n",
    "                    labels.append(0)\n",
    "            elif num_trees<40:\n",
    "                for i in range(5):\n",
    "                    trees.append(get_random_negative_tree(forest))\n",
    "                    labels.append(0)\n",
    "            elif num_trees<10000:\n",
    "                for i in range(10):\n",
    "                    trees.append(get_random_negative_tree(forest))\n",
    "                    labels.append(0)\n",
    "               \n",
    "            j += 1\n",
    "        \n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    \n",
    "\n",
    "    if j>1000:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _tree_height(xml_tree, node_id=0):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja oblicza wysokosc drzewa (dlugosc najdluzszej sciezki od korzenia do liscia)\n",
    "    lub lasu (maximum z wszystkich mozliwych drzew)\n",
    "    \n",
    "    xml_tree - drzewo luba las drzew lub korzen drzewa jednego lub drugiego\n",
    "    \"\"\"\n",
    "    \n",
    "    \n",
    "    if type(xml_tree)==ET.Element:\n",
    "        node = tree\n",
    "    else:\n",
    "        node = tree.getroot()\n",
    "        \n",
    "    node = node.find('.//node[@nid=\"' + str(node_id) + '\"]')\n",
    "    children = node.findall(\".//children//child\")\n",
    "    \n",
    "    if len(children)==0:\n",
    "        return 1\n",
    "    else:\n",
    "        children_nodes = [child.attrib[\"nid\"] for child in children]\n",
    "        return 1+max([_tree_height(tree,x) for x in children_nodes])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def number_of_nodes(tree):\n",
    "    \"\"\"\n",
    "    Zwraca liczbe wezlow w drzewie.\n",
    "    \n",
    "    tree - drzewo lub korzen drzewa\n",
    "    \"\"\"\n",
    "    if type(tree)==ET.Element:\n",
    "        return len(tree.findall(\"node\"))\n",
    "    else:\n",
    "        return len(tree.getroot().findall(\"node\")) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_subtree_label(tree, node):\n",
    "    \n",
    "    if node.find(\"children\") is None:\n",
    "        return 1\n",
    "    \n",
    "    if node.find(\"children\").attrib.get(\"chosen\",\"false\") == \"false\":\n",
    "        return 0\n",
    "    else:\n",
    "        return int(np.all([get_subtree_label(tree, tree.find(\".//node[@nid='\"+ x.attrib[\"nid\"] + \"']\")) for x in node.find(\"children\").findall(\"child\")]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_positive(tree): \n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja sprawdza czy drzewo jest pozytywne - czy jest poprawnym drzewem rozbioru\n",
    "    Zwraca wartosc logiczna.\n",
    "    \n",
    "    tree - drzewo [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "    \n",
    "    _check_sentence(tree,\"tree\")\n",
    "    \n",
    "    assert len(tree.find(\"node\"))>0, 'There is not \"node\" element in the tree'\n",
    "    \n",
    "    #Sprawdzamy czy wszystkie wezly \"node\" maja wartosc chosen=\"true\":\n",
    "    for x in tree.iter(\"node\"):\n",
    "        if not x.attrib[\"chosen\"]==\"true\":\n",
    "            return False\n",
    "\n",
    "    #Sprawdzamy czy wszystkie wezly \"children\" maja wartosc chosen=\"true\":\n",
    "    for x in tree.iter(\".//children\"):\n",
    "        if not x.attrib[\"chosen\"]==\"true\":\n",
    "            return False\n",
    "        \n",
    "    return True\n",
    "        \n",
    "        \n",
    "    \n",
    "\n",
    "\n",
    "def get_positive_tree(forest):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja zwraca poprawne (pozytywne) drzewo z upakowanego lasu (forest).\n",
    "    Dla lasu, w ktorym nie ma poprawnego drzewa funkcja wyrzuca blad.\n",
    "    \n",
    "    forest - las drzew [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "\n",
    "    # sprawdzenie poprawnosci lasu i ewentualne wypisanie komunikatu\n",
    "    _check_sentence(forest,\"forest\")\n",
    "            \n",
    "    root_old = forest.getroot()\n",
    "    root_new = ET.Element(\"tree\",root_old.attrib)\n",
    "    \n",
    "    \n",
    "    # las sklada sie z drzew (wezly \"node\") oraz dodatkowych danych (inne wezly) -\n",
    "    # tresc wypowiedzenia, statystyki lasu, itd. - i tutaj przepisujemy te wezly\n",
    "    features = root_old.getchildren()\n",
    "    for feature in features:\n",
    "        if feature.tag != \"node\": \n",
    "            feature_copy = deepcopy(feature)\n",
    "            if feature_copy.tag == \"stats\":\n",
    "                feature_copy.tag = \"forest-stats\"\n",
    "                \n",
    "            root_new.append(feature_copy) # modyfikujemy tag wezla wiec potrzebna kopia, zeby nie zmodyfikowac oryginalnego drzewa\n",
    "            \n",
    "    # definiujemy rekurencyjna funkcje, ktora bedzie przechodzic po lesie i\n",
    "    # kolekcjonowac wezly, tworzac losowe drzewo.\n",
    "    # drzewo jest tworzone na korzeniu root_new.\n",
    "    def add_positive_children(current_node_old):\n",
    "        \n",
    "        current_node_new = ET.SubElement(root_new, current_node_old.tag, current_node_old.attrib)\n",
    "        \n",
    "        features = current_node_old.getchildren()\n",
    "        # kazdy \"node\" jest terminalem albo nieterminalem i ma opis wlasnosci\n",
    "        # i tutaj wyciagamy te wlasnosci z wezla innego niz \"children\"\n",
    "        for feature in features:\n",
    "            if feature.tag != \"children\": \n",
    "                current_node_new.append(feature)\n",
    "        \n",
    "        \n",
    "        children_old = current_node_old.findall('children[@chosen=\"true\"]')\n",
    "        # powinno byc tylko jedno takie dziecko\n",
    "        \n",
    "        assert len(children_old) <= 1, 'More than one children has chosen=\"true\"'\n",
    "        \n",
    "        if len(children_old) == 0: #jestesmy w lisciu wiec konczymy dzialanie funkcji\n",
    "            return None\n",
    "        \n",
    "        #random_children_old = children_old[np.random.choice(len(children_old),1)[0]]\n",
    "        children_new = ET.SubElement(current_node_new, children_old[0].tag, children_old[0].attrib)\n",
    "        for child_old in children_old[0].getchildren():\n",
    "            x = ET.SubElement(children_new, child_old.tag, child_old.attrib)\n",
    "            next_node = root_old.find('.//node[@nid=\"' + x.attrib[\"nid\"] + '\"]')\n",
    "            assert next_node.attrib[\"chosen\"] == \"true\"\n",
    "            add_positive_children(next_node)\n",
    "        \n",
    "    \n",
    "    # wezel startowy (przyjmujemy, ze node z id=0 jest zawsze pierwszy):\n",
    "    # TODO: upewnic sie czy to jest poprawne podejscie - czy moze byc inny wezel poczatkowym\n",
    "    node_0 = root_old.find('.//node[@nid=\"0\"][@chosen=\"true\"]') \n",
    "    \n",
    "    # konstruujemy drzewo:\n",
    "    add_positive_children(node_0)\n",
    "    \n",
    "    positive_tree = ET.ElementTree(root_new)\n",
    "\n",
    "    # Sprawdzenie poprawnosci drzewa\n",
    "    assert is_positive(positive_tree), \"\"\"Something gone wrong - tree is not positive\"\"\"\n",
    "        \n",
    "        \n",
    "    return positive_tree\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_trees(forest):\n",
    "    \n",
    "    \"\"\"\n",
    "    Funkcja zwraca losowe drzewo z upakowanego lasu (forest).\n",
    "    Dla lasu, w ktorym nie ma poprawnego drzewa funkcja wyrzuca blad.\n",
    "    \n",
    "    forest - las drzew [xml.etree.ElementTree.ElementTree]\n",
    "    \"\"\"\n",
    "\n",
    "    # sprawdzenie poprawnosci lasu i ewentualne wypisanie komunikatu\n",
    "    _check_sentence(forest,\"forest\")\n",
    "\n",
    "            \n",
    "    root_old = forest.getroot()\n",
    "    root_new = ET.Element(\"tree\",root_old.attrib)\n",
    "    \n",
    "    \n",
    "    # las sklada sie z drzew (wezly \"node\") oraz dodatkowych danych (inne wezly) -\n",
    "    # tresc wypowiedzenia, statystyki lasu, itd. - i tutaj przepisujemy te wezly\n",
    "    features = root_old.getchildren()\n",
    "    for feature in features:\n",
    "        if feature.tag != \"node\": \n",
    "            feature_copy = deepcopy(feature)\n",
    "            if feature_copy.tag == \"stats\":\n",
    "                feature_copy.tag = \"forest-stats\"\n",
    "                \n",
    "            root_new.append(feature_copy) # modyfikujemy tag wezla wiec potrzebna kopia, zeby nie zmodyfikowac oryginalnego drzewa\n",
    "    \n",
    "    # definiujemy wezel ze statystykami drzewa\n",
    "    # robimy to w tym iejscu zeby zachowac logiczna kolejnosc wezlow - zeby wypisywalo sie to na poczatku\n",
    "    # wartosci nadamy nizej\n",
    "    ET.SubElement(root_new, \"tree-stats\", {\"height\":\"0\",\"nodes\":\"0\"})\n",
    "            \n",
    "            \n",
    "    # definiujemy rekurencyjna funkcje, ktora bedzie przechodzic po lesie i\n",
    "    # kolekcjonowac wezly, tworzac losowe drzewo.\n",
    "    # drzewo jest tworzone na korzeniu root_new.\n",
    "    \n",
    "    trees = []\n",
    "    \n",
    "    def add_random_children(current_node_old,root_new):\n",
    "        \n",
    "        root_new_recurrent = deepcopy(root_new)\n",
    "        \n",
    "        current_node_new = ET.SubElement(root_new_recurrent, current_node_old.tag, current_node_old.attrib)\n",
    "        \n",
    "        features = current_node_old.getchildren()\n",
    "        # kazdy \"node\" jest terminalem albo nieterminalem i ma opis wlasnosci\n",
    "        # i tutaj wyciagamy te wlasnosci z wezla innego niz \"children\"\n",
    "        for feature in features:\n",
    "            if feature.tag != \"children\": \n",
    "                current_node_new.append(feature)\n",
    "        \n",
    "        children_old = current_node_old.findall(\"children\")\n",
    "        if len(children_old) == 0: #jestesmy w lisciu wiec konczymy dzialanie funkcji\n",
    "            return root_new_recurrent\n",
    "        \n",
    "        #random_children_old = children_old[np.random.choice(len(children_old),1)[0]]\n",
    "        #random_children_new = ET.SubElement(current_node_new, random_children_old.tag, random_children_old.attrib)\n",
    "        \n",
    "        \n",
    "        \n",
    "        for children in children_old:\n",
    "            \n",
    "            children_new = ET.SubElement(current_node_new, children.tag, children.attrib)\n",
    "            \n",
    "            for child_old in children.getchildren():\n",
    "                x = ET.SubElement(children_new, child_old.tag, child_old.attrib)\n",
    "                next_node = root_old.find('.//node[@nid=\"' + x.attrib[\"nid\"] + '\"]')\n",
    "                if len(next_node.findall(\"children\"))==0:\n",
    "                    trees.append(ET.ElementTree(root_new_recurrent))\n",
    "                else:\n",
    "                    add_random_children(next_node,root_new_recurrent)\n",
    "                    \n",
    "        \n",
    "        \n",
    "    \n",
    "        # wezel startowy (przyjmujemy, ze node z id=0 jest zawsze pierwszy):\n",
    "    # TODO: upewnic sie czy to jest poprawne podejscie - czy moze byc inny wezel poczatkowym\n",
    "    node_0 = root_old.find('.//node[@nid=\"0\"]') \n",
    "    \n",
    "    # konstruujemy drzewo:\n",
    "    #add_random_children(node_0,root_new)\n",
    "    \n",
    "    #new_tree = ET.ElementTree(root_new)\n",
    "    \n",
    "    #th = _tree_height(new_tree, node_id=0)\n",
    "    \n",
    "    #root_new.find(\"tree-stats\").attrib[\"height\"] = str(th)\n",
    "    #root_new.find(\"tree-stats\").attrib[\"nodes\"] = str(len(root_new.findall(\"node\")))\n",
    "    \n",
    "    add_random_children(node_0,root_new)\n",
    "    \n",
    "    return trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
